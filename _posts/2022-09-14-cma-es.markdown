---
layout: post
title:  "CMA Evolution Strategy"
date:   2022-09-14 13:00:00 +0700
categories: artificial-intelligent machine-learning
tags: artificial-intelligent evolution-strategy
description: A note CMA-ES
comments: true
eqn-number: true
---
> A note on CMA - Evolution Strategy
<!-- excerpt-end -->
- [Preliminaries](#preliminaries)
- [Basic equation](#bsc-eqn)
- [Updating the mean](#upd-mean)
- [Adapting the covariance matrix](#adp-cov)
	- [Estimating from scratch](#est-scratch)
	- [Rank-$\gamma$-update](#rank-lambda-mu-update)
	- [Rank-one-update](#rank-one-update)
- [Controlling the step-size](#ctrl-sigma)
- [References](#references)
- [Footnotes](#footnotes)

## Preliminaries
{: #preliminaries}
The **condition number** of a matrix $\mathbf{A}$ is defined by
\begin{equation}
\kappa(\mathbf{A})\doteq\Vert\mathbf{A}\Vert\Vert\mathbf{A}^{-1}\Vert,
\end{equation}
where $\Vert\mathbf{A}\Vert=\sup_{\Vert\mathbf{x}\Vert=1}\Vert\mathbf{Ax}\Vert$.

For $\mathbf{A}$ that is non-singular, $\kappa(\mathbf{A})=\infty$.

For $\mathbf{A}$ which is positive definite, we thus have $\Vert\mathbf{A}\Vert=\lambda_\text{max}$ where $\lambda_\text{max}$ denotes the largest eigenvalue of $\mathbf{A}$, correspondingly $\lambda_\text{min}$ denotes the smallest eigenvalue of $\mathbf{A}$. The condition number of $\mathbf{A}$ therefore can be written as
\begin{equation}
\kappa(\mathbf{A})=\frac{\lambda_\text{max}}{\lambda_\text{min}}\geq 1,
\end{equation}
since corresponding to each eigenvalue $\lambda$ of $\mathbf{A}$, the inverse matrix $\mathbf{A}^{-1}$ takes $1/\lambda$ as its eigenvalue.

## Basic equation
{: #bsc-eqn}
In the CMA-ES, a population of new search points is generated by sampling an MVN, in which at generation $t+1$, for $t=0,1,2,\ldots$
\begin{equation}
\mathbf{x}\_k^{(t+1)}\sim\boldsymbol{\mu}^{(t)}+\sigma^{(t)}\mathcal{N}(\mathbf{0},\boldsymbol{\Sigma}^{(t)})\sim\mathcal{N}\left(\boldsymbol{\mu}^{(t)},{\sigma^{(t)}}^2\boldsymbol{\Sigma}^{(t)}\right),\hspace{1cm}k=1,\ldots,\lambda\label{eq:be.1}
\end{equation}
where
- $\mathbf{x}\_k^{(t+1)}\in\mathbb{R}^n$: the $k$-th sample at generation $t+1$.
- $\boldsymbol{\mu}^{(t)}\in\mathbb{R}^n$: mean of the search distribution at generation $t$.
- $\sigma^{(t)}\in\mathbb{R}$: step-size at generation $t$.
- $\boldsymbol{\Sigma}^{(t)}$: covariance matrix at generation $t$.
- ${\sigma^{(t)}}^2\boldsymbol{\Sigma}^{(t)}$: covariance matrix of the search distribution at generation $t$.
- $\lambda\geq 2$: sample size.

## Updating the mean
{: #update-mean}
The mean $\boldsymbol{\mu}^{(t+1)}$ of the search distribution is defined as the weighted average of $\gamma$ selected points from the sample $\mathbf{x}\_1^{(t+1)},\ldots,\mathbf{x}\_\lambda^{(t+1)}$:
\begin{equation}
\boldsymbol{\mu}^{(t+1)}=\sum_{i=1}^{\gamma}w_i\mathbf{x}\_{i:\lambda}^{(t+1)},\label{eq:um.1}
\end{equation}
where
- $\sum_{i=1}^{\gamma}w_i=1$ with $w_1\geq w_2\geq\ldots\geq w_{\gamma}>0$.
- $\gamma\leq\lambda$: number of selected points.
- $\mathbf{x}\_{i:\lambda}^{(t+1)}$: $i$-th best sample out of $\mathbf{x}\_1^{(t+1)},\ldots,\mathbf{x}\_\lambda^{(t+1)}$ from \eqref{eq:be.1}, i.e. with $f$ is the objective function to be minimized, we have
\begin{equation}
f(\mathbf{x}\_{1:\lambda}^{(t+1)})\geq f(\mathbf{x}\_{2:\lambda}^{(t+1)})\geq\ldots\geq f(\mathbf{x}\_{\lambda:\lambda}^{(t+1)})
\end{equation}

We can rewrite \eqref{eq:um.1} as an update rule for the mean $\boldsymbol{\mu}$
\begin{equation}
\boldsymbol{\mu}^{(t+1)}=\boldsymbol{\mu}^{(t)}+\alpha_\boldsymbol{\mu}\sum_{i=1}^{\gamma}w_i\left(\mathbf{x}\_{i:\lambda}^{(t+1)}-\boldsymbol{\mu}^{(t)}\right),
\end{equation}
where $\alpha_\boldsymbol{\mu}\leq 1$ is the learning rate, which is usually set to $1$.

## Adapting the covariance matrix
{: #adp-cov}

### Estimating from scratch
{: #est-scratch}
Rather than using the empirical covariance matrix as an estimator for $\boldsymbol{\Sigma}^{(t)}$, in the CMA-ES, we consider the following estimation
\begin{equation}
\boldsymbol{\Sigma}\_\lambda^{(t+1)}=\frac{1}{\lambda{\sigma^{(t)}}^2}\sum_{i=1}^{\lambda}\left(\mathbf{x}\_i^{(t+1)}-\boldsymbol{\mu}^{(t)}\right)\left(\mathbf{x}\_i^{(t+1)}-\boldsymbol{\mu}^{(t)}\right)^\text{T}\label{eq:es.1}
\end{equation}
Notice that in the above estimation \eqref{eq:es.1}, we have used all of the $\lambda$ samples. We thus can estimate a better covariance matrix by select some of the best individual out of $\lambda$ samples, which is analogous to how we update the mean $\boldsymbol{\mu}$.

In particular, we instead consider the estimation
\begin{equation}
\boldsymbol{\Sigma}\_{\gamma}^{(t+1)}=\frac{1}{\{\sigma^{(t)}\}^2}\sum_{i=1}^{\gamma}w_i\left(\mathbf{x}\_{i:\lambda}^{(t+1)}-\boldsymbol{\mu}^{(t)}\right)\left(\mathbf{x}\_{i:\lambda}^{(t+1)}-\boldsymbol{\mu}^{(t)}\right)^\text{T},\label{eq:es.2}
\end{equation}
where $\gamma\leq\lambda$ is the number of selected points; the weights $w_i$ and selected points $\mathbf{x}\_{i:\lambda}^{(t+1)}$ are defined as given in the update for $\boldsymbol{\mu}$.

### Rank-$\gamma$-update
{: #rank-lambda-mu-update}
In order to ensure that \eqref{eq:es.2} is a reliable estimator, the selected population must be large enough. However, to get a fast search, the population size $\lambda$ must be small, which lets the selected sample size consequently small also. Thus, we can not get a reliable estimator for a good covariance matrix from \eqref{eq:es.2}. However, we can use the history as a helping hand.

In particular, if we have experienced a sufficient number of generations, the mean of the $\boldsymbol{\Sigma}\_\gamma$ from all previous generations
\begin{equation}
\boldsymbol{\Sigma}^{(t+1)}=\frac{1}{t+1}\sum_{i=0}^{t}\boldsymbol{\Sigma}\_\gamma^{(i+1)}\label{eq:rlmu.1}
\end{equation}
would be a reliable estimator.

In addition, it is reasonable that the recent generations will have more affection to the current generation than the distant ones. Hence, rather than assigning estimated covariance matrices $\boldsymbol{\Sigma}\_\gamma$ from preceding generations the same weight as in \eqref{eq:rlmu.1}, it would be a better choice to give the more recent generations the higher weight.

Specifically, starting with an initial $\boldsymbol{\Sigma}^{(0)}=\mathbf{I}$, we consider the update, called **rank-$\gamma$-update**, for the covariance matrix at generation $t+1$ as
\begin{align}
\boldsymbol{\Sigma}^{(t+1)}&=(1-\alpha_\gamma)\boldsymbol{\Sigma}^{(t)}+\alpha_\gamma\boldsymbol{\Sigma}\_\gamma^{(t+1)} \\\\ &=(1-\alpha_\gamma)\boldsymbol{\Sigma}^{(t)}+\alpha_\gamma\frac{1}{\{\sigma^{(t)}\}^2}\sum_{i=1}^{\gamma}w_i\left(\mathbf{x}\_{i:\lambda}^{(t+1)}-\boldsymbol{\mu}^{(t)}\right)\left(\mathbf{x}\_{i:\lambda}^{(t+1)}-\boldsymbol{\mu}^{(t)}\right)^\text{T} \\\\ &=(1-\alpha_\gamma)\boldsymbol{\Sigma}^{(t)}+\alpha_\gamma\sum_{i=1}^{\gamma}w_i\mathbf{y}\_{i:\lambda}^{(t+1)}{\mathbf{y}\_{i:\lambda}^{(t+1)}}^\text{T},\label{eq:rlmu.2}
\end{align}
where
- $\alpha_\gamma\leq 1$: learning rate.
- $w_1,\ldots,w_\gamma$ and $\mathbf{x}\_{1:\lambda}^{(t+1)},\ldots,\mathbf{x}\_{\lambda:\lambda}^{(g+1)}$ are defined as usual.
- $\mathbf{y}\_{i:\lambda}^{(t+1)}=(\mathbf{x}\_{i:\lambda}^{(t+1)}-\boldsymbol{\mu}^{(t)})/\sigma^{(t)}$.

The update \eqref{eq:rlmu.2} can be generalized to $\lambda$ weights values which neither necessarily sum to $1$, nor be non-negative anymore, as
\begin{align}
\boldsymbol{\Sigma}^{(t+1)}&=\left(1-\alpha_\gamma\sum_{i=1}^{\lambda}w_i\right)\boldsymbol{\Sigma}^{(t)}+\alpha_\gamma\sum_{i=1}^{\lambda}w_i\mathbf{y}\_{i:\lambda}^{(t+1)}{\mathbf{y}\_{i:\lambda}^{(t+1)}}^\text{T} \\\\ &={\boldsymbol{\Sigma}^{(t)}}^{1/2}\left[\mathbf{I}+\alpha_\gamma\sum_{i=1}^{\lambda}w_i\left(\mathbf{z}\_{i:\lambda}^{(t+1)}{\mathbf{z}\_{i:\lambda}^{(t+1)}}^\text{T}-\mathbf{I}\right)\right]{\boldsymbol{\Sigma}^{(t)}}^{1/2},
\end{align}
where
- $w_1\geq\ldots\geq w_\gamma>0\geq w_{\gamma+1}\geq\ldots\geq w_\lambda\in\mathbb{R}$, and usually $\sum_{i=1}^{\gamma}w_i=1$ and $\sum_{i=1}^{\lambda}w_i\approx 0$.
- $\mathbf{z}\_{i:\lambda}^{(t+1)}={\boldsymbol{\Sigma}^{(t)}}^{1/2}\mathbf{y}\_{i:\lambda}^{(t+1)}$ is the mutation vector.

### Rank-one update
{: #rank-one-update}

## Controlling the step-size
{: #ctrl-sigma}

## References
{: #references}
[1] Nikolaus Hansen. [The CMA Evolution Strategy: A Tutorial](#https://arxiv.org/abs/1604.00772). 

## Footnotes
{: #footnotes}
