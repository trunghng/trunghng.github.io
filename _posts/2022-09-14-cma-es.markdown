---
layout: post
title:  "CMA Evolution Strategy"
date:   2022-09-14 13:00:00 +0700
categories: artificial-intelligent machine-learning
tags: artificial-intelligent evolution-strategy
description: A note CMA-ES
comments: true
eqn-number: true
---
> A note on CMA - Evolution Strategy
<!-- excerpt-end -->

- [Preliminaries](#preliminaries)
- [Basic equation](#bsc-eqn)
- [Updating the mean](#upd-mean)
- [Adapting the covariance matrix](#adp-cov)
	- [Estimating from scratch](#est-scratch)
	- [Rank-$\gamma$ update](#rank-lambda-mu-update)
	- [Rank-one update](#rank-one-update)
	- [Final update](#final-update)
- [Controlling the step-size](#ctrl-sigma)
- [References](#references)
- [Footnotes](#footnotes)

## Preliminaries
{: #preliminaries}
The **condition number** of a matrix $\mathbf{A}$ is defined by
\begin{equation}
\kappa(\mathbf{A})\doteq\Vert\mathbf{A}\Vert\Vert\mathbf{A}^{-1}\Vert,
\end{equation}
where $\Vert\mathbf{A}\Vert=\sup_{\Vert\mathbf{x}\Vert=1}\Vert\mathbf{Ax}\Vert$.

For $\mathbf{A}$ that is non-singular, $\kappa(\mathbf{A})=\infty$.

For $\mathbf{A}$ which is positive definite, we thus have $\Vert\mathbf{A}\Vert=\lambda_\text{max}$ where $\lambda_\text{max}$ denotes the largest eigenvalue of $\mathbf{A}$, correspondingly $\lambda_\text{min}$ denotes the smallest eigenvalue of $\mathbf{A}$. The condition number of $\mathbf{A}$ therefore can be written as
\begin{equation}
\kappa(\mathbf{A})=\frac{\lambda_\text{max}}{\lambda_\text{min}}\geq 1,
\end{equation}
since corresponding to each eigenvalue $\lambda$ of $\mathbf{A}$, the inverse matrix $\mathbf{A}^{-1}$ takes $1/\lambda$ as its eigenvalue.

## Basic equation
{: #bsc-eqn}
In the CMA-ES, a population of new search points is generated by sampling an MVN, in which at generation $t+1$, for $t=0,1,2,\ldots$
\begin{equation}
\mathbf{x}\_k^{(t+1)}\sim\boldsymbol{\mu}^{(t)}+\sigma^{(t)}\mathcal{N}(\mathbf{0},\boldsymbol{\Sigma}^{(t)})\sim\mathcal{N}\left(\boldsymbol{\mu}^{(t)},{\sigma^{(t)}}^2\boldsymbol{\Sigma}^{(t)}\right),\hspace{1cm}k=1,\ldots,\lambda\label{eq:be.1}
\end{equation}
where
- $\mathbf{x}\_k^{(t+1)}\in\mathbb{R}^n$: the $k$-th sample at generation $t+1$.
- $\boldsymbol{\mu}^{(t)}\in\mathbb{R}^n$: mean of the search distribution at generation $t$.
- $\sigma^{(t)}\in\mathbb{R}$: step-size at generation $t$.
- $\boldsymbol{\Sigma}^{(t)}$: covariance matrix at generation $t$.
- ${\sigma^{(t)}}^2\boldsymbol{\Sigma}^{(t)}$: covariance matrix of the search distribution at generation $t$.
- $\lambda\geq 2$: sample size.

## Updating the mean
{: #update-mean}
The mean $\boldsymbol{\mu}^{(t+1)}$ of the search distribution is defined as the weighted average of $\gamma$ selected points from the sample $\mathbf{x}\_1^{(t+1)},\ldots,\mathbf{x}\_\lambda^{(t+1)}$:
\begin{equation}
\boldsymbol{\mu}^{(t+1)}=\sum_{i=1}^{\gamma}w_i\mathbf{x}\_{i:\lambda}^{(t+1)},\label{eq:um.1}
\end{equation}
where
- $\sum_{i=1}^{\gamma}w_i=1$ with $w_1\geq w_2\geq\ldots\geq w_{\gamma}>0$.
- $\gamma\leq\lambda$: number of selected points.
- $\mathbf{x}\_{i:\lambda}^{(t+1)}$: $i$-th best sample out of $\mathbf{x}\_1^{(t+1)},\ldots,\mathbf{x}\_\lambda^{(t+1)}$ from \eqref{eq:be.1}, i.e. with $f$ is the objective function to be minimized, we have
\begin{equation}
f(\mathbf{x}\_{1:\lambda}^{(t+1)})\geq f(\mathbf{x}\_{2:\lambda}^{(t+1)})\geq\ldots\geq f(\mathbf{x}\_{\lambda:\lambda}^{(t+1)})
\end{equation}

We can rewrite \eqref{eq:um.1} as an update rule for the mean $\boldsymbol{\mu}$
\begin{equation}
\boldsymbol{\mu}^{(t+1)}=\boldsymbol{\mu}^{(t)}+\alpha_\boldsymbol{\mu}\sum_{i=1}^{\gamma}w_i\left(\mathbf{x}\_{i:\lambda}^{(t+1)}-\boldsymbol{\mu}^{(t)}\right),
\end{equation}
where $\alpha_\boldsymbol{\mu}\leq 1$ is the learning rate, which is usually set to $1$.

When choosing the weight values $w_i$ and population size $\gamma$ for recombination, we take into account the **variance effective selection mass**, denoted as $\gamma_\text{eff}$, given by
\begin{equation}
\gamma_\text{eff}\doteq\left(\frac{\Vert\mathbf{w}\Vert_1}{\Vert\mathbf{w}\Vert_2}\right)=\frac{\Vert\mathbf{w}\Vert_1^2}{\Vert\mathbf{w}\Vert_2^2}=\frac{1}{\sum_{i=1}^{\gamma}w_i^2}
\end{equation}
where $\mathbf{w}$ is defined as the weight vector
\begin{equation}
\mathbf{w}=(w_1,\ldots,w_\gamma)^\text{T}
\end{equation}

## Adapting the covariance matrix
{: #adp-cov}
The covariance matrix can be estimated from scratch using the population of the current generation or can be estimated with covariance matrix from previous generations.

### Estimating from scratch
{: #est-scratch}
Rather than using the empirical covariance matrix as an estimator for $\boldsymbol{\Sigma}^{(t)}$, in the CMA-ES, we consider the following estimation
\begin{equation}
\boldsymbol{\Sigma}\_\lambda^{(t+1)}=\frac{1}{\lambda{\sigma^{(t)}}^2}\sum_{i=1}^{\lambda}\left(\mathbf{x}\_i^{(t+1)}-\boldsymbol{\mu}^{(t)}\right)\left(\mathbf{x}\_i^{(t+1)}-\boldsymbol{\mu}^{(t)}\right)^\text{T}\label{eq:es.1}
\end{equation}
Notice that in the above estimation \eqref{eq:es.1}, we have used all of the $\lambda$ samples. We thus can estimate a better covariance matrix by select some of the best individual out of $\lambda$ samples, which is analogous to how we update the mean $\boldsymbol{\mu}$.

In particular, we instead consider the estimation
\begin{equation}
\boldsymbol{\Sigma}\_{\gamma}^{(t+1)}=\frac{1}{\{\sigma^{(t)}\}^2}\sum_{i=1}^{\gamma}w_i\left(\mathbf{x}\_{i:\lambda}^{(t+1)}-\boldsymbol{\mu}^{(t)}\right)\left(\mathbf{x}\_{i:\lambda}^{(t+1)}-\boldsymbol{\mu}^{(t)}\right)^\text{T},\label{eq:es.2}
\end{equation}
where $\gamma\leq\lambda$ is the number of selected points; the weights $w_i$ and selected points $\mathbf{x}\_{i:\lambda}^{(t+1)}$ are defined as given in the update for $\boldsymbol{\mu}$.

### Rank-$\gamma$ update
{: #rank-lambda-mu-update}
In order to ensure that \eqref{eq:es.2} is a reliable estimator, the selected population must be large enough. However, to get a fast search, the population size $\lambda$ must be small, which lets the selected sample size consequently small also. Thus, we can not get a reliable estimator for a good covariance matrix from \eqref{eq:es.2}. However, we can use the history as a helping hand.

In particular, if we have experienced a sufficient number of generations, the mean of the $\boldsymbol{\Sigma}\_\gamma$ from all previous generations
\begin{equation}
\boldsymbol{\Sigma}^{(t+1)}=\frac{1}{t+1}\sum_{i=0}^{t}\boldsymbol{\Sigma}\_\gamma^{(i+1)}\label{eq:rlmu.1}
\end{equation}
would be a reliable estimator.

In addition, it is reasonable that the recent generations will have more affection to the current generation than the distant ones. Hence, rather than assigning estimated covariance matrices $\boldsymbol{\Sigma}\_\gamma$ from preceding generations the same weight as in \eqref{eq:rlmu.1}, it would be a better choice to give the more recent generations the higher weight.

Specifically, starting with an initial $\boldsymbol{\Sigma}^{(0)}=\mathbf{I}$, we consider the update, called **rank-$\gamma$ update**, for the covariance matrix at generation $t+1$ using **exponential smoothing**[^1] as
\begin{align}
\boldsymbol{\Sigma}^{(t+1)}&=(1-\alpha_\gamma)\boldsymbol{\Sigma}^{(t)}+\alpha_\gamma\boldsymbol{\Sigma}\_\gamma^{(t+1)} \\\\ &=(1-\alpha_\gamma)\boldsymbol{\Sigma}^{(t)}+\alpha_\gamma\frac{1}{\{\sigma^{(t)}\}^2}\sum_{i=1}^{\gamma}w_i\left(\mathbf{x}\_{i:\lambda}^{(t+1)}-\boldsymbol{\mu}^{(t)}\right)\left(\mathbf{x}\_{i:\lambda}^{(t+1)}-\boldsymbol{\mu}^{(t)}\right)^\text{T} \\\\ &=(1-\alpha_\gamma)\boldsymbol{\Sigma}^{(t)}+\alpha_\gamma\sum_{i=1}^{\gamma}w_i\mathbf{y}\_{i:\lambda}^{(t+1)}{\mathbf{y}\_{i:\lambda}^{(t+1)}}^\text{T},\label{eq:rlmu.2}
\end{align}
where
- $\alpha_\gamma\leq 1$: learning rate.
- $w_1,\ldots,w_\gamma$ and $\mathbf{x}\_{1:\lambda}^{(t+1)},\ldots,\mathbf{x}\_{\lambda:\lambda}^{(g+1)}$ are defined as usual.
- $\mathbf{y}\_{i:\lambda}^{(t+1)}=(\mathbf{x}\_{i:\lambda}^{(t+1)}-\boldsymbol{\mu}^{(t)})/\sigma^{(t)}$.

The update \eqref{eq:rlmu.2} can be generalized to $\lambda$ weights values which neither necessarily sum to $1$, nor be non-negative anymore, as
\begin{align}
\boldsymbol{\Sigma}^{(t+1)}&=\left(1-\alpha_\gamma\sum_{i=1}^{\lambda}w_i\right)\boldsymbol{\Sigma}^{(t)}+\alpha_\gamma\sum_{i=1}^{\lambda}w_i\mathbf{y}\_{i:\lambda}^{(t+1)}{\mathbf{y}\_{i:\lambda}^{(t+1)}}^\text{T}\label{eq:rlmu.3} \\\\ &={\boldsymbol{\Sigma}^{(t)}}^{1/2}\left[\mathbf{I}+\alpha_\gamma\sum_{i=1}^{\lambda}w_i\left(\mathbf{z}\_{i:\lambda}^{(t+1)}{\mathbf{z}\_{i:\lambda}^{(t+1)}}^\text{T}-\mathbf{I}\right)\right]{\boldsymbol{\Sigma}^{(t)}}^{1/2},
\end{align}
where
- $w_1\geq\ldots\geq w_\gamma>0\geq w_{\gamma+1}\geq\ldots\geq w_\lambda\in\mathbb{R}$, and usually $\sum_{i=1}^{\gamma}w_i=1$ and $\sum_{i=1}^{\lambda}w_i\approx 0$.
- $\mathbf{z}\_{i:\lambda}^{(t+1)}={\boldsymbol{\Sigma}^{(t)}}^{1/2}\mathbf{y}\_{i:\lambda}^{(t+1)}$ is the mutation vector.

### Rank-one update
{: #rank-one-update}
We first consider a method that produces an $n$-dimensional normal distribution with zero mean. Specifically, let $\mathbf{y}\_1,\ldots,\mathbf{y}\_{t_0}\in\mathbb{R}^n$, for $t_0\geq n$ be vectors span $\mathbb{R}^n$. We thus have that
\begin{align}
\mathcal{N}(0,1)\mathbf{y}\_1+\ldots+\mathcal{N}(0,1)\mathbf{y}\_{t_0}&\sim\mathcal{N}(\mathbf{0},\mathbf{y}\_1\mathbf{y}\_1^\text{T})+\ldots+\mathcal{N}(\mathbf{0},\mathbf{y}\_{t_0}\mathbf{y}\_{t_0}^\text{T}) \\\\ &\sim\mathcal{N}\left(\mathbf{0},\sum_{i=1}^{t_0}\mathbf{y}\_i\mathbf{y}\_i^\text{T}\right)
\end{align}
The covariance matrix $\mathbf{y}\_i\mathbf{y}\_i^\text{T}$ has rank one, with only one eigenvalue $\Vert\mathbf{y}\_i\Vert^2$ and a corresponding eigenvector within the form $\alpha\mathbf{y}\_i$ for $\alpha\in\mathbb{R}$. Using the above equation, we can generate any MVN distribution.

Consider the update \eqref{eq:rlmu.3} with $\gamma=1$ and let $\mathbf{y}\_{t+1}=\left(\mathbf{x}\_{1:\lambda}^{(t+1)}-\boldsymbol{\mu}^{(t)}\right)/\sigma^{(t)}$, the **rank-one update** for the covariance matrix $\boldsymbol{\Sigma}^{(t+1)}$ is given by
\begin{equation}
\boldsymbol{\Sigma}^{t+1}=(1-\alpha_1)\boldsymbol{\Sigma}^{(t)}+\alpha_1\mathbf{y}\_{t+1}\mathbf{y}\_{t+1}^\text{T}
\end{equation}
The latter summand in the RHS has rank one and adds the maximum likelihood term for $\mathbf{y}\_{t+1}$ into the covariance matrix $\boldsymbol{\Sigma}^{(t)}$, which makes the probability of generating $\mathbf{y}\_{t+1}$ in the generation $t+1$ increase.

We continue by noticing that to update the covariance matrix $\boldsymbol{\Sigma}^{(t+1)}$, in \eqref{eq:rlmu.3}, we have used the selected steps
\begin{equation}
\mathbf{y}\_{i:\lambda}^{(g+1)}=\frac{\mathbf{x}\_{i:\lambda}^{(g+1)}-\boldsymbol{\mu}^{(g)}}{\sigma^{(g)}}
\end{equation}
However, since
\begin{equation}
\mathbf{y}\_{i:\lambda}^{(g+1)}{\mathbf{y}\_{i:\lambda}^{(g+1)}}^\text{T}=-\mathbf{y}\_{i:\lambda}^{(g+1)}\left(-\mathbf{y}\_{i:\lambda}^{(g+1)}\right)^\text{T},
\end{equation}
which means the sign information is lost when computing the covariance matrix. To track the sign information to the update rule of $\boldsymbol{\Sigma}^{(t+1)}$, we use **evolution path**, which defined as a sequence of successive steps over number of generations.

In particular, analogy to \eqref{eq:rlmu.3}, we use exponential smoothing to establish the evolution path, $\mathbf{p}\_c\in\mathbb{R}^n$, which starting with an initial value $\mathbf{p}\_c^{(0)}=\mathbf{0}$ and being updated with
\begin{align}
\mathbf{p}\_c^{(t+1)}&=(1-\alpha_c)\mathbf{p}\_c^{(g)}+\alpha_c\sum_{i=1}^{\gamma}w_i\mathbf{y}\_{i:\lambda}^{(t+1)} \\\\ &=(1-\alpha_c)\mathbf{p}\_c^{(g)}+\alpha_c\sum_{i=1}^{\gamma}w_i\frac{\mathbf{x}\_{i:\lambda}^{(t+1)}-\boldsymbol{\mu}^{(t)}}{\sigma^{(t)}} \\\\ &=(1-\alpha_c)\mathbf{p}\_c^{(g)}+\sqrt{\alpha_c(2-\alpha_c)\gamma_\text{eff}}\frac{\boldsymbol{\mu}^{(t+1)}-\boldsymbol{\mu}^{(t)}}{\sigma^{(t)}},
\end{align}
where
- $\alpha_c\leq 1$ is the learning rate.
- $\sqrt{\alpha_c(2-\alpha_c)\gamma_\text{eff}}$ is a normalization factor for $\mathbf{p}\_c^{(t+1)}$.

The rank-one update for the covariance matrix $\boldsymbol{\Sigma}^{(t)}$ via the evolution path $\mathbf{p}\_c^{(t+1)}$ then given as
\begin{equation}
\boldsymbol{\Sigma}^{(t+1)}=(1-\alpha_1)\boldsymbol{\Sigma}^{(t)}+\alpha_1\mathbf{p}\_c^{(t+1)}{\mathbf{p}\_c^{(t+1)}}^\text{T},\label{eq:rou.1}
\end{equation}
An empirical validated choice for the learning rate $\alpha_1$ is $\alpha_1\approx 2/n^2$.

### Final update
{: #final-update}
Combining rank-$\gamma$ update \eqref{eq:rlmu.3} and rank-one update \eqref{eq:rou.1} together, we obtain the final update for the covariance matrix $\boldsymbol{\Sigma}^{(t+1)}$ as
\begin{equation}
\boldsymbol{\Sigma}^{(t+1)}=\left(1-\alpha_1-\alpha_\gamma\sum_{i=1}^{\lambda}w_i\right)\boldsymbol{\Sigma}^{(t)}+\alpha_1\mathbf{p}\_c^{(t+1)}{\mathbf{p}\_c^{(t+1)}}^\text{T}+\alpha_\gamma\sum_{i=1}^{\lambda}w_i\mathbf{y}\_{i:\lambda}^{(t+1)}{\mathbf{y}\_{i:\lambda}^{(t+1)}}^\text{T},
\end{equation}
where
- $\alpha_1\approx 2/n^2$.
- $\alpha_\gamma\approx\min(\gamma_\text{eff}/n^2,1-\alpha_1)$.
- $\mathbf{y}\_{i:\lambda}^{(t+1)}=\left(\mathbf{x}\_{i:\lambda}^{(t+1)}-\boldsymbol{\mu}^{(t)}\right)/\sigma^{(t)}$.
- $\sum_{i=1}^{\lambda}w_i\approx-\alpha_1/\alpha_\gamma$.

## Controlling the step-size
{: #ctrl-sigma}

## References
{: #references}
[1] Nikolaus Hansen. [The CMA Evolution Strategy: A Tutorial](#https://arxiv.org/abs/1604.00772). 

## Footnotes
{: #footnotes}

[^1]: The simplest form of **exponential smoothing** is given by the formula
	\begin{align\*}
	s_0&=x_0 \\\\ s_t&=\alpha x_t+(1-\alpha)s_{t-1},\hspace{1cm}t>0
	\end{align\*}
	where $0<\alpha<1$ is referred as the **smoothing factor**.