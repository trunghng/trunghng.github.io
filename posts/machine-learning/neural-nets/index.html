<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Neural networks | Trung's Place</title><meta name=keywords content="machine-learning,neural-network"><meta name=description content="
Notes on Neural networks.
"><meta name=author content="Trung H. Nguyen"><link rel=canonical href=https://trunghng.github.io/posts/machine-learning/neural-nets/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.bc1149f4a72aa4858d3a9f71462f75e5884ffe8073ea9d6d5761d5663d651e20.css integrity="sha256-vBFJ9KcqpIWNOp9xRi915YhP/oBz6p1tV2HVZj1lHiA=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://trunghng.github.io/images/favicon/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://trunghng.github.io/images/favicon/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://trunghng.github.io/images/favicon/favicon-32x32.png><link rel=apple-touch-icon href=https://trunghng.github.io/images/favicon/apple-touch-icon.png><link rel=mask-icon href=https://trunghng.github.io/images/favicon/android-chrome-512x512.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=text/x-mathjax-config>
  MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": {availableFonts: []}
  });
</script><script type=text/x-mathjax-config>
    MathJax.Hub.Config({
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
      "HTML-CSS": {availableFonts: []},
      TeX: {
        equationNumbers: { autoNumber: "AMS" },
      },
    });
  </script><script type=text/javascript src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><style>.post-content{text-align:justify;font-size:15px}.post-content h1,h2,h3,h4,h5,h6{text-align:left}.post-content a{text-decoration:none}.post-content ol,.post-content ul{margin-left:10px}.post-content li>ol,.post-content li>ul{margin-left:30px}#roman-list,#number-list{counter-reset:section}#roman-list,#number-list>li{list-style:none;position:relative}#roman-list>li:before{counter-increment:section;content:"(" counter(section,lower-roman)") ";position:absolute;left:-.75em}#number-list>li:before{counter-increment:section;content:"(" counter(section,decimal)") ";position:absolute;left:-2em}figcaption{font-size:14px}.toc{font-size:15px}.post-footer{font-size:15px}.post-content figure>figcaption{all:revert;font-size:12px;width:70%;text-align:center;margin-left:15%}.post-content figure>figcaption>p{all:revert}</style><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="Neural networks"><meta property="og:description" content="
Notes on Neural networks.
"><meta property="og:type" content="article"><meta property="og:url" content="https://trunghng.github.io/posts/machine-learning/neural-nets/"><meta property="og:image" content="https://trunghng.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-09-02T13:00:00+07:00"><meta property="article:modified_time" content="2022-09-02T13:00:00+07:00"><meta property="og:site_name" content="Trung's Place"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://trunghng.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Neural networks"><meta name=twitter:description content="
Notes on Neural networks.
"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://trunghng.github.io/posts/"},{"@type":"ListItem","position":3,"name":"Neural networks","item":"https://trunghng.github.io/posts/machine-learning/neural-nets/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Neural networks","name":"Neural networks","description":" Notes on Neural networks.\n","keywords":["machine-learning","neural-network"],"articleBody":" Notes on Neural networks.\nFeed-forward network functions Recall that the linear models used in regression and classification are based on linear combination of fixed nonlinear basis function $\\phi_j(\\mathbf{x})$ and take the form \\begin{equation} y(\\mathbf{x},\\mathbf{w})=f\\left(\\sum_{j=1}^{M}w_j\\phi_j(\\mathbf{x})\\right),\\label{1} \\end{equation} where in the case of regression, $f$ is the function $f(x)=x$, while in the classification case, $f$ takes the form of a nonlinear activation function (e.g., the sigmoid function).\nNeural networks extend this model \\eqref{1} by letting each basis functions $\\phi_j(\\mathbf{x})$ be a nonlinear function of a linear combination of the inputs, where the coefficients in the combination are the adaptive parameters.\nMore formally, neural networks is a series of layers, in which each layer represents a functional transformation. Let us consider the first layer by constructing $M$ linear combinations of the input variable $x_1,\\ldots,x_D$ in the form \\begin{equation} a_j=\\sum_{i=1}^{D}w_{ji}^{(1)}x_i+w_{j0}^{(1)},\\label{2} \\end{equation} where\n$j=1,\\ldots,M$; the superscript $^{(1)}$ indicates that we are working with parameters of the first layer; $w_{ji}^{(1)}$’s are called the weights; $w_{j0}^{(1)}$’s are known as the biases; $a_j$’s are referred as activations. The activations $a_j$’s are then transformed using a differentiable, nonlinear activation function $h(\\cdot)$, which correspond to $f(\\cdot)$ in \\eqref{1} to give \\begin{equation} z_j=h(a_j),\\label{3} \\end{equation} where $z_j$ are called the hidden units. Repeating the same procedure as \\eqref{2}, which was following \\eqref{1}, $z_j$’s are taken as the inputs of the second layer to give $K$ outputs \\begin{equation} a_k=\\sum_{j=1}^{M}w_{kj}^{(2)}z_j+w_{k0}^{(2)},\\label{4} \\end{equation} where $k=1,\\ldots,K$.\nThis process will be repeated in $L$ times with $L$ is the number of layers. At the last layer, for instance, the second layer of our example network, the outputs, also called output unit activations, $a_k$’s are transformed using an appropriate activation function to give a set of network output $y_k$. For example, in multiple binary classification problems, we can choose the logistic sigmoid as our activation function that \\begin{equation} y_k=\\sigma(a_k)\\label{5} \\end{equation} Combining all these steps \\eqref{2}, \\eqref{3}, \\eqref{4} and \\eqref{5} together, our neural network with sigmoidal output unit activation functions can be defined as \\begin{equation} y_k(\\mathbf{x},\\mathbf{w})=\\sigma\\left(\\sum_{j=1}^{M}w_{kj}^{(2)}h\\left(\\sum_{i=1}^{D}w_{ji}^{(1)}x_i+w_{j0}^{(1)}\\right)+w_{k0}^{(2)}\\right),\\label{6} \\end{equation} where all of the weights and biases are comprises together into a parameter vector $\\mathbf{w}$. As suggested in linear regression, we can also let the bias $w_{j0}^{(1)}$ be coefficient of a dummy input variable $x_0=1$ that makes \\eqref{2} can be written as \\begin{equation} a_j=\\sum_{i=0}^{D}w_{ji}^{(1)}x_i \\end{equation} This results that our subsequent layers are also able to be written in a more convenient form, which lets the entire network \\eqref{6} take the form \\begin{equation} y_k(\\mathbf{x},\\mathbf{w})=\\sigma\\left(\\sum_{j=0}^{M}w_{kj}^{(2)}h\\left(\\sum_{i=0}^{D}w_{ji}^{(1)}x_i\\right)\\right) \\end{equation} Our network is also an example of a multilayer perception, or MLP, which is a combination of perceptron models. The key difference is that while the neural network uses continuous sigmoidal nonlinearities in the hidden units, which is differentiable w.r.t the parameters, the perceptron algorithm uses step-function nonlinearities, which is in contrast non-differentiable.\nThe network network we have been considering so far is feed-forward neural network, whose outputs are deterministic functions of the inputs. Each (hidden or output) unit in such a network computes a function given by \\begin{equation} z_k=h\\left(\\sum_{j}w_{kj}z_j\\right), \\end{equation} where the sum runs all over units sending connections to unit $k$ (bias included).\nUniversal approximation property Feed-forward networks with hidden layers (i.e., the layers in which the training data does not show the desired output, e.g., the first layer of our network, the second layer on the other hands is called the output layer) provide universal approximation property.\nIn concrete, the universal approximation theorem states that a feedforward network with a linear output layer and at least one hidden layer with any squashing activation function (e.g., the logistic sigmoid function) an approximate any continuous function on a compact subsets of $\\mathbb{R}^n$.\nWeight-space symmetries Network training Network outputs probabilistic interpretation Univariate regression Consider the regression problem in which the target variable $t$ has Gaussian distribution with an $\\mathbf{x}$ dependent mean \\begin{equation} p(t\\vert\\mathbf{x},\\mathbf{w})=\\mathcal{N}(t\\vert y(\\mathbf{x},\\mathbf{w}),\\beta^{-1}), \\end{equation} For the conditional distribution above, it is sufficient to take the output unit activation function to be the function $h(x)=x$, because such a network can approximate any continuous function from $\\mathbf{x}$ to $y$.\nGiven the data set $(\\mathbf{X},\\mathbf{t})=\\{\\mathbf{x}_n,t_n\\}$, where $\\mathbf{x}_n$’s are i.i.d for $n=1,\\ldots,N$, and where \\begin{align} \\mathbf{X}=\\left[\\begin{matrix}\\vert\u0026\u0026\\vert \\\\ \\mathbf{x}_1\u0026\\ldots\u0026\\mathbf{x}_N \\\\ \\vert\u0026\u0026\\vert\\end{matrix}\\right],\\hspace{1cm}\\mathbf{t}=\\left[\\begin{matrix}t_1 \\\\ \\vdots \\\\ t_N\\end{matrix}\\right] \\end{align} The likelihood function therefore can be given by \\begin{align} p(t\\vert\\mathbf{X},\\mathbf{w},\\beta)\u0026=\\prod_{n=1}^{N}p(t_n\\vert\\mathbf{x}_n,\\mathbf{w},\\beta) \\\\ \u0026=\\prod_{n=1}^{N}\\mathcal{N}(t_n\\vert y(\\mathbf{x}_n,\\mathbf{w}),\\beta^{-1}) \\end{align} With a minor change as usual that taking negative natural logarithm of both sides gives us \\begin{align} -\\log p(\\mathbf{t}\\vert\\mathbf{X},\\mathbf{w},\\beta)\u0026=-\\sum_{n=1}^{N}\\log\\mathcal{N}(t_n\\vert y(\\mathbf{x}_n,\\mathbf{w}),\\beta^{-1}) \\\\ \u0026=\\frac{\\beta}{2}\\sum_{n=1}^{N}\\big(y(\\mathbf{x}_n,\\mathbf{w})-t_n\\big)^2-\\frac{N}{2}\\log\\beta+\\frac{N}{2}\\log 2\\pi \\end{align} Therefore, maximizing the likelihood function $p(\\mathbf{t}\\vert\\mathbf{X},\\mathbf{x},\\beta)$ is equivalent to minimizing the sum-of-squares error function given as \\begin{equation} E(\\mathbf{w})=\\frac{1}{2}\\sum_{n=1}^{N}\\big(y(\\mathbf{x}_n,\\mathbf{w})-t_n\\big)^2, \\end{equation} This also means the value of $\\mathbf{w}$ that minimizes $E(\\mathbf{w})$ will be $\\mathbf{w}_\\text{ML}$, which implies that the corresponding solution for $\\beta$ will be given by \\begin{equation} \\frac{1}{\\beta_\\text{ML}}=\\frac{1}{N}\\sum_{n=1}^{N}\\big(y(\\mathbf{x}_n,\\mathbf{w}_\\text{ML})-t_n\\big)^2 \\end{equation}\nMultivariate regression Similarly, we consider the multiple target variables case, in which the conditional distribution of the target therefore takes the form \\begin{equation} p(\\mathbf{t}\\vert\\mathbf{x},\\mathbf{w},\\beta)=\\mathcal{N}(\\mathbf{t}\\vert\\mathbf{y}(\\mathbf{x},\\mathbf{w}),\\beta^{-1}\\mathbf{I}) \\end{equation} Repeating the same procedure as the univariate case, maximizing likelihood function is also equivalent to minimizing the sum-of-squares error function given by \\begin{equation} E(\\mathbf{w})=\\frac{1}{2}\\sum_{n=1}^{N}\\big\\Vert\\mathbf{y}(\\mathbf{x}_n,\\mathbf{w})-\\mathbf{t}_n\\big\\Vert^2, \\end{equation} which gives us the solution for the noise precision $\\beta$ in the multivariate case as \\begin{equation} \\frac{1}{\\beta_\\text{ML}}=\\frac{1}{NK}\\sum_{n=1}^{N}\\big\\Vert\\mathbf{y}(\\mathbf{x}_n,\\mathbf{w}_\\text{ML})-\\mathbf{t}_n\\big\\Vert^2, \\end{equation} where $K$ is the number of target variables.\nBinary classification Consider the problem of binary classification which outputs $t=1$ to denote class $\\mathcal{C}_1$ and otherwise to denote class $\\mathcal{C}_2$.\nIn particular, we consider a network having a single output whose activation function is a logistic sigmoid \\begin{equation} y=\\sigma(a)\\doteq\\frac{1}{1+\\exp(-a)}, \\end{equation} which follows immediately that $0\\leq y(\\mathbf{x},\\mathbf{w})\\leq 1$.\nThis suggests us interpreting $y(\\mathbf{x},\\mathbf{w})$ as the conditional probability for class $\\mathcal{C}_1$, $p(\\mathcal{C}_1\\vert\\mathbf{x})$, and hence the corresponding conditional probability for class $\\mathcal{C}_2$ will be $p(\\mathcal{C}_2\\vert\\mathbf{x})=1-y(\\mathbf{x},\\mathbf{w})$. Or in other words, the conditional distribution $p(t\\vert\\mathbf{x},\\mathbf{w})$ of targets $t$ given inputs $\\mathbf{x}$ is then a Bernoulli distribution of the form \\begin{equation} p(t\\vert\\mathbf{x},\\mathbf{w})=y(\\mathbf{x},\\mathbf{w})^t\\big(1-y(\\mathbf{x},\\mathbf{w})\\big)^{1-t} \\end{equation} If we consider a training set of $N$ independent observations as in the two regression tasks above, the likelihood function of our classification task will be given as \\begin{align} p(\\mathbf{t}\\vert\\mathbf{X},\\mathbf{w})\u0026=\\prod_{n=1}^{N}p(t_n\\vert\\mathbf{x}_n,\\mathbf{w}) \\\\ \u0026=\\prod_{n=1}^{N}y(\\mathbf{x}_n,\\mathbf{w})^{t_n}\\big(1-y(\\mathbf{x}_n,\\mathbf{w})\\big)^{1-t_n} \\end{align} Taking the negative natural logarithm of the likelihood as above gives us the cross-entropy error function \\begin{align} E(\\mathbf{w})=-\\log p(\\mathbf{t}\\vert\\mathbf{X},\\mathbf{w})\u0026=-\\log\\prod_{n=1}^{N}y(\\mathbf{x}_n,\\mathbf{w})^{t_n}\\big(1-y(\\mathbf{x}_n,\\mathbf{w})\\big)^{1-t_n} \\\\ \u0026=-\\sum_{n=1}^{N}t_n\\log y_n+(1-t_n)\\log(1-y_n), \\end{align} where $y_n=y(\\mathbf{x}_n,\\mathbf{w})$.\nMoreover, consider the partial derivative of this error function w.r.t the activation $a_i$, corresponding to a particular data point $i$, we have \\begin{align} \\frac{\\partial E(\\mathbf{w})}{\\partial a_i}\u0026=\\frac{\\partial}{\\partial a_i}-\\sum_{n=1}^{N}t_n\\log y_n+(1-t_n)\\log(1-y_n) \\\\ \u0026=-\\frac{t_i}{y_i}\\frac{\\partial y_i}{\\partial a_i}-\\frac{1-t_i}{1-y_i}\\frac{\\partial(1-y_i)}{\\partial a_i} \\\\ \u0026=\\frac{\\partial y_i}{\\partial a_i}\\left(\\frac{1-t_i}{1-y_i}-\\frac{t_i}{y_i}\\right) \\\\ \u0026=y_i(1-y_i)\\left(\\frac{1-t_i}{1-y_i}-\\frac{t_i}{y_i}\\right) \\\\ \u0026=y_i-t_i,\\label{eq:bin-clf-drv-error-a} \\end{align} where in the forth step, we have use the identity of the derivative of sigmoid function that \\begin{equation} \\frac{d\\sigma}{d a}=\\sigma(1-\\sigma) \\end{equation}\nMulti-class classification For the multi-class classification that assigns input variables to $K$ separated classes, we can use the network with $K$ outputs each of which has a logistic sigmoid activation function. Each output $t_k\\in\\{0,1\\}$ for $k=1,\\ldots,K$ indicates whether the input will be assigned to class $\\mathcal{C}_k$\nWe first consider the case that the class labels are independent given the input vector, which means the conditional distributions for class $C_k$’s will be $K$ i.i.d Bernoulli distributions, in which the conditional probability for class $\\mathcal{C}_k$ will take the form \\begin{equation} p(\\mathcal{C}_k\\vert\\mathbf{x},\\mathbf{w})=y_k(\\mathbf{x},\\mathbf{w})^{t_k}\\big(1-y_k(\\mathbf{x},\\mathbf{w})\\big)^{1-t_k} \\end{equation} Therefore, the joint distribution of them, the conditional distribution of the target variables will be given as \\begin{align} p(\\mathbf{t}\\vert\\mathbf{x},\\mathbf{w})\u0026=\\prod_{k=1}^{K}p(\\mathcal{C}_k\\vert\\mathbf{x},\\mathbf{w}) \\\\ \u0026=\\prod_{k=1}^{K}y_k(\\mathbf{x},\\mathbf{w})^{t_k}\\big(1-y_k(\\mathbf{x},\\mathbf{w})\\big)^{1-t_k} \\end{align} Let $\\mathbf{T}$ denote the combination of all the targets $\\mathbf{t}_n$, i.e., \\begin{equation} \\mathbf{T}=\\left[\\begin{matrix}-\\hspace{0.15cm}\\mathbf{t}_1^\\text{T}\\hspace{0.15cm}- \\\\ \\vdots \\\\ -\\hspace{0.15cm}\\mathbf{t}_N^\\text{T}\\hspace{0.15cm}-\\end{matrix}\\right], \\end{equation} the likelihood function therefore takes the form of \\begin{align} p(\\mathbf{T}\\vert\\mathbf{X},\\mathbf{w})\u0026=\\prod_{n=1}^{N}p(\\mathbf{t}_n\\vert\\mathbf{x}_n,\\mathbf{w}) \\\\ \u0026=\\prod_{n=1}^{N}\\prod_{k=1}^{K}y_k(\\mathbf{x}_n,\\mathbf{w})^{t_k}\\big(1-y_k(\\mathbf{x}_n,\\mathbf{w})\\big)^{1-t_k}\\label{eq:mult-clf-llh} \\end{align} Analogy to the binary case, taking the negative natural logarithm of the likelihood \\eqref{eq:mult-clf-llh} gives us the corresponding cross-entropy error function for the multi-class case, given as \\begin{align} E(\\mathbf{w})=-\\log p(\\mathbf{T}\\vert\\mathbf{X},\\mathbf{w})\u0026=-\\log\\prod_{n=1}^{N}\\prod_{k=1}^{K}y_k(\\mathbf{x}_n,\\mathbf{w})^{t_{nk}}\\big(1-y_k(\\mathbf{x}_n,\\mathbf{w})\\big)^{1-t_{nk}} \\\\ \u0026=-\\sum_{n=1}^{N}\\sum_{k=1}^{K}t_{nk}\\log y_{nk}+(1-t_{nk})\\log(1-y_{nk}),\\label{eq:mult-clf-error} \\end{align} where $y_{nk}$ is short for $y_k(\\mathbf{x}_n,\\mathbf{w})$.\nSimilar to the binary case, consider the partial derivative of the error function \\eqref{eq:mult-clf-error} w.r.t to the activation for a particular output unit $a_{ij}$, corresponding to a particular data point $i$, we have \\begin{align} \\frac{\\partial E(\\mathbf{w})}{\\partial a_{ij}}\u0026=\\frac{\\partial}{\\partial a_{ij}}-\\sum_{n=1}^{N}\\sum_{k=1}^{K}t_{nk}\\log y_{nk}+(1-t_{nk})\\log(1-y_{nk}) \\\\ \u0026=\\left(\\frac{1-t_{ij}}{1-y_{ij}}-\\frac{t_{ij}}{y_{ij}}\\right)\\frac{\\partial y_{ij}}{\\partial a_{ij}} \\\\ \u0026=\\left(\\frac{1-t_{ij}}{1-y_{ij}}-\\frac{t_{ij}}{y_{ij}}\\right)y_{ij}(1-y_{ij}) \\\\ \u0026=y_{ij}-t_{ij}\\label{eq:mult-drv-error-a} \\end{align} which takes the same form as \\eqref{eq:bin-clf-drv-error-a}\nOn the other hands, if each input is assigned only to one of $K$ classes (mutually exclusive), the conditional distributions for class $C_k$ will be instead given as \\begin{equation} p(\\mathcal{C}_k\\vert\\mathbf{x})=p(t_k=1\\vert\\mathbf{x})=y_k(\\mathbf{x},\\mathbf{w}), \\end{equation} and thus the conditional distribution of the targets is \\begin{equation} p(\\mathbf{t}\\vert\\mathbf{x},\\mathbf{w})=\\prod_{k=1}^{K}p(t_k=1\\vert\\mathbf{x})^{t_k}=\\prod_{k=1}^{K}y_k(\\mathbf{x},\\mathbf{w})^{t_k} \\end{equation} The likelihood is therefore given as \\begin{equation} p(\\mathbf{T}\\vert\\mathbf{X},\\mathbf{w})=\\prod_{n=1}^{N}p(\\mathbf{t}_n\\vert\\mathbf{x}_n,\\mathbf{w})=\\prod_{n=1}^{N}\\prod_{k=1}^{K}y_k(\\mathbf{x}_n,\\mathbf{w})^{t_{nk}}, \\end{equation} which gives us the following cross-entropy error function by taking the negative natural logarithm \\begin{align} E(\\mathbf{w})=-\\log p(\\mathbf{T}\\vert\\mathbf{X},\\mathbf{w})\u0026=-\\log\\prod_{n=1}^{N}\\prod_{k=1}^{K}y_k(\\mathbf{x},\\mathbf{w})^{t_{nk}} \\\\ \u0026=-\\sum_{n=1}^{N}\\sum_{k=1}^{K}t_{nk}\\log y_k(\\mathbf{x}_n,\\mathbf{w})\\label{eq:mult-me-clf-error} \\end{align} As discussed in Softmax regression, we see that the output unit activation function is given by the softmax function \\begin{equation} y_k(\\mathbf{x},\\mathbf{w})=\\frac{\\exp\\big[a_k(\\mathbf{x},\\mathbf{w})\\big]}{\\sum_{j=1}^{K}\\exp\\big[a_j(\\mathbf{x},\\mathbf{w})\\big]} \\end{equation} Taking the derivative of the error function \\eqref{eq:mult-me-clf-error} w.r.t to the activation for a particular output unit $a_{ij}$, corresponding to a particular data point $i$, we have \\begin{align} \\frac{\\partial E(\\mathbf{w})}{\\partial a_{ij}}\u0026=\\frac{\\partial}{\\partial a_{ij}}-\\sum_{n=1}^{N}\\sum_{k=1}^{K}t_{nk}\\log y_{nk} \\\\ \u0026=-\\sum_{k=1}^{K}\\frac{t_{ik}}{y_{ik}}\\frac{\\partial y_{ik}}{\\partial a_{ij}} \\\\ \u0026=-\\sum_{k=1}^{K}\\frac{t_{ik}}{y_{ik}}y_{ik}(1\\{j=k\\}-y_{ij})\\label{53} \\\\ \u0026=y_{ij}\\sum_{k=1}^{K}t_{ik}-\\sum_{k=1}^{K}t_{ik}1\\{j=k\\} \\\\ \u0026=y_{ij}-t_{ij} \\end{align} where we have used the identity of the derivative of the softmax function in the forth step to obtain \\eqref{53}.\nParameter optimization In training neural network to find a value of $\\mathbf{w}$ to minimize the error function $E(\\mathbf{w})$, we usually start with some initial value $\\mathbf{w}_0$ and iteratively update the weight vector $\\mathbf{w}$, in which the weight at time step $\\tau+1$ is given as \\begin{equation} \\mathbf{w}^{(t+1)}=\\mathbf{w}^{(\\tau)}+\\Delta\\mathbf{w}^{(\\tau)}, \\end{equation} where $\\Delta\\mathbf{w}^{(\\tau)}$ is some update rule.\nAt each time step $\\tau$, there are two distinct stages:\nStage 1 refers to evaluating the derivatives of the error function w.r.t the weights, which can be accomplished efficiently using backpropagation that will be discussed in the next section. Stage 2 relates to using those computed derivatives to calculate the adjustments to be made to the weights $\\mathbf{w}$. Gradient descent, for instance, is the simplest approach in which each time step the weights take a small step in the direction of the negative gradient, as \\begin{equation} \\mathbf{w}^{(\\tau+1)}=\\mathbf{w}^{(\\tau)}-\\eta\\nabla_\\mathbf{w}E(\\mathbf{w}^{(\\tau)}), \\end{equation} where $\\eta\u003e0$ is called the learning rate of the update. Backpropagation In this section, we will consider the use of backpropagation technique to evaluate the first and second derivatives of error-functions w.r.t the weights and also the derivatives of the network outputs w.r.t the inputs.\nError-function derivatives We first consider the case of evaluating the first order derivative of the error function w.r.t to the weight parameter $\\mathbf{w}$.\nConsider a simple linear model where the outputs $y_k$’s are linear combinations of the input variable $x_i$’s \\begin{equation} y_k=\\sum_{i}w_{ki}x_i, \\end{equation} together with the error function, in which the error function for the $n$ data point is defined as \\begin{equation} E_n(\\mathbf{w})=\\frac{1}{2}\\sum_{k}(y_{nk}-t_{nk})^2, \\end{equation} where $y_{nk}=y_k(\\mathbf{x}_n,\\mathbf{w})$.\nThe gradient of this error function w.r.t to a weight $w_{ji}$ then can be computed by \\begin{equation} \\frac{\\partial E_n}{\\partial w_{ji}}=(y_{nj}-t_{nj})x_{ni} \\end{equation} In a general feed-forward network, each unit is a weighted sum of its inputs \\begin{equation} a_j=\\sum_{i}w_{ji}z_i \\end{equation}\nJacobian matrix Hessian matrix Bayesian neural networks Posterior parameter distribution Preferences [1] Christopher M. Bishop. Pattern Recognition and Machine Learning. Springer New York, NY, 2006.\n[2] Ian Goodfellow \u0026 Yoshua Bengio \u0026 Aaron Courville. Deep Learning. MIT Press, 2016.\nFootnotes","wordCount":"1789","inLanguage":"en","datePublished":"2022-09-02T13:00:00+07:00","dateModified":"2022-09-02T13:00:00+07:00","author":{"@type":"Person","name":"Trung H. Nguyen"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://trunghng.github.io/posts/machine-learning/neural-nets/"},"publisher":{"@type":"Organization","name":"Trung's Place","logo":{"@type":"ImageObject","url":"https://trunghng.github.io/images/favicon/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://trunghng.github.io accesskey=h title="Trung's Place (Alt + H)"><img src=https://trunghng.github.io/apple-touch-icon.png alt aria-label=logo height=35>Trung's Place</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://trunghng.github.io/ title=Posts><span>Posts</span></a></li><li><a href=https://trunghng.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://trunghng.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://trunghng.github.io/about/ title=About><span>About</span></a></li><li><a href=https://trunghng.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Neural networks</h1><div class=post-meta><span title='2022-09-02 13:00:00 +0700 +0700'>September 2, 2022</span>&nbsp;·&nbsp;9 min&nbsp;·&nbsp;Trung H. Nguyen</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#ff-func>Feed-forward network functions</a><ul><li><a href=#unv-approx>Universal approximation property</a></li><li><a href=#w-s-sym>Weight-space symmetries</a></li></ul></li><li><a href=#net-training>Network training</a><ul><li><a href=#output-prob-itp>Network outputs probabilistic interpretation</a><ul><li><a href=#univ-output>Univariate regression</a></li><li><a href=#mult-output>Multivariate regression</a></li><li><a href=#bi-clf>Binary classification</a></li><li><a href=#mult-clf>Multi-class classification</a></li></ul></li><li><a href=#param-opt>Parameter optimization</a></li><li><a href=#backprop>Backpropagation</a><ul><li><a href=#erf-drv>Error-function derivatives</a></li><li><a href=#jacobian-mtx>Jacobian matrix</a></li><li><a href=#hessian-mtx>Hessian matrix</a></li></ul></li></ul></li><li><a href=#bayes-nn>Bayesian neural networks</a><ul><li><a href=#posterior-param-dist>Posterior parameter distribution</a></li></ul></li><li><a href=#preferences>Preferences</a></li><li><a href=#footnotes>Footnotes</a></li></ul></nav></div></details></div><div class=post-content><blockquote><p>Notes on Neural networks.</p></blockquote><h2 id=ff-func>Feed-forward network functions<a hidden class=anchor aria-hidden=true href=#ff-func>#</a></h2><p>Recall that the <a href=https://trunghng.github.io/posts/machine-learning/glm/>linear models</a> used in regression and classification are based on linear combination of fixed nonlinear basis function $\phi_j(\mathbf{x})$ and take the form
\begin{equation}
y(\mathbf{x},\mathbf{w})=f\left(\sum_{j=1}^{M}w_j\phi_j(\mathbf{x})\right),\label{1}
\end{equation}
where in the case of regression, $f$ is the function $f(x)=x$, while in the classification case, $f$ takes the form of a nonlinear activation function (e.g., the <a href=https://trunghng.github.io/posts/machine-learning/glm/#logistic-sigmoid-func>sigmoid function</a>).</p><p><strong>Neural networks</strong> extend this model \eqref{1} by letting each basis functions $\phi_j(\mathbf{x})$ be a nonlinear function of a linear combination of the inputs, where the coefficients in the combination are the adaptive parameters.</p><p>More formally, neural networks is a series of layers, in which each layer represents a functional transformation. Let us consider the first layer by constructing $M$ linear combinations of the input variable $x_1,\ldots,x_D$ in the form
\begin{equation}
a_j=\sum_{i=1}^{D}w_{ji}^{(1)}x_i+w_{j0}^{(1)},\label{2}
\end{equation}
where</p><ul><li>$j=1,\ldots,M$;</li><li>the superscript $^{(1)}$ indicates that we are working with parameters of the first layer;</li><li>$w_{ji}^{(1)}$&rsquo;s are called the <strong>weights</strong>;</li><li>$w_{j0}^{(1)}$&rsquo;s are known as the <strong>biases</strong>;</li><li>$a_j$&rsquo;s are referred as <strong>activations</strong>.</li></ul><p>The activations $a_j$&rsquo;s are then transformed using a differentiable, nonlinear <strong>activation function</strong> $h(\cdot)$, which correspond to $f(\cdot)$ in \eqref{1} to give
\begin{equation}
z_j=h(a_j),\label{3}
\end{equation}
where $z_j$ are called the <strong>hidden units</strong>. Repeating the same procedure as \eqref{2}, which was following \eqref{1}, $z_j$&rsquo;s are taken as the inputs of the second layer to give $K$ outputs
\begin{equation}
a_k=\sum_{j=1}^{M}w_{kj}^{(2)}z_j+w_{k0}^{(2)},\label{4}
\end{equation}
where $k=1,\ldots,K$.</p><p>This process will be repeated in $L$ times with $L$ is the number of layers. At the last layer, for instance, the second layer of our example network, the outputs, also called <strong>output unit activations</strong>, $a_k$&rsquo;s are transformed using an appropriate activation function to give a set of network output $y_k$. For example, in multiple binary classification problems, we can choose the logistic sigmoid as our activation function that
\begin{equation}
y_k=\sigma(a_k)\label{5}
\end{equation}
Combining all these steps \eqref{2}, \eqref{3}, \eqref{4} and \eqref{5} together, our neural network with sigmoidal output unit activation functions can be defined as
\begin{equation}
y_k(\mathbf{x},\mathbf{w})=\sigma\left(\sum_{j=1}^{M}w_{kj}^{(2)}h\left(\sum_{i=1}^{D}w_{ji}^{(1)}x_i+w_{j0}^{(1)}\right)+w_{k0}^{(2)}\right),\label{6}
\end{equation}
where all of the weights and biases are comprises together into a parameter vector $\mathbf{w}$. As suggested in <a href=https://trunghng.github.io/posts/machine-learning/glm/#dummy-coeff>linear regression</a>, we can also let the bias $w_{j0}^{(1)}$ be coefficient of a dummy input variable $x_0=1$ that makes \eqref{2} can be written as
\begin{equation}
a_j=\sum_{i=0}^{D}w_{ji}^{(1)}x_i
\end{equation}
This results that our subsequent layers are also able to be written in a more convenient form, which lets the entire network \eqref{6} take the form
\begin{equation}
y_k(\mathbf{x},\mathbf{w})=\sigma\left(\sum_{j=0}^{M}w_{kj}^{(2)}h\left(\sum_{i=0}^{D}w_{ji}^{(1)}x_i\right)\right)
\end{equation}
Our network is also an example of a <strong>multilayer perception</strong>, or <strong>MLP</strong>, which is a combination of <a href=https://trunghng.github.io/posts/machine-learning/glm/#perceptron>perceptron models</a>. The key difference is that while the neural network uses continuous sigmoidal nonlinearities in the hidden units, which is differentiable w.r.t the parameters, the perceptron algorithm uses step-function nonlinearities, which is in contrast non-differentiable.</p><p>The network network we have been considering so far is <strong>feed-forward neural network</strong>, whose outputs are deterministic functions of the inputs. Each (hidden or output) unit in such a network computes a function given by
\begin{equation}
z_k=h\left(\sum_{j}w_{kj}z_j\right),
\end{equation}
where the sum runs all over units sending connections to unit $k$ (bias included).</p><h3 id=unv-approx>Universal approximation property<a hidden class=anchor aria-hidden=true href=#unv-approx>#</a></h3><p>Feed-forward networks with <strong>hidden layers</strong> (i.e., the layers in which the training data does not show the desired output, e.g., the first layer of our network, the second layer on the other hands is called the <strong>output layer</strong>) provide <strong>universal approximation</strong> property.</p><p>In concrete, the universal approximation theorem states that a feedforward network with a linear output layer and at least one hidden layer with any <strong>squashing</strong> activation function (e.g., the logistic sigmoid function) an approximate any continuous function on a compact subsets of $\mathbb{R}^n$.</p><h3 id=w-s-sym>Weight-space symmetries<a hidden class=anchor aria-hidden=true href=#w-s-sym>#</a></h3><h2 id=net-training>Network training<a hidden class=anchor aria-hidden=true href=#net-training>#</a></h2><h3 id=output-prob-itp>Network outputs probabilistic interpretation<a hidden class=anchor aria-hidden=true href=#output-prob-itp>#</a></h3><h4 id=univ-output>Univariate regression<a hidden class=anchor aria-hidden=true href=#univ-output>#</a></h4><p>Consider the <a href=https://trunghng.github.io/posts/machine-learning/glm/#least-squares-reg>regression problem</a> in which the target variable $t$ has Gaussian distribution with an $\mathbf{x}$ dependent mean
\begin{equation}
p(t\vert\mathbf{x},\mathbf{w})=\mathcal{N}(t\vert y(\mathbf{x},\mathbf{w}),\beta^{-1}),
\end{equation}
For the conditional distribution above, it is sufficient to take the output unit activation function to be the function $h(x)=x$, because such a network can approximate any continuous function from $\mathbf{x}$ to $y$.</p><p>Given the data set $(\mathbf{X},\mathbf{t})=\{\mathbf{x}_n,t_n\}$, where $\mathbf{x}_n$&rsquo;s are i.i.d for $n=1,\ldots,N$, and where
\begin{align}
\mathbf{X}=\left[\begin{matrix}\vert&&\vert \\ \mathbf{x}_1&\ldots&\mathbf{x}_N \\ \vert&&\vert\end{matrix}\right],\hspace{1cm}\mathbf{t}=\left[\begin{matrix}t_1 \\ \vdots \\ t_N\end{matrix}\right]
\end{align}
The likelihood function therefore can be given by
\begin{align}
p(t\vert\mathbf{X},\mathbf{w},\beta)&=\prod_{n=1}^{N}p(t_n\vert\mathbf{x}_n,\mathbf{w},\beta) \\ &=\prod_{n=1}^{N}\mathcal{N}(t_n\vert y(\mathbf{x}_n,\mathbf{w}),\beta^{-1})
\end{align}
With a minor change as usual that taking negative natural logarithm of both sides gives us
\begin{align}
-\log p(\mathbf{t}\vert\mathbf{X},\mathbf{w},\beta)&=-\sum_{n=1}^{N}\log\mathcal{N}(t_n\vert y(\mathbf{x}_n,\mathbf{w}),\beta^{-1}) \\ &=\frac{\beta}{2}\sum_{n=1}^{N}\big(y(\mathbf{x}_n,\mathbf{w})-t_n\big)^2-\frac{N}{2}\log\beta+\frac{N}{2}\log 2\pi
\end{align}
Therefore, maximizing the likelihood function $p(\mathbf{t}\vert\mathbf{X},\mathbf{x},\beta)$ is equivalent to minimizing the sum-of-squares error function given as
\begin{equation}
E(\mathbf{w})=\frac{1}{2}\sum_{n=1}^{N}\big(y(\mathbf{x}_n,\mathbf{w})-t_n\big)^2,
\end{equation}
This also means the value of $\mathbf{w}$ that minimizes $E(\mathbf{w})$ will be $\mathbf{w}_\text{ML}$, which implies that the corresponding solution for $\beta$ will be given by
\begin{equation}
\frac{1}{\beta_\text{ML}}=\frac{1}{N}\sum_{n=1}^{N}\big(y(\mathbf{x}_n,\mathbf{w}_\text{ML})-t_n\big)^2
\end{equation}</p><h4 id=mult-output>Multivariate regression<a hidden class=anchor aria-hidden=true href=#mult-output>#</a></h4><p>Similarly, we consider the multiple target variables case, in which the conditional distribution of the target therefore takes the form
\begin{equation}
p(\mathbf{t}\vert\mathbf{x},\mathbf{w},\beta)=\mathcal{N}(\mathbf{t}\vert\mathbf{y}(\mathbf{x},\mathbf{w}),\beta^{-1}\mathbf{I})
\end{equation}
Repeating the same procedure as the univariate case, maximizing likelihood function is also equivalent to minimizing the sum-of-squares error function given by
\begin{equation}
E(\mathbf{w})=\frac{1}{2}\sum_{n=1}^{N}\big\Vert\mathbf{y}(\mathbf{x}_n,\mathbf{w})-\mathbf{t}_n\big\Vert^2,
\end{equation}
which gives us the solution for the noise precision $\beta$ in the multivariate case as
\begin{equation}
\frac{1}{\beta_\text{ML}}=\frac{1}{NK}\sum_{n=1}^{N}\big\Vert\mathbf{y}(\mathbf{x}_n,\mathbf{w}_\text{ML})-\mathbf{t}_n\big\Vert^2,
\end{equation}
where $K$ is the number of target variables.</p><h4 id=bi-clf>Binary classification<a hidden class=anchor aria-hidden=true href=#bi-clf>#</a></h4><p>Consider the problem of binary classification which outputs $t=1$ to denote class $\mathcal{C}_1$ and otherwise to denote class $\mathcal{C}_2$.</p><p>In particular, we consider a network having a single output whose activation function is a logistic sigmoid
\begin{equation}
y=\sigma(a)\doteq\frac{1}{1+\exp(-a)},
\end{equation}
which follows immediately that $0\leq y(\mathbf{x},\mathbf{w})\leq 1$.</p><p>This suggests us interpreting $y(\mathbf{x},\mathbf{w})$ as the conditional probability for class $\mathcal{C}_1$, $p(\mathcal{C}_1\vert\mathbf{x})$, and hence the corresponding conditional probability for class $\mathcal{C}_2$ will be $p(\mathcal{C}_2\vert\mathbf{x})=1-y(\mathbf{x},\mathbf{w})$. Or in other words, the conditional distribution $p(t\vert\mathbf{x},\mathbf{w})$ of targets $t$ given inputs $\mathbf{x}$ is then a Bernoulli distribution of the form
\begin{equation}
p(t\vert\mathbf{x},\mathbf{w})=y(\mathbf{x},\mathbf{w})^t\big(1-y(\mathbf{x},\mathbf{w})\big)^{1-t}
\end{equation}
If we consider a training set of $N$ independent observations as in the two regression tasks above, the likelihood function of our classification task will be given as
\begin{align}
p(\mathbf{t}\vert\mathbf{X},\mathbf{w})&=\prod_{n=1}^{N}p(t_n\vert\mathbf{x}_n,\mathbf{w}) \\ &=\prod_{n=1}^{N}y(\mathbf{x}_n,\mathbf{w})^{t_n}\big(1-y(\mathbf{x}_n,\mathbf{w})\big)^{1-t_n}
\end{align}
Taking the negative natural logarithm of the likelihood as above gives us the cross-entropy error function
\begin{align}
E(\mathbf{w})=-\log p(\mathbf{t}\vert\mathbf{X},\mathbf{w})&=-\log\prod_{n=1}^{N}y(\mathbf{x}_n,\mathbf{w})^{t_n}\big(1-y(\mathbf{x}_n,\mathbf{w})\big)^{1-t_n} \\ &=-\sum_{n=1}^{N}t_n\log y_n+(1-t_n)\log(1-y_n),
\end{align}
where $y_n=y(\mathbf{x}_n,\mathbf{w})$.</p><p>Moreover, consider the partial derivative of this error function w.r.t the activation $a_i$, corresponding to a particular data point $i$, we have
\begin{align}
\frac{\partial E(\mathbf{w})}{\partial a_i}&=\frac{\partial}{\partial a_i}-\sum_{n=1}^{N}t_n\log y_n+(1-t_n)\log(1-y_n) \\ &=-\frac{t_i}{y_i}\frac{\partial y_i}{\partial a_i}-\frac{1-t_i}{1-y_i}\frac{\partial(1-y_i)}{\partial a_i} \\ &=\frac{\partial y_i}{\partial a_i}\left(\frac{1-t_i}{1-y_i}-\frac{t_i}{y_i}\right) \\ &=y_i(1-y_i)\left(\frac{1-t_i}{1-y_i}-\frac{t_i}{y_i}\right) \\ &=y_i-t_i,\label{eq:bin-clf-drv-error-a}
\end{align}
where in the forth step, we have use the identity of the <a href=https://trunghng.github.io/posts/machine-learning/glm/#sigmoid-derivative>derivative of sigmoid function</a> that
\begin{equation}
\frac{d\sigma}{d a}=\sigma(1-\sigma)
\end{equation}</p><h4 id=mult-clf>Multi-class classification<a hidden class=anchor aria-hidden=true href=#mult-clf>#</a></h4><p>For the multi-class classification that assigns input variables to $K$ separated classes, we can use the network with $K$ outputs each of which has a logistic sigmoid activation function. Each output $t_k\in\{0,1\}$ for $k=1,\ldots,K$ indicates whether the input will be assigned to class $\mathcal{C}_k$</p><p>We first consider the case that the class labels are independent given the input vector, which means the conditional distributions for class $C_k$&rsquo;s will be $K$ i.i.d Bernoulli distributions, in which the conditional probability for class $\mathcal{C}_k$ will take the form
\begin{equation}
p(\mathcal{C}_k\vert\mathbf{x},\mathbf{w})=y_k(\mathbf{x},\mathbf{w})^{t_k}\big(1-y_k(\mathbf{x},\mathbf{w})\big)^{1-t_k}
\end{equation}
Therefore, the joint distribution of them, the conditional distribution of the target variables will be given as
\begin{align}
p(\mathbf{t}\vert\mathbf{x},\mathbf{w})&=\prod_{k=1}^{K}p(\mathcal{C}_k\vert\mathbf{x},\mathbf{w}) \\ &=\prod_{k=1}^{K}y_k(\mathbf{x},\mathbf{w})^{t_k}\big(1-y_k(\mathbf{x},\mathbf{w})\big)^{1-t_k}
\end{align}
Let $\mathbf{T}$ denote the combination of all the targets $\mathbf{t}_n$, i.e.,
\begin{equation}
\mathbf{T}=\left[\begin{matrix}-\hspace{0.15cm}\mathbf{t}_1^\text{T}\hspace{0.15cm}- \\ \vdots \\ -\hspace{0.15cm}\mathbf{t}_N^\text{T}\hspace{0.15cm}-\end{matrix}\right],
\end{equation}
the likelihood function therefore takes the form of
\begin{align}
p(\mathbf{T}\vert\mathbf{X},\mathbf{w})&=\prod_{n=1}^{N}p(\mathbf{t}_n\vert\mathbf{x}_n,\mathbf{w}) \\ &=\prod_{n=1}^{N}\prod_{k=1}^{K}y_k(\mathbf{x}_n,\mathbf{w})^{t_k}\big(1-y_k(\mathbf{x}_n,\mathbf{w})\big)^{1-t_k}\label{eq:mult-clf-llh}
\end{align}
Analogy to the binary case, taking the negative natural logarithm of the likelihood \eqref{eq:mult-clf-llh} gives us the corresponding cross-entropy error function for the multi-class case, given as
\begin{align}
E(\mathbf{w})=-\log p(\mathbf{T}\vert\mathbf{X},\mathbf{w})&=-\log\prod_{n=1}^{N}\prod_{k=1}^{K}y_k(\mathbf{x}_n,\mathbf{w})^{t_{nk}}\big(1-y_k(\mathbf{x}_n,\mathbf{w})\big)^{1-t_{nk}} \\ &=-\sum_{n=1}^{N}\sum_{k=1}^{K}t_{nk}\log y_{nk}+(1-t_{nk})\log(1-y_{nk}),\label{eq:mult-clf-error}
\end{align}
where $y_{nk}$ is short for $y_k(\mathbf{x}_n,\mathbf{w})$.</p><p>Similar to the binary case, consider the partial derivative of the error function \eqref{eq:mult-clf-error} w.r.t to the activation for a particular output unit $a_{ij}$, corresponding to a particular data point $i$, we have
\begin{align}
\frac{\partial E(\mathbf{w})}{\partial a_{ij}}&=\frac{\partial}{\partial a_{ij}}-\sum_{n=1}^{N}\sum_{k=1}^{K}t_{nk}\log y_{nk}+(1-t_{nk})\log(1-y_{nk}) \\ &=\left(\frac{1-t_{ij}}{1-y_{ij}}-\frac{t_{ij}}{y_{ij}}\right)\frac{\partial y_{ij}}{\partial a_{ij}} \\ &=\left(\frac{1-t_{ij}}{1-y_{ij}}-\frac{t_{ij}}{y_{ij}}\right)y_{ij}(1-y_{ij}) \\ &=y_{ij}-t_{ij}\label{eq:mult-drv-error-a}
\end{align}
which takes the same form as \eqref{eq:bin-clf-drv-error-a}</p><p>On the other hands, if each input is assigned only to one of $K$ classes (mutually exclusive), the conditional distributions for class $C_k$ will be instead given as
\begin{equation}
p(\mathcal{C}_k\vert\mathbf{x})=p(t_k=1\vert\mathbf{x})=y_k(\mathbf{x},\mathbf{w}),
\end{equation}
and thus the conditional distribution of the targets is
\begin{equation}
p(\mathbf{t}\vert\mathbf{x},\mathbf{w})=\prod_{k=1}^{K}p(t_k=1\vert\mathbf{x})^{t_k}=\prod_{k=1}^{K}y_k(\mathbf{x},\mathbf{w})^{t_k}
\end{equation}
The likelihood is therefore given as
\begin{equation}
p(\mathbf{T}\vert\mathbf{X},\mathbf{w})=\prod_{n=1}^{N}p(\mathbf{t}_n\vert\mathbf{x}_n,\mathbf{w})=\prod_{n=1}^{N}\prod_{k=1}^{K}y_k(\mathbf{x}_n,\mathbf{w})^{t_{nk}},
\end{equation}
which gives us the following cross-entropy error function by taking the negative natural logarithm
\begin{align}
E(\mathbf{w})=-\log p(\mathbf{T}\vert\mathbf{X},\mathbf{w})&=-\log\prod_{n=1}^{N}\prod_{k=1}^{K}y_k(\mathbf{x},\mathbf{w})^{t_{nk}} \\ &=-\sum_{n=1}^{N}\sum_{k=1}^{K}t_{nk}\log y_k(\mathbf{x}_n,\mathbf{w})\label{eq:mult-me-clf-error}
\end{align}
As discussed in <a href=https://trunghng.github.io/posts/machine-learning/glm/#softmax-reg>Softmax regression</a>, we see that the output unit activation function is given by the softmax function
\begin{equation}
y_k(\mathbf{x},\mathbf{w})=\frac{\exp\big[a_k(\mathbf{x},\mathbf{w})\big]}{\sum_{j=1}^{K}\exp\big[a_j(\mathbf{x},\mathbf{w})\big]}
\end{equation}
Taking the derivative of the error function \eqref{eq:mult-me-clf-error} w.r.t to the activation for a particular output unit $a_{ij}$, corresponding to a particular data point $i$, we have
\begin{align}
\frac{\partial E(\mathbf{w})}{\partial a_{ij}}&=\frac{\partial}{\partial a_{ij}}-\sum_{n=1}^{N}\sum_{k=1}^{K}t_{nk}\log y_{nk} \\ &=-\sum_{k=1}^{K}\frac{t_{ik}}{y_{ik}}\frac{\partial y_{ik}}{\partial a_{ij}} \\ &=-\sum_{k=1}^{K}\frac{t_{ik}}{y_{ik}}y_{ik}(1\{j=k\}-y_{ij})\label{53} \\ &=y_{ij}\sum_{k=1}^{K}t_{ik}-\sum_{k=1}^{K}t_{ik}1\{j=k\} \\ &=y_{ij}-t_{ij}
\end{align}
where we have used the identity of the <a href=https://trunghng.github.io/posts/machine-learning/glm/#softmax-derivative>derivative of the softmax function</a> in the forth step to obtain \eqref{53}.</p><h3 id=param-opt>Parameter optimization<a hidden class=anchor aria-hidden=true href=#param-opt>#</a></h3><p>In training neural network to find a value of $\mathbf{w}$ to minimize the error function $E(\mathbf{w})$, we usually start with some initial value $\mathbf{w}_0$ and iteratively update the weight vector $\mathbf{w}$, in which the weight at time step $\tau+1$ is given as
\begin{equation}
\mathbf{w}^{(t+1)}=\mathbf{w}^{(\tau)}+\Delta\mathbf{w}^{(\tau)},
\end{equation}
where $\Delta\mathbf{w}^{(\tau)}$ is some update rule.</p><p>At each time step $\tau$, there are two distinct stages:</p><ul id=number-list><li>Stage 1 refers to evaluating the derivatives of the error function w.r.t the weights, which can be accomplished efficiently using <b>backpropagation</b> that will be discussed in the next section.</li><li>Stage 2 relates to using those computed derivatives to calculate the adjustments to be made to the weights $\mathbf{w}$. <b>Gradient descent</b>, for instance, is the simplest approach in which each time step the weights take a small step in the direction of the negative gradient, as
\begin{equation}
\mathbf{w}^{(\tau+1)}=\mathbf{w}^{(\tau)}-\eta\nabla_\mathbf{w}E(\mathbf{w}^{(\tau)}),
\end{equation}
where $\eta>0$ is called the <b>learning rate</b> of the update.</li></ul><h3 id=backprop>Backpropagation<a hidden class=anchor aria-hidden=true href=#backprop>#</a></h3><p>In this section, we will consider the use of <strong>backpropagation</strong> technique to evaluate the first and second derivatives of error-functions w.r.t the weights and also the derivatives of the network outputs w.r.t the inputs.</p><h4 id=erf-drv>Error-function derivatives<a hidden class=anchor aria-hidden=true href=#erf-drv>#</a></h4><p>We first consider the case of evaluating the first order derivative of the error function w.r.t to the weight parameter $\mathbf{w}$.</p><p>Consider a simple linear model where the outputs $y_k$&rsquo;s are linear combinations of the input variable $x_i$&rsquo;s
\begin{equation}
y_k=\sum_{i}w_{ki}x_i,
\end{equation}
together with the error function, in which the error function for the $n$ data point is defined as
\begin{equation}
E_n(\mathbf{w})=\frac{1}{2}\sum_{k}(y_{nk}-t_{nk})^2,
\end{equation}
where $y_{nk}=y_k(\mathbf{x}_n,\mathbf{w})$.</p><p>The gradient of this error function w.r.t to a weight $w_{ji}$ then can be computed by
\begin{equation}
\frac{\partial E_n}{\partial w_{ji}}=(y_{nj}-t_{nj})x_{ni}
\end{equation}
In a general feed-forward network, each unit is a weighted sum of its inputs
\begin{equation}
a_j=\sum_{i}w_{ji}z_i
\end{equation}</p><h4 id=jacobian-mtx>Jacobian matrix<a hidden class=anchor aria-hidden=true href=#jacobian-mtx>#</a></h4><h4 id=hessian-mtx>Hessian matrix<a hidden class=anchor aria-hidden=true href=#hessian-mtx>#</a></h4><h2 id=bayes-nn>Bayesian neural networks<a hidden class=anchor aria-hidden=true href=#bayes-nn>#</a></h2><h3 id=posterior-param-dist>Posterior parameter distribution<a hidden class=anchor aria-hidden=true href=#posterior-param-dist>#</a></h3><h2 id=preferences>Preferences<a hidden class=anchor aria-hidden=true href=#preferences>#</a></h2><p>[1] Christopher M. Bishop. <a href=https://link.springer.com/book/9780387310732>Pattern Recognition and Machine Learning</a>. Springer New York, NY, 2006.</p><p>[2] Ian Goodfellow & Yoshua Bengio & Aaron Courville. <a href=https://www.deeplearningbook.org>Deep Learning</a>. MIT Press, 2016.</p><h2 id=footnotes>Footnotes<a hidden class=anchor aria-hidden=true href=#footnotes>#</a></h2></div><footer class=post-footer><ul class=post-tags><li><a href=https://trunghng.github.io/tags/machine-learning/>machine-learning</a></li><li><a href=https://trunghng.github.io/tags/neural-network/>neural-network</a></li></ul><nav class=paginav><a class=prev href=https://trunghng.github.io/posts/evolution-strategy/cma-es/><span class=title>« Prev</span><br><span>CMA Evolution Strategy</span></a>
<a class=next href=https://trunghng.github.io/posts/measure-theory/measure-theory-p3/><span class=title>Next »</span><br><span>Measure theory - III: the Lebesgue integral</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Neural networks on twitter" href="https://twitter.com/intent/tweet/?text=Neural%20networks&url=https%3a%2f%2ftrunghng.github.io%2fposts%2fmachine-learning%2fneural-nets%2f&hashtags=machine-learning%2cneural-network"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Neural networks on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2ftrunghng.github.io%2fposts%2fmachine-learning%2fneural-nets%2f&title=Neural%20networks&summary=Neural%20networks&source=https%3a%2f%2ftrunghng.github.io%2fposts%2fmachine-learning%2fneural-nets%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Neural networks on reddit" href="https://reddit.com/submit?url=https%3a%2f%2ftrunghng.github.io%2fposts%2fmachine-learning%2fneural-nets%2f&title=Neural%20networks"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Neural networks on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2ftrunghng.github.io%2fposts%2fmachine-learning%2fneural-nets%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Neural networks on whatsapp" href="https://api.whatsapp.com/send?text=Neural%20networks%20-%20https%3a%2f%2ftrunghng.github.io%2fposts%2fmachine-learning%2fneural-nets%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Neural networks on telegram" href="https://telegram.me/share/url?text=Neural%20networks&url=https%3a%2f%2ftrunghng.github.io%2fposts%2fmachine-learning%2fneural-nets%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2022 <a href=https://trunghng.github.io>Trung's Place</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>