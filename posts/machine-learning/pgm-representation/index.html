<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Probabilistic Graphical Models - Representation | Trung's Place</title><meta name=keywords content="machine-learning,probabilistic-graphical-model"><meta name=description content="Notes on Representation in PGMs."><meta name=author content="Trung H. Nguyen"><link rel=canonical href=https://trunghng.github.io/posts/machine-learning/pgm-representation/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.bc1149f4a72aa4858d3a9f71462f75e5884ffe8073ea9d6d5761d5663d651e20.css integrity="sha256-vBFJ9KcqpIWNOp9xRi915YhP/oBz6p1tV2HVZj1lHiA=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://trunghng.github.io/images/favicon/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://trunghng.github.io/images/favicon/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://trunghng.github.io/images/favicon/favicon-32x32.png><link rel=apple-touch-icon href=https://trunghng.github.io/images/favicon/apple-touch-icon.png><link rel=mask-icon href=https://trunghng.github.io/images/favicon/android-chrome-512x512.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=text/x-mathjax-config>
  MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": {availableFonts: []}
  });
</script><script type=text/x-mathjax-config>
    MathJax.Hub.Config({
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
      "HTML-CSS": {availableFonts: []},
      TeX: {
        equationNumbers: { autoNumber: "AMS" },
      },
    });
  </script><script type=text/javascript src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><style>.post-content{text-align:justify;font-size:15px}.post-content h1,h2,h3,h4,h5,h6{text-align:left}.post-content a,.post-content a:link,.post-content a:visited,.post-content a:hover,.post-content a:active{box-shadow:none;font-weight:700;color:#4682b4}.post-content ol,.post-content ul{margin-left:10px}.post-content li>ol,.post-content li>ul{margin-left:30px}#roman-list,#number-list,#alpha-list{counter-reset:section;margin-bottom:10px}#roman-list>li{list-style:none;position:relative}#number-list>li{list-style:none;position:relative}#alpha-list>li{list-style:none;position:relative}#roman-list>li:before{counter-increment:section;content:"(" counter(section,lower-roman)") ";position:absolute;left:-2em}#number-list>li:before{counter-increment:section;content:"(" counter(section,decimal)") ";position:absolute;left:-2em}#alpha-list>li:before{counter-increment:section;content:"(" counter(section,lower-alpha)") ";position:absolute;left:-2em}.toc{font-size:15px}.post-footer{font-size:15px}.post-content figure>img{display:block;margin-left:auto;margin-right:auto}.post-content figure>figcaption{all:revert;text-align:justify;font-size:12px;font-style:italic;width:70%;margin-left:15%}.post-content figure>figcaption>p{all:revert}.post-content h3{font-size:28px}.post-content h4{font-size:24px}.post-content h5{font-size:20px}.post-content h6{font-size:16px}</style><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="Probabilistic Graphical Models - Representation"><meta property="og:description" content="Notes on Representation in PGMs."><meta property="og:type" content="article"><meta property="og:url" content="https://trunghng.github.io/posts/machine-learning/pgm-representation/"><meta property="og:image" content="https://trunghng.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-12-10T17:55:57+07:00"><meta property="article:modified_time" content="2022-12-10T17:55:57+07:00"><meta property="og:site_name" content="Trung's Place"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://trunghng.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Probabilistic Graphical Models - Representation"><meta name=twitter:description content="Notes on Representation in PGMs."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://trunghng.github.io/posts/"},{"@type":"ListItem","position":3,"name":"Probabilistic Graphical Models - Representation","item":"https://trunghng.github.io/posts/machine-learning/pgm-representation/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Probabilistic Graphical Models - Representation","name":"Probabilistic Graphical Models - Representation","description":"Notes on Representation in PGMs.\n","keywords":["machine-learning","probabilistic-graphical-model"],"articleBody":"Notes on Representation in PGMs.\nGraphs A graph, denoted $\\mathcal{K}$ is a tuple of $\\mathcal{X}$ and $\\mathcal{E}$ where $\\mathcal{X}=\\{X_1,\\ldots,X_n\\}$ is the sets of nodes (or vertices) and $\\mathcal{E}$ is the set of edges. \\begin{equation} \\mathcal{K}=(\\mathcal{X},\\mathcal{E}) \\end{equation}\nNodes, Edges Any pair of nodes $X_i,X_j$, for $i\\neq j$ is connected by either a directed edge $X_i\\rightarrow X_j$ or an undirected edge $X_i-X_j$1. We use the notation $X_i\\rightleftharpoons X_j$ to denote that $X_i$ is connected to $X_j$ via some edge, whether directed (in any direction) or undirected.\nIf the graph contains directed edges only, we call it a directed graph, denoted $\\mathcal{G}$, else if the graph established by undirected edge only, it is referred as undirected graph, denoted $\\mathcal{H}$.\nFigure 1: (taken from the PGM book) Example of a partially directed graph $\\mathcal{K}$ Following are some necessary notations:\nIf $X_i\\rightarrow X_j\\in\\mathcal{E}$, we say that $X_i$ is the parent of $X_j$ while $X_j$ is the child of $X_i$.\nE.g. node $I$ is a child of nodes $C,E$ and $H$ while $D$ is a parent of $G$. If $X_i-X_j\\in\\mathcal{E}$, we say that $X_i$ is a neighbor of $X_j$, and vice versa.\nE.g. node $F$ is a neighbor of $G$. If $X\\rightleftharpoons Y\\in\\mathcal{E}$, we say that $X$ and $Y$ are adjacent.\nE.g. nodes $A$ and $C$ are adjacent, while $D$ is adjacent to $E$. We use $\\text{Pa}_X$ to denote the set of parents of $X$, $\\text{Ch}_X$ to denote the set of its children and $\\text{Nb}_X$ to denote its neighbors. The set $\\text{Boundary}_X\\doteq\\text{Pa}_X\\cup\\text{Nb}_X$ is known as the boundary of $X$.\nE.g. $\\text{Pa}_I=\\{C,E,H\\}$ and $\\text{Boundary}_F=\\text{Pa}_F\\cup\\text{Nb}_F=\\{C\\}\\cup\\{G\\}=\\{C,G\\}$. The degree of a node $X$ is the number of edges in which it participates; its indegree is the number of directed edges $Y\\rightarrow X$. The degree of a graph is the maximal degree of a node in the graph.\nE.g. node $D$ has degree of $3$, indegree of $0$; the graph $\\mathcal{K}$ has degree of $3$. Subgraphs Consider the graph $\\mathcal{K}=(\\mathcal{X},\\mathcal{E})$ and let $\\mathbf{X}\\subset\\mathcal{X}$ be a subset of nodes in $\\mathcal{K}$. Then:\nThe induced subgraph of $\\mathcal{K}$, denoted $\\mathcal{K}[\\mathbf{X}]$ is defined as the graph $(\\mathbf{X},\\mathcal{E}')$ where \\begin{equation} \\mathcal{E}'=\\{X\\rightleftharpoons Y:X,Y\\in\\mathbf{X}\\} \\end{equation} A subgraph over $\\mathbf{X}$ is complete if every two nodes in $\\mathbf{X}$ are connected via some edges. The set $\\mathbf{X}$ is known as a clique; or even a maximal clique if for any set of nodes $\\mathbf{Y}\\supset\\mathbf{X}$, $\\mathbf{Y}$ is not a clique, i.e. \\begin{equation} \\{\\mathbf{Y}\\text{ clique}:\\mathbf{Y}\\supset\\mathbf{X}\\}=\\emptyset \\end{equation} The set $\\mathbf{X}$ is called upward closed in $\\mathbf{K}$ if for any $X\\in\\mathbf{X}$, we have that \\begin{equation} \\text{Boundary}_X\\subset\\mathbf{X} \\end{equation} The upward closure of $\\mathbf{X}$ is the minimal closed subset $\\mathbf{Y}$ covering $\\mathbf{X}$, i.e. \\begin{equation} \\mathbf{Y}=\\sup\\{\\bar{\\mathbf{Y}}\\text{ upward closed in }\\mathcal{K}:\\bar{\\mathbf{Y}}\\supset\\mathbf{X}\\} \\end{equation} The upwardly closed subgraph of $\\mathbf{X}$, denoted $\\mathcal{K}^+[\\mathbf{X}]$, is the induced subgraph over $\\mathbf{Y}$, $\\mathcal{K}[\\mathbf{Y}]$. Paths, Trails Consider the graph $\\mathcal{K}=(\\mathcal{X},\\mathcal{E})$, the basic notion of edges gives rise to following definitions:\n$X_1,\\ldots,X_k$ form a path in $\\mathcal{K}$ if for every $i=1,\\ldots,k-1$, we have that either $X_i\\rightarrow X_{i+1}$ or $X_i-X_{i+1}$. A path is directed if there exists a directed edge $X_i\\rightarrow X_{i+1}$. $X_1,\\ldots,X_k$ form a trail in $\\mathcal{K}$ if for every $i=1,\\ldots,k-1$, we have that $X_i\\rightleftharpoons X_{i+1}$. $\\mathcal{K}$ is connected if for every pair $X_i,X_j$ there is a trail between $X_i$ and $X_j$. $X$ is an ancestor of $Y$ and correspondingly $Y$ is a descendant of $X$ in $\\mathcal{K}$ if there exists a directed path $X_1,\\ldots,X_k$ with $X_1=X$ and $X_k=Y$. An ordering of nodes $X_1,\\ldots,X_n$ is a topological ordering relative to $\\mathbf{K}$ if whenever we have $X_i\\rightarrow X_j\\in\\mathcal{E}$, then $i\\lt j$. This gives rise to critical results that for each node $X_i$, we have that \\begin{equation} \\text{Pa}_{X_i}\\subset\\{X_1,\\ldots,X_{i-1}\\}, \\end{equation} and \\begin{equation} \\text{Ch}_{X_i}\\subset\\{X_{i+1},\\ldots,X_n\\} \\end{equation} Cycles, Loops A cycle in $\\mathcal{K}$ is a directed path $X_1,\\ldots,X_k$ where $X_1=X_k$. $\\mathcal{K}$ is acyclic if it contains no cycles. $\\mathcal{K}$ is a directed acyclic graph (or DAG) if it is both directed and acyclic. An acyclic graph containing both directed and undirected edges is known as a partially directed acyclic graph (or PDAG).\nLet $\\mathcal{K}$ be a PDAG over $\\mathcal{X}$ and let $\\mathbf{K}_1,\\ldots,\\mathbf{K}_\\ell$ be a disjoint partition of $\\mathcal{X}$ such that: the induced subgraph over $\\mathbf{K}_i$ contains no directed edges; for any pair of nodes $X\\in\\mathbf{K}_i$ and $Y\\in\\mathbf{K}_j$ for $i\\lt j$, an edge between $X$ and $Y$ can only be a directed edge $X\\rightarrow Y$. Each component $\\mathbf{K}_i$ is called a chain component, while $\\mathcal{K}$ is referred as a chain graph. A loop in $\\mathcal{K}$ is a trail $X_1,\\ldots,X_k$ where $X_1=X_k$. A graph is singly connected if it contains no loops. A node in a singly connected graph is called a leaf if it has exactly one adjacent node. A singly connected directed graph is called a polytree, while a singly connected undirected graph is known as a forest; if it is also connected, it is called a tree. A directed graph is a forest if each node has at most one parent. A directed forest is a tree if it is also connected. Directed Graphical Model A Directed Graphical Model (or Bayesian network) is a tuple $\\mathcal{B}=(\\mathcal{G},P)$ where\n$\\mathcal{G}$ is a Bayesian network structure, $P$ factorizes according to $\\mathcal{G}$, $P$ is specified as a set of CPDs associated with $\\mathcal{G}$’s nodes. Bayesian Network Structure A Bayesian network structure (or Bayesian network graph, BN graph) is a DAG, denoted $\\mathcal{G}=(\\mathcal{X},\\mathcal{E})$ with $\\mathcal{X}=\\{X_1,\\ldots,X_n\\}$ where\nEach node $X_i\\in\\mathcal{X}$ represents a random variable. Each node $X_i\\in\\mathcal{X}$ is associated with a conditional independencies assumption, called local independencies, denoted $\\mathcal{I}_\\ell(\\mathcal{G})$, which says that $X_i$ is conditionally independent of its non-descendants given its parent, i.e. \\begin{equation} (X_i\\perp\\text{NonDescendants}_{X_i}\\vert\\hspace{0.1cm}\\text{Pa}_{X_i}), \\end{equation} where $\\text{NonDescendants}_{X_i}$ denotes the set of non-descendant nodes of $X_i$. I-Maps Let $P$ be a distribution over $\\mathcal{X}$, we define $\\mathcal{I}(P)$ to be the set of independence assertions of the form $(X\\perp Y\\hspace{0.1cm}\\vert Z)$ that hold in $P$, i.e. \\begin{equation} P\\models(X\\perp Y\\vert Z), \\end{equation} or \\begin{equation} P(X,Y\\vert Z)=P(X\\vert Z)P(Y\\vert Z) \\end{equation} Let $\\mathcal{K}$ be a graph associated with a set of independencies $\\mathcal{I}(\\mathcal{K})$, then $\\mathcal{K}$ is an I-map (for independence map) for a set of independencies $\\mathcal{I}$ if $\\mathcal{I}(\\mathcal{K})\\subset\\mathcal{I}$.\nHence, if $P$ satisfies the local dependencies associated with $\\mathcal{G}$, we have \\begin{equation} \\mathcal{I}_\\ell(\\mathcal{G})\\subset\\mathcal{I}(P), \\end{equation} which implies that $\\mathcal{G}$ is an I-map for $\\mathcal{I}(P)$, or simply an I-map for $P$.\nFactorization Let $\\mathcal{G}$ is a BN graph over $X_1,\\ldots,X_n\\in\\mathcal{X}$. A distribution $P$ over $\\mathcal{X}$ is said to factorize according to $\\mathcal{G}$ if $P$ can be expressed as a product \\begin{equation} P(X_1,\\ldots,X_n)=\\prod_{i=1}^{n}P(X_i\\vert\\text{Pa}_{X_i}) \\end{equation} This equation is known as the chain rule for Bayesian networks. Each individual factor $P(X_i\\vert\\text{Pa}_{X_i})$, which is a conditional probability distribution (CPD), is called the local probabilistic model.\nI-Map - Factorization Connection Theorem 1: Let $\\mathcal{G}$ be a BN graph over a set of random variables $\\mathcal{X}$ and let $P$ be a joint distribution over $\\mathcal{X}$. Then $\\mathcal{G}$ is an I-map for $P$ if and only if $P$ factorizes over $\\mathcal{G}$.\nProof\nI-map $\\Rightarrow$ Factorization\nWithout loss of generality, let $X_1,\\ldots,X_n$ be a topological ordering of the variables in $\\mathcal{X}$.\nLet us consider an arbitrary $X_i$ for $i\\in\\{1,\\ldots,n\\}$. As mentioning above, the topological ordering implies that \\begin{align} \\text{Pa}_{X_i}\u0026\\subset\\{X_1,\\ldots,X_{i-1}\\}, \\\\ \\text{Ch}_{X_i}\u0026\\subset\\{X_{i+1},\\ldots,X_n\\} \\end{align} Consequently, none of descendants of $X_i$ is in $\\{X_1,\\ldots,X_{n-1}\\}$. Thus, if we denote the set of all non-descendant nodes of $X_i$ as $\\text{NonDescentdants}_{X_i}$ and let $\\mathbf{Z}\\subset\\text{NonDescentdants}_{X_i}$, then \\begin{equation} \\mathbf{Z}\\cup\\text{Pa}_{X_i}=\\{X_1,\\ldots,X_{i-1}\\} \\end{equation} Moreover, the local independence for $X_i$ implies that \\begin{equation} (X_i\\perp\\mathbf{Z}\\vert\\text{ Pa}_{X_i}) \\end{equation} Therefore, since $\\mathcal{G}$ is an I-map for $P$ we obtain \\begin{equation} P(X_i\\vert X_1,\\ldots,X_{i-1})=P(X_i\\vert\\text{Pa}_{X_i}) \\end{equation} Thus, by the chain rule for probabilities, we have \\begin{equation} P(X_1,\\ldots,X_n)=\\prod_{i=1}^{n}P(X_i\\vert X_1,\\ldots,X_{i-1})=\\prod_{i=1}^{n}P(X_i\\vert\\text{Pa}_{X_i}) \\end{equation} I-map $\\Leftarrow$ Factorization\nTo prove that $\\mathcal{G}$ is an I-map according to $P$, we need to show that $\\mathcal{I}_\\ell(\\mathcal{G})$ holds in $P$. Consider an arbitrary node $X_i$ and the local independencies $(X_i\\perp\\text{NonDescendants}_{X_i}\\vert\\text{Pa}_{X_i})$, our problem remains to prove that \\begin{equation} P(X_i\\vert\\mathcal{X}\\backslash X_i)=P(X_i\\vert\\text{Pa}_{X_i}) \\end{equation} since \\begin{equation} P(X_i\\vert\\mathcal{X}\\backslash X_i)=P(X_i\\vert\\text{NonDescendants}_{X_i}\\cup\\text{Pa}_{X_i}) \\end{equation} By factorization, we have that \\begin{align} P(\\mathcal{X}\\backslash X_i)\u0026=\\sum_{X_i}P(X_1,\\ldots,X_n) \\\\ \u0026=\\sum_{X_i}\\prod_{j=1}^{n}P(X_j\\vert\\text{Pa}_{X_j}) \\\\ \u0026=\\left(\\prod_{j=1,j\\neq i}^{n}P(X_j\\vert\\text{Pa}_{X_j})\\right)\\sum_{X_i}P(X_i\\vert\\text{Pa}_{X_i}) \\\\ \u0026=\\prod_{j=1,j\\neq i}^{n}P(X_j\\vert\\text{Pa}_{X_j}), \\end{align} where in the last step, we use the fact that the conditional probability function $P(X_i\\vert\\text{Pa}_{X_i})$ sum to $1$ over the sample space of $X_i$. This implies that by Bayes rules \\begin{align} P(X_i\\vert\\mathcal{X}\\backslash X_i)\u0026=\\frac{P(X_1,\\ldots,X_n)}{P(\\mathcal{X}\\backslash X_i)} \\\\ \u0026=\\frac{\\prod_{j=1}^{n}P(X_j\\vert\\text{Pa}_{X_j})}{\\prod_{j=1,j\\neq i}^{n}P(X_j\\vert\\text{Pa}_{X_j})} \\\\ \u0026=P(X_i\\vert\\text{Pa}_{X_i}) \\end{align} Independencies in Bayesian Network D-separation Let $\\mathcal{G}$ be a BN structure, $X_1\\rightleftharpoons\\ldots\\rightleftharpoons X_n$ be a trail in $\\mathcal{G}$ and let $\\mathbf{Z}$ be a subset of observed variables. The trail $X_1\\rightleftharpoons\\ldots\\rightleftharpoons X_n$ is active if\nWhenever we have a v-structure $X_{i-1}\\rightarrow X_i\\leftarrow X_{i+1}$, $X_i$ or one of its descendants are in $\\mathbf{Z}$; No other node along the trail are in $\\mathbf{Z}$. Figure 2: (taken from the PGM book) The four possible two-edge trails from $X$ to $Y$ via $Z$: (a) Causal trail; (b) Evidential trail; (c) Common cause trail; (d) Common effect trail Consider the trails forming from two edges as illustrated above:\nThe trail $X\\rightarrow Z\\rightarrow Y$ is active $\\Leftrightarrow$ $Z$ is not observed. The trail $X\\leftarrow Z\\leftarrow Y$ is active $\\Leftrightarrow$ $Z$ is not observed. The trail $X\\leftarrow Z\\leftarrow Y$ is active $\\Leftrightarrow$ $Z$ is not observed. The trail $X\\rightarrow Z\\leftarrow Y$ is active $\\Leftrightarrow$ either $Z$ or one of its descendants is observed. Let $\\mathbf{X},\\mathbf{Y},\\mathbf{Z}$ be sets of nodes in $\\mathcal{G}$. Then $\\mathbf{X}$ and $\\mathbf{Y}$ are said to be d-separated given $\\mathbf{Z}$, denoted $\\text{d-sep}_\\mathcal{G}(\\mathbf{X};\\mathbf{Y}\\vert\\mathbf{Z})$, if there is no active trail between any node $X\\in\\mathbf{X}$ and $Y\\in\\mathbf{Y}$ given $\\mathbf{Z}$.\nWe define the global Markov independencies associated with $\\mathcal{G}$, denoted $\\mathcal{I}(\\mathcal{G})$, to be the set of all independencies that correspond to d-separation in $\\mathcal{G}$ \\begin{equation} \\mathcal{I}(\\mathcal{G})=\\big\\{(\\mathbf{X}\\perp\\mathbf{Y}\\vert\\mathbf{Z}):\\text{d-sep}_\\mathcal{G}(\\mathbf{X};\\mathbf{Y}\\vert\\mathbf{Z})\\big\\} \\end{equation}\nSoundness, Completeness Theorem 2 (Soundness of d-separation) If a distribution $P$ factorizes according to $\\mathcal{G}$, then \\begin{equation} \\mathcal{I}(\\mathcal{G})\\subset\\mathcal{I}(P) \\end{equation} The soundness property says that if $\\text{d-sep}_\\mathcal{G}(X;Y\\vert\\mathbf{Z})$ then they are conditional independent given $\\mathbf{Z}$, or $(X\\perp Y\\vert\\mathbf{Z})$.\nTheorem 3 (Completeness of d-separation) If two variables $X$ and $Y$ are independent given $\\mathbf{Z}$, then they are d-separated.\nThe completeness property says that d-separation detects all possible independencies.\nTheorem 4: Let $\\mathcal{G}$ be a BN graph. If $X$ and $Y$ are not d-separated given $\\mathbf{Z}$, then $X$ and $Y$ are dependent given $\\mathbf{Z}$ in some distribution $P$ that factorizes over $\\mathcal{G}$.\nTheorem 5: For almost all distributions $P$ that factorize over $\\mathcal{G}$, i.e. for all distributions except for a set of measure zero in the space of CPD parameterizations, we have that \\begin{equation} \\mathcal{I}(\\mathcal{G})=\\mathcal{I}(P) \\end{equation} These results state that for almost all parameterizations $P$ of the graph $\\mathcal{G}$, the d-separation test precisely characterizes the independencies that hold for $P$.\nI-Equivalence Two graph $\\mathcal{K}_1$ and $\\mathcal{K}_2$ over $\\mathcal{X}$ are said to be I-equivalent if they encode the same set of conditional independencies assertions, i.e. \\begin{equation} \\mathcal{I}(\\mathcal{K}_1)=\\mathcal{I}(\\mathcal{K}_2) \\end{equation} This implies that any distribution $P$ that factorizes over $\\mathcal{K}_1$ also factorizes according to $\\mathcal{K}_2$ and vice versa.\nThe skeleton of a BN graph $\\mathcal{G}$ over $\\mathcal{X}$ is an undirected graph over $\\mathcal{X}$ containing an edge $\\{X,Y\\}$ for every edge $(X,Y)$ in $\\mathcal{G}$.\nTheorem 6 (skeleton + v-structures $\\Rightarrow$ I-equivalence) Let $\\mathcal{G}_1$ and $\\mathcal{G_2}$ be two graphs over $\\mathcal{X}$. If $\\mathcal{G}_1,\\mathcal{G}_2$ both have the same skeleton and the same set of v-structures then they are I-equivalent.2\nFigure 3: (taken from the PGM book) Two graphs have the same skeleton and set of v-structures, i.e. $\\{X\\rightarrow Y\\leftarrow Z\\}$, and thus are I-equivalent Immorality A v-structure $X\\rightarrow Z\\leftarrow Y$ is an immorality if there is no direct edge between. If there is such an edge, it is called a covering edge for the v-structure.\nIt is easily seen that not every v-structure is an immorality, which implies that two networks with the same set of immoralities do not necessarily have the same set of v-structures.\nTheorem 7 (skeleton + immoralities $\\Leftrightarrow$ I-equivalence) Let $\\mathcal{G}_1$ and $\\mathcal{G_2}$ be two graphs over $\\mathcal{X}$. If $\\mathcal{G}_1,\\mathcal{G}_2$ both have the same skeleton and the same set of immoralities iff they are I-equivalent.\nProof\nTo prove the theorem, we first introduce the notion of minimal active trail and triangle.\nDefinition (Minimal active trail) An active trail $X_1,\\ldots,X_m$ is minimal if there is no other active trail from $X_1$ to $X_m$ that shortcuts some of the nodes, i.e. there is no active trail \\begin{equation} X_1\\rightleftharpoons X_{i_1}\\rightleftharpoons\\ldots X_{i_k}\\rightleftharpoons X_m\\hspace{1cm}\\text{for }1\\lt i_1\\lt\\ldots\\lt i_k\\lt m \\end{equation} Definition (Triangle) Any three consecutive nodes in a trail $X_1,\\ldots,X_m$ are called a triangle if their skeleton is fully connected, i.e. forms a 3-clique.\nOur attention now is to prove that the only possible triangle in minimal active trail is the one having form of $X_{i-1}\\leftarrow X_i\\rightarrow X_{i+1}$ and either $X_{i-1}\\rightarrow X_{i+1}$ or $X_{i-1}\\leftarrow X_{i+1}$.\nConsider a two-edge trail from $X_{i-1}$ to $X_{i+1}$ via $X_i$, which as being mentioned above, has four possible forms $X_{i-1}\\rightarrow X_i\\rightarrow X_{i+1}$\nIt is easily seen that $X_i$ has to be not observed to make the trail active. If $X_{i-1}$ is connected to $X_{i+1}$ via $X_{i-1}\\rightarrow X_{i+1}$, this gives rise to a shortcut. On the other hand, if they are connected by $X_{i-1}\\leftarrow X_{i+1}$, the triangle now induces a cycle. $X_{i-1}\\leftarrow X_i\\leftarrow X_{i+1}$\nThis case is symmetrically identical to the previous one, and thus is not viable. $X_{i-1}\\leftarrow X_i\\rightarrow X_{i+1}$\nThe first observation is that $X_i$ has to be not given. The second observation is $X_{i-1}$ and $X_{i+1}$ are symmetric through $X_i$, so we only need to consider some specific cases of $X_{i-1}$ and the same logic is applied to $X_{i+1}$ analogously.\nLet us examine the two-edge trail $X_{i-2},X_{i-1},X_i$. On the one hand, if we have $X_{i-2}\\rightarrow X_{i-1}$, $X_{i-1}$ then has to be given, which implies that If $X_{i-1}\\leftarrow X_{i+1}$ exists, it will create a shortcut, which is not allowed. If $X_{i-1}\\rightarrow X_{i+1}$ exists, no shortcut appears, $X_{i-1},X_i,X_{i+1}$ satisfies the condition of a triangle in the minimal active trail $X_1,\\ldots,X_m$. On the other hand, if we have $X_{i-2}\\leftarrow X_{i-1}$, then $X_{i-1}$ is not observed, analogously, we instead have If $X_{i-1}\\leftarrow X_{i+1}$ exists, no shortcut is formed, $X_{i-1},X_i,X_{i+1}$ create a triangle. If $X_{i-1}\\rightarrow X_{i+1}$ exists, $X_{i-1},X_i,X_{i+1}$ is do not form a triangle due to the appearance of a shortcut through $X_{i-1}$ to $X_{i+1}$. $X_{i-1}\\rightarrow X_i\\leftarrow X_{i+1}$\nIn this case, $X_i$ or one of its descendant is observed. Using the similar procedure to previous case gives us no viable triangle formed by $X_{i-1},X_i,X_{i+1}$. Given these results, we are now ready for the main part. Let us begin with the forward path. Skeleton + Immoralities $\\Rightarrow$ I-equivalence\nAssume that there exists node $X,Y,Z$ such that \\begin{align} (X\\perp Y\\vert Z)\u0026\\in\\mathcal{I}(\\mathcal{G}_1), \\\\ (X\\perp Y\\vert Z)\u0026\\not\\in\\mathcal{I}(\\mathcal{G}_2), \\end{align} which implies that there is an active trail through $X,Y$ and $Z$ in the graph $\\mathcal{G}_2$. Let us consider the minimal one and continue by examining two cases that whether $Z$ is observed. If $Z$ is observed, in $\\mathcal{G}_1$, we have $X\\rightarrow Z\\rightarrow Y$, or $X\\leftarrow Z\\leftarrow Y$, or $X\\leftarrow Z\\rightarrow Y$, while we have $X\\rightarrow Z\\leftarrow Y$ in $\\mathcal{G}_2$, which is a v-structure. To assure that both graphs have the same set of moralities, there exist an edge that directly connects $X$ and $Y$, or in other words, $X,Y,Z$ form a triangle. This contradicts to the claim we have proved in the previous part. If $Z$ is not observed, thus in $\\mathcal{G}_1$, $X,Y,Z$ now must form a v-structure $X\\rightarrow Z\\leftarrow Y$. And also, to guarantee that both graphs have the same moralities, there exists an edge, without loss of generality, we assume $X\\rightarrow Y$. However, this edge will active the trail $X,Y,Z$, or in other words, in $\\mathcal{G}_1$, we now have $(X\\not\\perp Y\\vert Z)$, which is a contradiction of our assumption. Skeleton + Immoralities $\\Leftarrow$ I-equivalence\nConsider two I-equivalent graphs $\\mathcal{G}_1$ and $\\mathcal{G}_2$. First assuming that they do not have that same skeleton. This implies without loss of generality that there exists a trail in $\\mathcal{G}_1$ that does not appear in $\\mathcal{G}_2$, which induces a conditional independence in $\\mathcal{G}_1$ but not in $\\mathcal{G}_2$, contradicts to the fact that they two graphs are I-equivalent. Now assuming that two graphs do not have the same set of moralities. From Distributions to Graphs Given a distribution $P$, how can we represent the independencies of $P$ with a graph $\\mathcal{G}$?\nMinimal I-Maps A graph $\\mathcal{K}$ is a minimal I-map for a set of independencies $\\mathcal{I}$ if it is an I-map for $\\mathcal{I}$, and removing one edge from $\\mathcal{K}$ makes it no longer be an I-map.\nPerfect Maps A graph $\\mathcal{K}$ is a perfect map (or P-map) for a set of independencies $\\mathcal{I}$ if we have that $\\mathcal{I}(\\mathcal{K})=\\mathcal{I}$; and if $\\mathcal{I}(\\mathcal{K})=\\mathcal{I}(P)$, $\\mathcal{K}$ is said to be a perfect map for $P$.\nUndirected Graphical Model Similar to the directed case, each node in an undirected graphical model represents a random variable. However, as indicated from the name, each edge that connects two nodes is now undirected, and thus can not describe causal relationship between those nodes as in Bayesian network.\nMarkov Networks Factors Let $\\mathbf{D}$ be a set of r.v.s. The function $\\phi:\\text{Val}(\\mathbf{D})\\mapsto\\mathbb{R}$ is referred as a factor with the scope $\\mathbf{D}$, denoted $\\mathbf{D}=\\text{Scope}(\\phi)$.\nA factor is nonnegative if all of its entries are nonnegative.\nLet $\\mathbf{X},\\mathbf{Y},\\mathbf{Z}$ be disjoint sets of variables, and let $\\phi_1(\\mathbf{X},\\mathbf{Y})$ and $\\phi_2(\\mathbf{Y},\\mathbf{Z})$ be factors. The product $\\phi_1\\times\\phi_2$ is called a factor product, which is a factor $\\psi:\\text{Val}(\\mathbf{X},\\mathbf{Y},\\mathbf{Z})\\mapsto\\mathbb{R}$, given as \\begin{equation} \\psi(\\mathbf{X},\\mathbf{Y},\\mathbf{Z})=\\phi_1(\\mathbf{X},\\mathbf{Y})\\cdot\\phi_2(\\mathbf{Y},\\mathbf{Z}) \\end{equation}\nFigure 4: (taken from the PGM book) An example of factor product It is worth remarking that both CPDs and joint distribution are factors. As each Bayesian network define a joint distribution factor, which is the product of the CPDs factor. Specifically, let $\\phi_{X_i}(X_i,\\text{Pa}_{X_i})$ denote $P(X\\vert\\text{Pa}_{X_i})$, we can write \\begin{equation} P(X_1,\\ldots,X_n)=\\prod_{i=1}^{n}\\phi_{X_i} \\end{equation}\nMarkov Random Fields Given the notions of factor and factor product, we are now ready to define an undirected parameterization of a distribution.\nAn Undirected Graphical Model (or Markov Random Field, or Markov network) is defined by an undirected graph $\\mathcal{H}$ and a probability distribution $P_\\Phi$ parameterized by a set of factors $\\Phi=\\{\\phi_1(\\mathbf{D}_1),\\ldots,\\phi_K(\\mathbf{D}_K)\\}$ over variables $X_1,\\ldots,X_n$ such that \\begin{equation} P_\\Phi(X_1,\\ldots,X_n)=\\frac{1}{Z}\\tilde{P}_\\Phi(X_1,\\ldots,X_n), \\end{equation} where\nEach node of $\\mathcal{H}$ correspond to a variable $X_i$. The factor product \\begin{equation} \\tilde{P}_\\Phi(X_1,\\ldots,X_n)=\\phi_1(\\mathbf{D}_1)\\times\\ldots\\times\\phi_K(\\mathbf{D}_K) \\end{equation} is an unnormalized measure. $Z$ is a normalizing constant called the partition function, given by \\begin{equation} Z=\\sum_{X_1,\\ldots,X_n}\\tilde{P}_\\Phi(X_1,\\ldots,X_n) \\end{equation} $P_\\Phi$ is also called a Gibbs distribution, which factorizes over $\\mathcal{H}$, in the sense that each $\\mathbf{D}_k$ for $k=1,\\ldots,K$ is a complete subgraph (or clique) of $\\mathcal{H}$. The factors $\\phi_1,\\ldots,\\phi_K$ that parameterize $\\mathcal{H}$ are referred as clique potentials, or potential functions of $\\mathcal{H}$. Reduced Markov Networks Consider the task of conditioning a distribution on some assignment $\\mathbf{u}$ to some subset of variables $\\mathbf{U}$. This task corresponds to the process\nStep 1. Eliminate all entries in the joint distribution that are inconsistent with the event $\\mathbf{U}=\\mathbf{u}$. Step 2. Normalize the remaining entries to sum to $1$. Consider the case that the distribution is in form of $P_\\Phi$ for some set of factor $\\Phi$.\nFactor Reduction Let $\\phi(\\mathbf{Y})$ be a factor, and let $\\mathbf{U}=\\mathbf{u}$ be an assignment for $\\mathbf{U}\\subset\\mathbf{Y}$. The reduction of the factor $\\phi$ to the context $\\mathbf{U}=\\mathbf{u}$, denoted $\\phi[\\mathbf{U}=\\mathbf{u}]$, or $\\phi[\\mathbf{u}]$ for short, is defined to be a factor over scope $\\mathbf{Y}’=\\mathbf{Y}\\backslash\\mathbf{U}$, such that \\begin{equation} \\phi[\\mathbf{u}](\\mathbf{y}’)=\\phi(\\mathbf{y}’,\\mathbf{u}) \\end{equation} For $\\mathbf{U}\\not\\subset\\mathbf{Y}$, we define $\\phi[\\mathbf{u}]$ to be $\\phi[\\mathbf{U}’=\\mathbf{u}’]$ where\n$\\mathbf{U}’=\\mathbf{U}\\cap\\mathbf{Y}$; $\\mathbf{u}’\\doteq\\mathbf{u}[\\mathbf{U}’]$, where $\\mathbf{u}[\\mathbf{U}’]$ denotes the assignment in $\\mathbf{u}$ to the variable in $\\mathbf{U}’$. Example 1: Consider the factor $\\phi$ with $\\text{Scope}(\\phi)=\\{A,B,C\\}$, as given in the right-most table of Figure 4. The reduction of $\\phi$ to the context $C=c^1$ is a factor over scope $\\{A,B,C\\}\\backslash\\{C\\}=\\{A,B\\}$, given by \\begin{equation} \\phi[c^1](a,b)=\\phi(a,b,c^1), \\end{equation} which is illustrated in the following table\nFigure 5: (taken from the PGM book) Factor reduction: The factor computed in Figure 4, reduced to the context $C=c^1$. With the definition of factor reduction, let us consider a product of factors. We have that an entry in the product is consistent with $\\mathbf{u}$ iff it is a product of entries that are all consistent with $\\mathbf{u}$.\nReduced Gibbs Distribution Let $P_\\Phi$ be a Gibbs distribution parameterized by $\\Phi=\\{\\phi_1,\\ldots,\\phi_K\\}$, and let $\\mathbf{u}$ be a context. The reduced Gibbs distribution $P_\\Phi[\\mathbf{u}]$ is the Gibbs distribution defined by the set of factors \\begin{equation} \\Phi[\\mathbf{u}]=\\{\\phi_1[\\mathbf{u}],\\ldots,\\phi_K[\\mathbf{u}]\\} \\end{equation}\nProposition 8: Let $P_\\Phi(\\mathbf{X})$ be a Gibbs distribution, we then have \\begin{equation} P_\\Phi[\\mathbf{u}]=P_\\Phi(\\mathbf{W}\\vert\\mathbf{u}), \\end{equation} where $\\mathbf{W}=\\mathbf{X}\\backslash\\mathbf{U}$.\nReduced Markov Network Let $\\mathcal{H}$ be a Markov network over the nodes $\\mathbf{X}$ and $\\mathbf{U}=\\mathbf{u}$ be a context. The reduced Markov network $\\mathcal{H}[\\mathbf{u}]$ is a Markov network over the nodes $\\mathbf{W}=\\mathbf{X}\\backslash\\mathbf{U}$, where we have an edge $X-Y$ if there is an edge $X-Y$ in $\\mathcal{H}$.\nProposition 9: Let $P_\\Phi(\\mathbf{X})$ be a Gibbs distribution that factorizes over $\\mathcal{H}$, and let $\\mathbf{U}=\\mathbf{u}$ be a context. Then we have that $P_\\Phi[\\mathbf{u}]$ factorizes over $\\mathcal{H}[\\mathbf{u}]$.\nFigure 6: (taken from the PGM book) An example of a Markov network and the reduction of its factors to some contexts (a) The initial Markov network; (b) The reduced network to the context $G=g$; (c) The reduced network to the context $G=g,S=s$. Independencies in Markov Network Analogy to Bayesian network, the graph structure in a Markov Random Field can be viewed as encoding a set of independence assumptions, which can be specified by considering the undirected paths through nodes.\nSeparation Let $\\mathcal{H}$ be a Markov network structure and let $X_1-\\ldots-X_k$ be a path in $\\mathcal{H}=(\\mathcal{X},\\mathcal{E})$. Let $\\mathbf{Z}\\subset\\mathcal{X}$ be a set of observed variables. Then $X_1-\\ldots-X_k$ is active given $\\mathbf{Z}$ if none of $X_1,\\ldots,X_k$ is in $\\mathbf{Z}$.\nLet $\\mathbf{X},\\mathbf{Y}$ be set of nodes in $\\mathcal{H}$. We say that $\\mathbf{Z}$ separates $\\mathbf{X}$ and $\\mathbf{Y}$, denoted $\\text{sep}_\\mathcal{H}(\\mathbf{X};\\mathbf{Y}\\vert\\mathbf{Z})$ if there is no active path between any node $X\\in\\mathbf{X}$ and $Y\\in\\mathbf{Y}$ given $\\mathbf{Z}$.\nGlobal Markov Independencies As in the case of Bayesian network, we define the global Markov independencies associated with $\\mathcal{H}$, denoted $\\mathcal{I}(\\mathcal{H})$, to be the set of all independencies correspond to separation in $\\mathcal{H}$ \\begin{equation} \\mathcal{I}(\\mathcal{H})=\\big\\{(\\mathbf{X}\\perp\\mathbf{Y}\\vert\\mathbf{Z}):\\text{sep}_\\mathcal{H}(\\mathbf{X};\\mathbf{Y}\\vert\\mathbf{Z})\\big\\} \\end{equation}\nLocal Markov Independencies Let $\\mathcal{H}$ be a Markov network. We define the pairwise independencies associated with $\\mathcal{H}$ to be \\begin{equation} \\mathcal{I}_p(\\mathcal{H})=\\big\\{(X\\perp Y\\vert\\mathcal{X}\\backslash\\{X,Y\\}):X-Y\\notin\\mathcal{H}\\big\\} \\end{equation} Or in other words, the pairwise independencies states that $X$ and $Y$ are independent given all other nodes in $\\mathcal{H}$.\nFor a given graph $\\mathcal{H}$ and for an arbitrary node $X$ of $\\mathcal{H}$, the set of neighbors of $X$ is also called the Markov blanket of $X$, denoted $\\text{MB}_\\mathcal{H}(X)$. With this notion, we define the local independencies, or Markov local independencies, associated with $\\mathcal{H}$ to be \\begin{equation} \\mathcal{I}_\\ell(\\mathcal{H})=\\big\\{\\big(X\\perp\\mathcal{X}\\backslash(\\{X\\}\\cup\\text{MB}_\\mathcal{H}(X))\\vert\\text{MB}_\\mathcal{H}(X)\\big):X\\in\\mathcal{X}\\big\\} \\end{equation} Or in other words, the Markov local independencies says that $X$ is independent of the rest of the nodes in $\\mathcal{H}$ given its neighbors.\nThe definition of Markov blanket can also be rewritten using independencies assertions:\nA set $\\mathbf{U}$ is a Markov blanket of $X$ in a distribution $P$ if $X\\notin\\mathbf{U}$ and if $\\mathbf{U}$ is a minimal set of nodes such that \\begin{equation} \\big(X\\perp\\mathcal{X}\\backslash(\\{X\\}\\cup\\mathbf{U})\\vert\\mathbf{U}\\big)\\in\\mathcal{I}(P) \\end{equation}\nMarkov Independencies Relationships Theorem 10: Let $\\mathcal{H}$ be a Markov network and $P$ be a positive distribution. The following three statement are then equivalent:\n$P\\models\\mathcal{I}_\\ell(\\mathcal{H})$. $P\\models\\mathcal{I}_p(\\mathcal{H})$. $P\\models\\mathcal{I}(\\mathcal{H})$. Proof\n(i) $\\Rightarrow$ (ii)\nConsider an arbitrary node $X$ in $\\mathcal{H}$. Let $Y\\in\\mathcal{X}$ such that $X-Y\\notin\\mathcal{H}$, then $Y\\notin\\text{MB}_\\mathcal{H}(X)$, or in other words \\begin{equation} Y\\in\\mathcal{X}\\backslash(\\{X\\}\\cup\\text{MB}_\\mathcal{H}(X)) \\end{equation} Moreover, since $P\\models\\mathcal{I}_\\ell(\\mathcal{H})$, we have that $P$ satisfies \\begin{equation} \\big(X\\perp\\mathcal{X}\\backslash(\\{X\\}\\cup\\text{MB}_\\mathcal{H}(X))\\vert\\text{MB}_\\mathcal{H}(X)\\big), \\end{equation} which implies that \\begin{equation} \\big(X\\perp Y\\vert\\text{MB}_\\mathcal{X}\\cup\\mathcal{X}\\backslash(\\{X,Y\\}\\cup\\text{MB}_\\mathcal{H}(X))\\big) \\end{equation} holds for $P$. Or in other words, for any $X,Y$ such that $X-Y\\notin\\mathcal{H}$, we have \\begin{equation} P\\models(X\\perp Y\\vert\\mathcal{X}\\backslash\\{X,Y\\}), \\end{equation} which proves our claim. (ii) $\\Rightarrow$ (iii) (iii) $\\Rightarrow$ (i)\nThis follows directly from the fact that if two nodes $X$ and $Y$ are not connected, then they are necessarily separated by all remaining nodes of the graph. Soundness, Completeness Theorem 11 (Soundness of separation) Let $\\mathcal{H}=(\\mathcal{X},\\mathcal{E})$ be a Markov network structure and let $P$ be a distribution over $\\mathcal{X}$. If $P$ is a Gibbs distribution that factorizes over $\\mathcal{H}$, then $\\mathcal{H}$ is an I-map for $P$.\nProof\nLet $\\mathbf{X},\\mathbf{Y}$ and $\\mathbf{Z}$ be any disjoint subsets of $\\mathcal{X}$ such that $\\text{sep}_\\mathcal{H}(\\mathbf{X};\\mathbf{Y}\\vert\\mathbf{Z})$. We need to show that \\begin{equation} P\\models(\\mathbf{X}\\perp\\mathbf{Y}\\vert\\mathbf{Z}) \\end{equation} We begin by considering the case that $\\mathbf{X}\\cup\\mathbf{Y}\\cup\\mathbf{Z}=\\mathcal{X}$. Since $\\mathbf{Z}$ separates $\\mathbf{X}$ and $\\mathbf{Y}$, then for any $X\\in\\mathbf{X}$ and for any $Y\\in\\mathbf{Y}$, there is no direct edge between $X,Y$. This implies that any clique in $\\mathcal{H}$ is either in $\\mathbf{X}\\cup\\mathbf{Z}$ or in $\\mathbf{Y}\\cup\\mathbf{Z}$.\nLet $I_\\mathbf{X}$ denote the indices of the set of cliques within $\\mathbf{X}\\cup\\mathbf{Z}$ and let $I_\\mathbf{Y}$ represent the indices of the ones in $\\mathbf{Y}\\cup\\mathbf{Z}$. Thus, as $P$ factorizes over $\\mathcal{H}$, we have that \\begin{align} P(X_1,\\ldots,X_n)\u0026=\\frac{1}{Z}\\prod_{i}\\phi_i(\\mathbf{D}_i) \\\\ \u0026=\\frac{1}{Z}\\left(\\prod_{i\\in I_\\mathbf{X}}\\phi_i(\\mathbf{D}_i)\\right)\\cdot\\left(\\prod_{i\\in I_\\mathbf{Y}}\\phi_i(\\mathbf{D}_i)\\right) \\\\ \u0026=\\frac{1}{Z}\\phi_\\mathbf{X}(\\mathbf{X},\\mathbf{Z})\\phi_\\mathbf{Y}(\\mathbf{Y},\\mathbf{Z}), \\end{align} where $\\phi_\\mathbf{X},\\phi_\\mathbf{Y}$ are some factors with scopes $\\mathbf{X}\\cup\\mathbf{Z}$ and $\\mathbf{Y}\\cup\\mathbf{Z}$ respectively. Hence, it follows that \\begin{equation} P\\models(\\mathbf{X}\\perp\\mathbf{Y}\\vert\\mathbf{Z}) \\end{equation} Now consider the case that $\\mathbf{X}\\cup\\mathbf{Y}\\cup\\mathbf{Z}\\subset\\mathcal{X}$. Let $\\mathbf{U}=\\mathcal{X}\\backslash(\\mathbf{X}\\cup\\mathbf{Y}\\cup\\mathbf{Z})$. We can divide $\\mathbf{U}$ into two disjoint sets $\\mathbf{U}_1$ and $\\mathbf{U}_2$ such that \\begin{equation} \\text{sep}_\\mathcal{H}(\\mathbf{X}\\cup\\mathbf{U}_1;\\mathbf{Y}\\cup\\mathbf{U}_2\\vert\\mathbf{Z}) \\end{equation} And since $(\\mathbf{X}\\cup\\mathbf{U}_1)\\cup(\\mathbf{Y}\\cup\\mathbf{U}_2)\\cup\\mathbf{Z}=\\mathcal{X}$, we can follow the previous procedure to conclude that \\begin{equation} P\\models(\\mathbf{X}\\cup\\mathbf{U}_1\\perp\\mathbf{Y}\\cup\\mathbf{U}_2\\vert\\mathbf{Z}), \\end{equation} which implies that \\begin{equation} P\\models(\\mathbf{X}\\perp\\mathbf{Y}\\vert\\mathbf{Z}) \\end{equation}\nTheorem 12 (Hammersley-Clifford) Let $\\mathcal{H}=(\\mathcal{X},\\mathcal{E})$ be a Markov network structure and let $P$ be a positive distribution over $\\mathcal{X}$. If $\\mathcal{H}$ is an I-map for $P$, then $P$ is a Gibbs distribution that factorizes over $\\mathcal{H}$.\nCorollary 13: The positive distribution $P$ factorizes a Markov network $\\mathcal{H}$ iff $\\mathcal{H}$ is an I-map for $P$.\nTheorem 14 (Completeness of separation) Let $\\mathcal{H}$ be a Markov network structure. If $X$ and $Y$ are not separated given $\\mathbf{Z}$ in $\\mathcal{H}$, then $X$ and $Y$ are dependent given $\\mathbf{Z}$ in some distribution $P$ that factorizes over $\\mathcal{H}$.\nFrom Distributions to Graphs As mentioned above, the notion of minimal I-map lets us encode the independencies of a given distribution $P$ using a graph structure.\nIn particular, for a distribution $P$, we can construct the minimal I-map based on either the pairwise independencies or the local independencies.\nTheorem 15: Let $P$ be a positive distribution and $\\mathcal{H}$ be a Markov network defined by including an edge $X-Y$ for all $X,Y$ such that $P\\not\\models(X\\perp Y\\vert\\mathcal{X}\\backslash\\{X,Y\\}) $. Then $\\mathcal{H}$ is the unique minimal I-map for $P$.\nTheorem 16: Let P be a positive distribution and let $\\mathcal{H}$ be a Markov network defined by including an edge $X-Y$ for all $X$ and all $Y\\in\\text{MB}_\\mathcal{H}(X)$. Then $\\mathcal{H}$ is the unique minimal I-map for $P$.\nRemark: Not every distribution has a perfect map as UGM (proof by contradiction).\nFactor Graphs A factor graph $\\mathcal{F}$ is an undirected graph whose nodes are divided into two groups: variable nodes (denoted as ovals) and factor nodes (denoted as squares) and whose edges only connect each factor (potential function) $\\psi_c$ to its dependent nodes $X\\in X_c$.\nFigure 7: (based on figure from the PGM book) Different factor graphs for the same Markov network: (a) A Markov network consists of nodes $X_1,X_2,X_3$; (b) A factor graph with a factor $\\psi_{1,2,3}$ connected to each $X_1,X_2,X_3$; (c) A factor graph with three pairwise factors $\\psi_{1,2}$ (connected to $X_1,X_2$), $\\psi_{1,3}$ (connected to $X_1,X_3$) and $\\psi_{2,3}$ (connected to $X_2,X_3$) Log-Linear Models A distribution $P$ is a log-linear model over a Markov network $\\mathcal{H}$ if it is associated with\na set of features $\\mathcal{F}=\\{\\phi_1(\\mathbf{X}_1),\\ldots,\\phi_k(\\mathbf{X}_k)\\}$ where each $\\mathbf{X}_i$ is a complete subgraph in $\\mathcal{H}$, a set of weight $w_1,\\ldots,w_k$, such that \\begin{equation} P(X_1,\\ldots,X_n)=\\frac{1}{Z}\\exp\\left[-\\sum_{i=1}^{k}w_i\\phi_i(\\mathbf{X}_i)\\right] \\end{equation} The function $\\phi_i$ are called energy functions.\nCanonical Parameterization The canonical parameterization of a Gibbs distribution over $\\mathcal{H}$ is defined via a set of energy functions over all cliques. For instance, the Markov network given in Figure 7(a) would have energy functions for each of the cliques \\begin{equation} \\{\\{X_1,X_2,X_3\\},\\{X_1,X_2\\},\\{X_2,X_3\\},\\{X_1,X_3\\},\\{X_1\\},\\{X_2\\},\\{X_3\\}\\}, \\end{equation} plus a constant energy function for the empty clique.\nBayesian \u0026 Markov Networks We are ready to derive the relationship between representations: Bayesian network and Markov network. Specifically, we can find a Bayesian network which is a minimal I-map for a given Markov network and vice versa.\nBayesian Networks to Markov Networks Let us begin by considering a distribution $P_\\mathcal{B}$, where $\\mathcal{B}$ is a parameterized network over a graph $\\mathcal{G}$. Then, $P_\\mathcal{B}$ can be seen as a Gibbs distribution by considering each CPD $P(X_i\\vert\\text{Pa}_{X_i})$ as a factor with scope $X_i,\\text{Pa}_{X_i}$. This Gibbs distribution then has $1$ as its partition function.\nProposition 17: Let $\\mathcal{B}$ be a Bayesian network over $\\mathcal{X}$ and let $\\mathbf{E}=\\mathbf{e}$ be an observation. Let $\\mathbf{W}=\\mathcal{X}\\backslash\\mathbf{E}$. Then $P_\\mathcal{B}(\\mathbf{W}\\vert\\mathbf{e})$ is a Gibbs distribution, defined by the factors $\\Phi=\\{\\phi_{X_i}\\}_{X_i\\in\\mathcal{X}}$, where \\begin{equation} \\phi_{X_i}=P_\\mathcal{B}(X_i\\vert\\text{Pa}_{X_i})[\\mathbf{E}=\\mathbf{e}] \\end{equation} The partition function for this Gibbs distribution is $P(\\mathbf{e})$.\nThis result lets us consider any Bayesian network conditioned as evidence $\\mathbf{e}$ as a Gibbs distribution with partion function $P(\\mathbf{e})$.\nTo find the undirected graph serving as an I-map for a set of factors in a Bayesian network, we recall that we have considered each CPD $P(X_i\\vert\\text{Pa}_{X_i})$ as a factor with scope $X_i,\\text{Pa}_{X_i}$, in the undirected I-map. Therefore, in the undirected I-map, we need to have an edge between $X_i$ and each of its parents, as well as between all of the parents of $X_i$ (due to each factor corresponds to a clique).\nMoralized Graph The moral graph $\\mathcal{M}[\\mathcal{G}]$ of a Bayesian network structure $\\mathcal{G}$ over $\\mathcal{X}$ is the undirected graph over $\\mathcal{X}$ that consists of an undirected edge between $X$ and $Y$ if\nthere is a directed edge between them (in either direction), or $X$ and $Y$ are both parents of the same node. Figure 8: (based on figure from the PGM book) A Bayesian network and its moral graph: (a) A Bayesian network; (b) The moral graph established by converting directed edges into undirected, plus adding edges between non-connected nodes which are both parents of the same nodes (newly created edges are denoted as $\\color{red}{red}$ color) The construction of moral graphs follows directly to a result.\nCorollary 18: Let $\\mathcal{G}$ be a BN graph. Then for any distribution $P_\\mathcal{B}$ such that $\\mathcal{B}$ is a parameterization of $\\mathcal{G}$, we have that $\\mathcal{M}[\\mathcal{G}]$ is an I-map for $P_\\mathcal{B}$.\nProposition 19: Let $\\mathcal{G}$ be any BN graph. The moralized graph $\\mathcal{M}[\\mathcal{G}]$ is a minimal I-map for $\\mathcal{G}$.\nProof\nWe begin by introducing the notion of Markov blanket in a Bayesian network $\\mathcal{G}$.\nDefinition (Markov blanket in BN) The Markov blanket of a node $X\\in\\mathcal{X}$ in a Bayesian network $\\mathcal{G}$, denoted $\\text{MB}_\\mathcal{G}(X)$, is the set of $X$’s parents, $X$’s children, and other parents of $X$’s children.\nLet $X\\in\\mathcal{X}$ be a node of $\\mathcal{G}$, we have that $\\text{MB}_\\mathcal{G}(X)$ d-separates $X$ from all other variables in $\\mathcal{G}$; and that no subset of $\\text{MB}_\\mathcal{G}(X)$ has that property. Specifically:\nLet $\\mathbf{W}=\\mathcal{X}\\backslash\\big(\\{X\\}\\cup\\text{MB}_\\mathcal{G}(X)\\big)$, and let $Z\\in\\text{MB}_\\mathcal{G}(X)$ be some node in the Markov blanket of $X$. Then for each $Y\\in\\mathbf{W}$ that connected to $X$ via a trail, we have three possible cases: \\begin{equation} X\\rightarrow Z\\rightarrow Y;X\\leftarrow Z\\leftarrow Y;X\\leftarrow Z\\rightarrow Y \\end{equation} The v-structure is excluded due to the definition of $\\text{MB}_\\mathcal{G}(X)$, i.e. if $X\\rightarrow Z\\leftarrow Y$ exists, then $Y\\in\\text{MB}_\\mathcal{G}(X)$. As $\\text{MB}_\\mathcal{G}(X)$ is given, $Z$ is observed, all of those 2-edge trails are then in-active, which implies that $\\text{d-sep}_\\mathcal{G}(X;Y\\vert Z)$, and thus $\\text{d-sep}_\\mathcal{G}(X;\\mathbf{W}\\vert\\text{MB}_\\mathcal{G}(X))$. As we have mentioned above that if a v-structure exists, then $Y$ must be in the Markov blanket of $X$, it follows directly that $\\text{MB}_\\mathcal{G}(X)$ is the minimal set having the property. Thus, in other words, we can conclude that the Markov blanket of $X$, $\\text{MB}_\\mathcal{G}(X)$, the smallest set required to render $X$ independent of all other nodes in $\\mathcal{G}$. For each $X\\in\\mathcal{X}$, by viewing its Markov blanket in $\\mathcal{G}$ as the set of its neighbors in an undirected graph $\\mathcal{H}$ (which is the definition of Markov blanket in a Markov network), we then have that $\\mathcal{H}$ is a minimal I-map for $\\mathcal{G}$. Additionally, by how it is constructed, $\\mathcal{H}$ is also a moral graph of $\\mathcal{G}$, and thus $\\mathcal{I}(\\mathcal{H})\\subset\\mathcal{I}(\\mathcal{G})$.\nRemark:\nThe addition of the moralizing edges to the Markov network $\\mathcal{H}$ leads to the loss of independence information implied by $\\mathcal{G}$. However, moralization causes loss of independencies assertions only when it introduces new edges into the graph. Proposition 20: If the directed graph $\\mathcal{G}$ is moral (in the sense that it contains no immoralities, i.e. for any pair of $X,Y$ in $\\mathcal{G}$ sharing a child, there is a covering edge between $X$ and $Y$), then its moralized graph $\\mathcal{M}[\\mathcal{G}]$, which now has the same edges as $\\mathcal{G}$, is a perfect map of $\\mathcal{G}$.\nIn other words, this result states that a moral graph $\\mathcal{G}$ can be converted to a Markov network without losing independencies assertions.\nProof\nLet $\\mathcal{H}=\\mathcal{M}[\\mathcal{G}]$, then $\\mathcal{H}$ and $\\mathcal{G}$ have the same edges. As in Proposition 19, we have shown that $\\mathcal{I}(\\mathcal{H})\\subset\\mathcal{I}(\\mathcal{G})$, our problem remains to prove that $\\mathcal{I}(\\mathcal{H})\\supset\\mathcal{I}(\\mathcal{G})$.\nAssume that there is an independence \\begin{equation} (\\mathbf{X}\\perp\\mathbf{Y}\\vert\\mathbf{Z})\\in\\mathcal{I}(\\mathcal{G}), \\end{equation} which is not in $\\mathcal{I}(\\mathcal{H})$. This implies that there exists some active trail from $\\mathbf{X}$ to $\\mathbf{Y}$ given $\\mathbf{Z}$ in $\\mathcal{H}$. Consider some such trail which is minimal. As $\\mathcal{H},\\mathcal{G}$ have same edges, the same trail must also exist in $\\mathcal{G}$. Thus, it is also in-active in $\\mathcal{G}$ given $\\mathbf{Z}$, which implies that it contains a v-structure, say $X_1\\rightarrow X_2\\leftarrow X_3$. Moreover, as $\\mathcal{G}$ is moral, there exists an edge connecting $X_1$ and $X_3$, contradicts the assumption that the trail is minimal.\nMarkov Networks to Bayesian Networks Theorem 21: Let $\\mathcal{H}$ be a Markov network graph, and let $\\mathcal{G}$ be any Bayesian network minimal I-map for $\\mathcal{H}$. Then $\\mathcal{G}$ can have no immoralities.\nConditional Random Fields A conditional random field, or CRF, is an undirected graph $\\mathcal{H}$ whose nodes correspond to $\\mathbf{X}\\cup\\mathbf{Y}$ where $\\mathbf{X}$ is a set of observed variables and $\\mathbf{Y}$ is a (disjoint) set of target variables which specifies a conditional distribution (instead of a joint distribution) \\begin{equation} P(\\mathbf{Y}\\vert\\mathbf{X})=\\frac{1}{Z(\\mathbf{X})}\\prod_{c\\in C}\\psi_c(\\mathbf{X}_c,\\mathbf{Y}_c), \\end{equation} where the partition function $Z(\\mathbf{X})$ now depends on $\\mathbf{X}$ (rather than being a constant) \\begin{equation} Z(\\mathbf{X})=\\sum_\\mathbf{Y}\\prod_{c\\in C}\\psi_c(\\mathbf{X}_c,\\mathbf{Y}_c) \\end{equation}\nExample - Naive Markov Consider a CRF over the binary-value variables $\\mathbf{X}=\\{X_1,\\ldots,X_k\\}$ and $\\mathbf{Y}=\\{Y\\}$, and a pairwise potential between $Y$ and each $X_i$. The model is referred as a naive Markov model. Assume that the pairwise potentials defined via the log-linear model \\begin{equation} \\psi_i(X_i,Y)=\\exp\\big[w_i\\mathbf{1}\\{X_i=1,Y=1\\}\\big] \\end{equation} Additionally, we also have a single-node potential \\begin{equation} \\psi_0(Y)=\\exp\\big[w_0\\mathbf{1}\\{Y=1\\}\\big] \\end{equation} We then have that \\begin{equation} P(Y=1\\vert x_1,\\ldots,x_k)=\\frac{1}{1+\\exp\\left[-\\left(w_0+\\sum_{i=1}^{k}w_i x_i\\right)\\right]} \\end{equation}\nLocal Probabilistic Models Tabular CPDs For a space of discrete-valued random variables only, we can encode the CPDs $P(X\\vert\\text{Pa}_X)$ as a table where each entry corresponds to a pair of $X,\\text{Pa}_X$.\nIt is easily seen that this representation raises a disadvantage that the number of parameters required grows exponentially in the number of parents. Also, it is impossible to store the conditional probability corresponding to a continuous-valued random variables.\nTo avoid these problems, instead of viewing CPDs as tables listing all of the conditional probabilities $P(x\\vert\\text{pa}_X)$, we should consider them as functions that given $\\text{pa}_X$ and $x$, return the conditional probability $P(x\\vert\\text{pa}_X)$.\nDeterministic CPDs The simplest type of non-tabular CPD corresponds to a variable $X$ being a deterministic function of its parents $\\text{Pa}_X$. It means, there exists $f:\\text{Val}(Pa_X)\\mapsto\\text{Val}(X)$ such that \\begin{equation} P(x\\vert\\text{pa}_X)=\\begin{cases}1\u0026\\hspace{1cm}x=f(\\text{pa}_X) \\\\ 0\u0026\\hspace{1cm}\\text{otherwise}\\end{cases} \\end{equation} Deterministic variables are denoted as double-line ovals, as illustrated in the following example\nFigure 9: (taken from the PGM book) A network with $C$ being a deterministic function of $A$ and $B$. Consider the above figure, as $C$ being a deterministic function of $A$ and $B$, we can deduce that $C$ is fully observed if $A$ and $B$ are both observed. In other words, we have that \\begin{equation} (D\\perp E\\vert A,B) \\end{equation}\nTheorem 22: Let $\\mathcal{G}$ be a network structure, and let $\\mathbf{X},\\mathbf{Y},\\mathbf{Z}$ be sets of variables, $\\mathbf{D}$ be set of deterministic variables. If $\\mathbf{X}$ is deterministically separated from $\\mathbf{Y}$ given $\\mathbf{Z}$3, then for all distributions $P$ such that $P\\models\\mathcal{I}_\\ell(\\mathcal{G})$ and where, for each $X\\in\\mathbf{D}$, $P(X\\vert\\text{Pa}_X)$ is a deterministic CPD, we have that $P\\models(\\mathbf{X}\\perp\\mathbf{Y}\\vert\\mathbf{Z})$.\nTheorem 23: Let $\\mathcal{G}$ be a network structure, and let $\\mathbf{X},\\mathbf{Y},\\mathbf{Z}$ be sets of variables, $\\mathbf{D}$ be set of deterministic variables. If $\\mathbf{X}$ is not deterministically separated from $\\mathbf{Y}$ given $\\mathbf{Z}$, then there exists a distribution $P$ such that $P\\models\\mathcal{I}_\\ell(\\mathcal{G})$ and where, for each $X\\in\\mathbf{D}$, $P(X\\vert\\text{Pa}_X)$ is a deterministic CPD, but we instead have $P\\not\\models(\\mathbf{X}\\perp\\mathbf{Y}\\vert\\mathbf{Z})$.\nIt is worth remarking that particular deterministic CPD might imply additional independencies. For instance, let us consider the following examples\nExample 2: Consider the following Bayesian network\nFigure 10: (taken from the PGM book) Another Bayesian network with $C$ being a deterministic function of $A$ and $B$. In the above figure, if $C=A\\text{ XOR }B$, we have that $A$ is fully determined given $C$ and $B$. In other words, we have that \\begin{equation} (D\\perp E\\vert B,C) \\end{equation} Example 3: Consider the network given in Figure 9, with $C=A\\text{ OR }B$. Assume that we are given $A=a^1$, it is then immediately that $C=c^1$ without taking into account the value of $B$. Or in other words, we have that \\begin{equation} P(D\\vert B,a^1)=P(D\\vert a^1) \\end{equation} On the other hand, given $A=a^0$, the value of $C$ is not fully determined, and still depend the value of $B$.\nContext-Specific Independence Let $\\mathbf{X},\\mathbf{Y},\\mathbf{Z}$ be pairwise disjoint sets of variables, let $\\mathbf{C}$ be a set of variable (which might overlap with $\\mathbf{X}\\cup\\mathbf{Y}\\cup\\mathbf{Z}$), and let $\\mathbf{c}\\in\\text{Val}(\\mathbf{C})$. We say that $X$ and $\\mathbf{Y}$ are contextually independent given $\\mathbf{Z}$ and the context $\\mathbf{C}$ denoted $(\\mathbf{X}\\perp_c\\mathbf{Y}\\vert\\mathbf{Z},\\mathbf{c})$ if \\begin{equation} P(\\mathbf{Y},\\mathbf{Z},\\mathbf{c})\u003e0\\Rightarrow P(\\mathbf{X}\\vert\\mathbf{Y},\\mathbf{Z},\\mathbf{c})=P(\\mathbf{X}\\vert\\mathbf{Z},\\mathbf{c}) \\end{equation} Independence statements of this form is known as the context-specific independencies (CSI).\nGiven this definition, let us examine some examples.\nExample 4: Given the Bayesian network in Figure 9 with $C$ being a deterministic function $\\text{OR}$ of $A$ and $B$. By properties of $\\text{OR}$ function, we can conclude some independence assertions \\begin{align} \u0026(C\\perp_c B\\hspace{0.1cm}\\vert\\hspace{0.1cm}a^1), \\\\ \u0026(D\\perp_c B\\hspace{0.1cm}\\vert\\hspace{0.1cm}a^1), \\\\ \u0026(A\\perp_c B\\hspace{0.1cm}\\vert\\hspace{0.1cm}c^0), \\\\ \u0026(D\\perp_c E\\hspace{0.1cm}\\vert\\hspace{0.1cm}c^0), \\\\ \u0026(D\\perp_c E\\hspace{0.1cm}\\vert\\hspace{0.1cm}b^0,c^1) \\end{align} Example 5: Given the Bayesian network in Figure 10 with $C$ being the exclusive or of $A$ and $B$. We can also conclude some independence assertions using properties of $\\text{XOR}$ function \\begin{align} \u0026(D\\perp_c E\\hspace{0.1cm}\\vert\\hspace{0.1cm}b^1,c^0), \\\\ \u0026(D\\perp_c E\\vert\\hspace{0.1cm}b^0,c^1) \\end{align}\nContext-specific CPDs Tree-CPDs A tree-CPD representing a CPD for variable $X$ is a rooted tree, where:\neach leaf node is labeled with a distribution $P(X)$; each internal node is labeled with some variable $Z\\in\\text{Pa}_X$; each edge from an internal node, which is labeled as some $Z$, to its child nodes corresponds to a $z_i\\in\\text{Val}(Z)$. Figure 11: (taken from the PGM book) A tree-CPD for $P(J\\vert A,S,L)$. The structure is common in cases where a variable can depend on a set of r.v.s but we have uncertainty about which r.v.s it depends on. For example, in the above tree-CDP representing $P(J\\vert A,S,L)$, we have that \\begin{align} \u0026(J\\perp_c L,S\\vert\\hspace{0.1cm}a^0), \\\\ \u0026(J\\perp_c L\\vert\\hspace{0.1cm}a^1,s^1), \\\\ \u0026(J\\perp_c L\\vert\\hspace{0.1cm}s^1) \\end{align}\nMultiplexer CPD A CPD $P(Y\\vert A,Z_1,\\ldots,Z_k)$ is said to be a multiplexer CPD if $\\text{Val}(A)=\\{1,\\ldots,k\\}$ and \\begin{equation} P(Y\\vert a,Z_1,\\ldots,Z_k)=\\mathbf{1}\\{Y=Z_a\\}, \\end{equation} where $a$ is the value of $A$. The variable $A$ is referred as the selector variable for the CPD.\nFigure 12: (based on figure from the PGM book) (a) A Bayesian network for $P(J,C,L_1,L_2)$; (b) Tree-CPD for $P(J\\vert C,L_1,L_2)$; (c) Modified network with additional variable $L$ acting as a multiplexer CPD. Rule CPDs A rule $\\rho$ is a pair $(\\mathbf{c},p)$ where $\\mathbf{c}$ is an assignment to some subset of variables $\\mathbf{C}$ and $p\\in[0,1]$. $\\mathbf{C}$ is then referred as the scope of $\\rho$, denoted $\\mathbf{C}=\\text{Scope}(\\rho)$.\nThis representation decomposes a tree-CPD into its most basic elements.\nExample 6: Consider the tree-CPD given in Figure 11. The tree defines eight rules \\begin{equation} \\left\\{\\begin{array}{l}(a^0,j^0;0.8), \\\\ (a^0,j^1;0.2), \\\\ (a^1,s^0,l^0,j^0;0.9), \\\\ (a^1,s^0,l^0,j^1;0.1), \\\\ (a^1,s^0,l^1,j^0;0.4), \\\\ (a^1,s^0,l^1,j^1;0.6), \\\\ (a^1,s^1,j^0;0.1), \\\\ (a^1,s^1,j^1;0.9)\\end{array}\\right\\} \\end{equation} It is necessary that each conditional distribution $P(X\\vert\\text{Pa}_X)$ is specified by exactly one rule. Or in other words, the rules in a tree-CPD must be mutually exclusive and exhaustive.\nRule-based CPD A rule-based CPD $P(X\\vert\\text{Pa}_X)$ is a set of rules $\\mathcal{R}$ such that\nFor each $\\rho\\in\\mathcal{R}$, we have that \\begin{equation} \\text{Scope}(\\rho)\\subset\\{X\\}\\cup\\text{Pa}_X \\end{equation} For each assignment $(x,\\mathbf{u})$ to $\\{X\\}\\cup\\text{Pa}_X$, we have exactly one rule $(\\mathbf{c};p)\\in\\mathcal{R}$ such that $\\mathbf{c}$ is compatible with $(x,\\mathbf{u})$. And we say that \\begin{equation} P(X=x\\vert\\text{Pa}_X=\\mathbf{u})=p \\end{equation} $\\sum_x P(x\\vert\\mathbf{u})=1$. Example 7: Let $X$ be a variable with $\\text{Pa}_X=\\{A,B,C\\}$ with $X$’s CPD is defined by sets of rules \\begin{equation} \\left\\{\\begin{array}{l}\\rho_1:(a^1,b^1,x^0;0.1), \\\\ \\rho_2:(a^1,b^1,x^1;0.9), \\\\ \\rho_3:(a^0,c^1,x^0;0.2), \\\\ \\rho_4:(a^0,c^1,x^1;0.8), \\\\ \\rho_5:(b^0,c^0,x^0;0.3), \\\\ \\rho_6:(b^0,c^0,x^1;0.7), \\\\ \\rho_7:(a^1,b^0,c^1,x^0;0.4), \\\\ \\rho_8:(a^1,b^0,c^1,x^1;0.6), \\\\ \\rho_9:(a^0,b^1,c^0;0.5)\\end{array}\\right\\} \\end{equation} The tree-CPD corresponds to the above rule-based CPD $P(X\\vert A,B,C)$ is given as:\nIt is worth noticing that both CPD entries $P(x^0\\vert a^0,b^1,c^0)$ and $P(x^1\\vert a^0,b^1,c^0)$ are determined by rule $\\rho_9$ only. This kind of rule only works for uniform distribution. Independencies in Context-specific CPDs If $\\mathbf{c}$ be a context associated with a branch in the tree-CPD for $X$, then $X$ is independent of the remaining parents, $\\text{Pa}_X\\backslash\\text{Scope}(\\mathbf{c})$, given $\\mathbf{c}$. Moreover, there might exist CSI statements conditioned on contexts which are not induced by complete branches.\nExample 8: Consider the tree-CPD given in Figure 11, as mentioned above, we have that \\begin{equation} (J\\perp_c L\\hspace{0.1cm}\\vert\\hspace{0.1cm}s^1), \\end{equation} where $s^1$ is not the full assignment associated with a branch.\nAlso, consider the tree-CPD given in Figure 12(b), we have that \\begin{align} \u0026(J\\perp_c L_2\\hspace{0.1cm}\\vert\\hspace{0.1cm}c^1), \\\\ \u0026(J\\perp_c L_1\\hspace{0.1cm}\\vert\\hspace{0.1cm}c^2), \\end{align} where neither $c^1$ nor $c^2$ is the full assignment associated with a branch.\nReduced Rule Let $\\rho=(\\mathbf{c}’;p)$ be a rule and $\\mathbf{c}$ be a context. If $\\mathbf{c}’$ is compatible with $\\mathbf{c}$, we say that $\\rho\\sim\\mathbf{c}$.\nIn this case, let $\\mathbf{c}’’$ be the assignment in $c’$ to the variables in $\\text{Scope}(\\mathbf{c}’)\\backslash\\text{Scope}(\\mathbf{c})$. We then define the reduced rule $\\rho[\\mathbf{c}]=(\\mathbf{c}’’;p)$. If $\\mathcal{R}$ be a set of rules, we define the reduced rule set \\begin{equation} \\mathcal{R}[\\mathbf{c}]=\\{\\rho[\\mathbf{c}]:\\rho\\in\\mathcal{R},\\rho\\sim\\mathbf{c}\\} \\end{equation}\nExample 9: Consider the rule set $\\mathcal{R}$ given in Example 7, we have that the reduced set corresponding to context $a^1$ is \\begin{equation} \\mathcal{R}[a^1]=\\left\\{\\begin{array}{l}\\rho_1’:(b^1,x^0;0.1), \\\\ \\rho_2:(b^1,x^1;0.9), \\\\ \\rho_5:(b^0,c^0,x^0;0.3), \\\\ \\rho_6:(b^0,c^0,x^1;0.7), \\\\ \\rho_7:(b^0,c^1,x^0;0.4), \\\\ \\rho_8’:(b^0,c^1,x^1;0.6),\\end{array}\\right\\} \\end{equation} which is obtained by selecting rules compatible with $a^1$, i.e. $\\{\\rho_1,\\rho_2,\\rho_5,\\rho_6,\\rho_7,\\rho_8\\}$, then canceling out $a^1$ from all the rules where it appeared.\nProposition 20: Let $\\mathcal{R}$ be the rules in the rule-based CPD for a variable $X$, and let $\\mathcal{R}_\\mathbf{c}$ be the rules in $\\mathcal{R}$ compatible with $\\mathbf{c}$. Let $\\mathbf{Y}\\subset\\text{Pa}_X$ be a subset such that $\\mathbf{Y}\\cap\\text{Scope}(\\mathbf{c})=\\emptyset$. If for all $\\rho\\in\\mathcal{R}[\\mathbf{c}]$, we have that $\\mathbf{Y}\\cap\\text{Scope}(\\rho)=\\emptyset$, then \\begin{equation} (X\\perp_c\\mathbf{Y}\\hspace{0.1cm}\\vert\\hspace{0.1cm}\\text{Pa}_X\\backslash\\mathbf{Y},\\mathbf{c}) \\end{equation}\nSpurious Edge Let $P(X\\vert\\text{Pa}_X)$ be a CPD, $Y\\in\\text{Pa}_X$ be a set and let $\\mathbf{c}$ be a context. The edge $Y\\rightarrow X$ is said to be spurious in the context $\\mathbf{c}$ if $P(X\\vert\\text{Pa}_X)$ satisfies $(X\\perp_c Y\\hspace{0.1cm}\\vert\\hspace{0.1cm}\\text{Pa}_X\\backslash\\{Y\\},\\mathbf{c})$, where $\\mathbf{c}’$ is the restriction of $\\mathbf{c}$ to variables in $\\text{Pa}_X$.\nHence, by examining the reduced rule set, we can specify whether an edge is spurious, i.e. if $\\mathcal{R}$ be the rule-based CPD for $P(X\\vert\\text{Pa}_X)$, then $Y\\rightarrow X$ is spurious in context $\\mathbf{c}$ if $Y$ does not appear in $\\mathcal{R}[\\mathbf{c}]$.\nTheorem 21: Let $\\mathcal{G}$ be a network structure, $P$ be a distribution such that $P\\models\\mathcal{I}_\\ell(\\mathcal{G})$, $\\mathbf{c}$ be a context, and $\\mathbf{X},\\mathbf{Y},\\mathbf{Z}$ be sets of variables. If $\\mathbf{X}$ is CSI-separated from $\\mathbf{Y}$ given $\\mathbf{Z}$ in the context $\\mathbf{c}$4, then we have that $P\\models(\\mathbf{X}\\perp_c\\mathbf{Y}\\hspace{0.1cm}\\vert\\hspace{0.1cm}\\mathbf{Z},\\mathbf{c})$.\nIndependence of Causal Influence Noisy-Or Model Let $Y$ be a binary-valued r.v with $k$ binary-valued parents $X_1,\\ldots,X_k$. The CPD $P(Y\\vert X_1,\\ldots,X_k)$ is a noisy-or if there are $k+1$ noise parameters $\\lambda_0,\\lambda_1,\\ldots,\\lambda_k$ such that \\begin{align} P(y^0\\vert X_1,\\ldots,X_k)\u0026=(1-\\lambda_0)\\prod_{i:X_i=x_i^1}(1-\\lambda_i)\\label{eq:nom.1} \\\\ P(y^1\\vert X_1,\\ldots,X_k)\u0026=1-(1-\\lambda_0)\\prod_{i:X_i=x_i^1}(1-\\lambda_i) \\end{align} If we interpret $x_i^0$ as $0$ and $x_i^1$ as $1$, \\eqref{eq:nom.1} can be rewritten as \\begin{equation} P(y^0\\vert X_1,\\ldots,X_k)=(1-\\lambda_0)\\prod_{i=1}^{k}(1-\\lambda_i)^{x_i} \\end{equation}\nGeneralized Linear Models Binary-valued Variables Multivalued Variables Continuous Variables Conditional Bayesian Networks A conditional Bayesian network $\\mathcal{B}$ over $\\mathbf{Y}$ given $\\mathbf{X}$ is defined as a DAG $\\mathcal{G}$ whose nodes are $\\mathbf{X}\\cup\\mathbf{Y}\\cup\\mathbf{Z}$ where $\\mathbf{X},\\mathbf{Y},\\mathbf{Z}$ are disjoint. The variables in $\\mathbf{X}$ are called inputs, the ones in $\\mathbf{Y}$ are referred as outputs and the others in $\\mathbf{Z}$ are known as encapsulated.\nThe variables in $\\mathbf{X}$ have no parents in $\\mathcal{G}$, while the variables in $\\mathbf{Y}\\cup\\mathbf{Z}$ are associated with a CPD. The network defines a CPD using chain rule \\begin{equation} P_\\mathcal{B}(\\mathbf{Y},\\mathbf{Z}\\vert\\mathbf{X})=\\prod_{T\\in\\mathbf{Y}\\cup\\mathbf{Z}}P(T\\vert\\text{Pa}_T) \\end{equation} The distribution $P_\\mathcal{B}(\\mathbf{Y}\\vert\\mathbf{X})$ is defined as the marginal of $P_\\mathcal{B}(\\mathbf{Y},\\mathbf{Z}\\vert\\mathbf{X})$ \\begin{equation} P_\\mathcal{B}(\\mathbf{Y}\\vert\\mathbf{X})=\\sum_\\mathbf{Z}P_\\mathcal{B}(\\mathbf{Y},\\mathbf{Z}\\vert\\mathbf{X}) \\end{equation} The conditional Bayesian network is the directed version of CRF mentioned above.\nEncapsulated CPD Let $Y$ be a r.v with $k$ parents $X_1,\\ldots,X_k$. The CPD $P(Y\\vert X_1,\\ldots,X_k)$ is an encapsulated CPD if it is represented using a conditional Bayesian network over $Y$ given $X_1,\\ldots,X_k$.\nTemplate-based Representations Temporal Models In a temporal model, for each $X_i\\in\\mathcal{X}$, we let $X_i^{(t)}$ denote its instantiation at time $t$. The variables $X_i$ are referred as template variables.\nConsider a distribution over trajectories sampled over time $t=0,1,\\ldots,T$ - $P(\\mathcal{X}^{(0)},\\mathcal{X}^{(1)},\\ldots,\\mathcal{X}^{(T)})$, or $P(\\mathcal{X}^{(0:T)})$ where $\\mathcal{X}^{(t)}=\\{X_i^{(t)}\\}$. Using the chain rule for probabilities, we have that \\begin{equation} P(\\mathcal{X}^{(0:T)})=P(\\mathcal{X}^{(0)},\\mathcal{X}^{(1)},\\ldots,\\mathcal{X}^{(T)})=P(\\mathcal{X}^{(0)})\\prod_{t=0}^{T-1}P(\\mathcal{X}^{(t+1)}\\vert \\mathcal{X}^{(0:t)}),\\label{eq:tm.1} \\end{equation} where $\\mathcal{X}^{(t_1:t_2)}\\doteq\\{\\mathcal{X}^{(t_1)},\\mathcal{X}^{(t_1+1)},\\ldots,\\mathcal{X}^{(t_2-1)},\\mathcal{X}^{(t_2)}\\}$ for $t_1","wordCount":"9041","inLanguage":"en","datePublished":"2022-12-10T17:55:57+07:00","dateModified":"2022-12-10T17:55:57+07:00","author":{"@type":"Person","name":"Trung H. Nguyen"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://trunghng.github.io/posts/machine-learning/pgm-representation/"},"publisher":{"@type":"Organization","name":"Trung's Place","logo":{"@type":"ImageObject","url":"https://trunghng.github.io/images/favicon/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://trunghng.github.io accesskey=h title="Trung's Place (Alt + H)"><img src=https://trunghng.github.io/images/others/pokeball.png alt aria-label=logo height=27>Trung's Place</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://trunghng.github.io/ title=Posts><span>Posts</span></a></li><li><a href=https://trunghng.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://trunghng.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://trunghng.github.io/about/ title=About><span>About</span></a></li><li><a href=https://trunghng.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Probabilistic Graphical Models - Representation</h1><div class=post-meta><span title='2022-12-10 17:55:57 +0700 +0700'>December 10, 2022</span>&nbsp;·&nbsp;43 min&nbsp;·&nbsp;Trung H. Nguyen</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#graphs>Graphs</a><ul><li><a href=#nodes-edges>Nodes, Edges</a></li><li><a href=#subgraphs>Subgraphs</a></li><li><a href=#paths-trails>Paths, Trails</a></li><li><a href=#cycles-loops>Cycles, Loops</a></li></ul></li><li><a href=#dgm>Directed Graphical Model</a><ul><li><a href=#bayesian-network-structure>Bayesian Network Structure</a></li><li><a href=#i-maps>I-Maps</a></li><li><a href=#factorization>Factorization</a></li><li><a href=#i-map---factorization-connection>I-Map - Factorization Connection</a></li><li><a href=#independencies-in-bayesian-network>Independencies in Bayesian Network</a><ul><li><a href=#d-separation>D-separation</a></li><li><a href=#soundness-completeness-bn>Soundness, Completeness</a></li><li><a href=#i-equivalence>I-Equivalence</a><ul><li><a href=#immorality>Immorality</a></li></ul></li></ul></li><li><a href=#dist2graph-bn>From Distributions to Graphs</a><ul><li><a href=#min-imap>Minimal I-Maps</a></li><li><a href=#perfect-maps>Perfect Maps</a></li></ul></li></ul></li><li><a href=#ugm>Undirected Graphical Model</a><ul><li><a href=#markov-networks>Markov Networks</a><ul><li><a href=#factors>Factors</a></li><li><a href=#markov-random-fields>Markov Random Fields</a></li><li><a href=#reduced-markov-networks>Reduced Markov Networks</a><ul><li><a href=#factor-reduction>Factor Reduction</a></li><li><a href=#reduced-gibbs-distribution>Reduced Gibbs Distribution</a></li><li><a href=#reduced-markov-network>Reduced Markov Network</a></li></ul></li></ul></li><li><a href=#independencies-in-markov-network>Independencies in Markov Network</a><ul><li><a href=#separation>Separation</a></li><li><a href=#global-markov-independencies>Global Markov Independencies</a></li><li><a href=#local-markov-independencies>Local Markov Independencies</a></li><li><a href=#markov-independencies-relationships>Markov Independencies Relationships</a></li><li><a href=#soundness-completeness-mn>Soundness, Completeness</a></li></ul></li><li><a href=#dist2graph-mn>From Distributions to Graphs</a><ul><li><a href=#factor-graphs>Factor Graphs</a></li><li><a href=#log-linear-models>Log-Linear Models</a></li><li><a href=#canonical-parameterization>Canonical Parameterization</a></li></ul></li><li><a href=#bayesian--markov-networks>Bayesian & Markov Networks</a><ul><li><a href=#bn-2-mrf>Bayesian Networks to Markov Networks</a><ul><li><a href=#moralized-graph>Moralized Graph</a></li></ul></li><li><a href=#markov-networks-to-bayesian-networks>Markov Networks to Bayesian Networks</a></li></ul></li><li><a href=#crf>Conditional Random Fields</a><ul><li><a href=#example---naive-markov>Example - Naive Markov</a></li></ul></li></ul></li><li><a href=#local-probabilistic-models>Local Probabilistic Models</a><ul><li><a href=#tabular-cpds>Tabular CPDs</a></li><li><a href=#deterministic-cpds>Deterministic CPDs</a><ul><li><a href=#context-specific-independence>Context-Specific Independence</a></li></ul></li><li><a href=#context-specific-cpds>Context-specific CPDs</a><ul><li><a href=#tree-cpds>Tree-CPDs</a><ul><li><a href=#multiplexer-cpd>Multiplexer CPD</a></li></ul></li><li><a href=#rule-cpds>Rule CPDs</a><ul><li><a href=#rule-based-cpd>Rule-based CPD</a></li></ul></li><li><a href=#independencies-in-context-specific-cpds>Independencies in Context-specific CPDs</a><ul><li><a href=#reduced-rule>Reduced Rule</a></li><li><a href=#spurious-edge>Spurious Edge</a></li></ul></li></ul></li><li><a href=#independence-of-causal-influence>Independence of Causal Influence</a><ul><li><a href=#noisy-or-model>Noisy-Or Model</a></li><li><a href=#glm>Generalized Linear Models</a><ul><li><a href=#binary-valued-variables>Binary-valued Variables</a></li><li><a href=#multivalued-variables>Multivalued Variables</a></li></ul></li></ul></li><li><a href=#continuous-variables>Continuous Variables</a></li><li><a href=#cbn>Conditional Bayesian Networks</a><ul><li><a href=#encapsulated-cpd>Encapsulated CPD</a></li></ul></li></ul></li><li><a href=#template-based-representations>Template-based Representations</a><ul><li><a href=#temporal-models>Temporal Models</a><ul><li><a href=#markovian-system>Markovian System</a></li><li><a href=#dbn>Dynamic Bayesian Networks</a></li><li><a href=#state-observation-models>State-Observation Models</a><ul><li><a href=#hmm>Hidden Markov Models</a></li><li><a href=#linear-dynamical-systems>Linear Dynamical Systems</a><ul><li><a href=#extended-kalman-filters>Extended Kalman Filters</a></li></ul></li></ul></li></ul></li><li><a href=#template-variables--template-factors>Template Variables & Template Factors</a></li><li><a href=#directed-probabilistic-models-for-object-relational>Directed Probabilistic Models for Object-Relational</a><ul><li><a href=#plate-models>Plate Models</a><ul><li><a href=#ground-bayesian-networks-for-plate-models>Ground Bayesian Networks for Plate Models</a></li></ul></li><li><a href=#probabilistic-relational-models>Probabilistic Relational Models</a><ul><li><a href=#ground-bayesian-networks-for-prms>Ground Bayesian Networks for PRMs</a></li></ul></li></ul></li><li><a href=#undirected-representation>Undirected Representation</a><ul><li><a href=#ground-gibbs-distribution>Ground Gibbs Distribution</a></li></ul></li></ul></li><li><a href=#references>References</a></li><li><a href=#footnotes>Footnotes</a></li></ul></nav></div></details></div><div class=post-content><p>Notes on Representation in PGMs.</p><h2 id=graphs>Graphs<a hidden class=anchor aria-hidden=true href=#graphs>#</a></h2><p>A <strong>graph</strong>, denoted $\mathcal{K}$ is a tuple of $\mathcal{X}$ and $\mathcal{E}$ where $\mathcal{X}=\{X_1,\ldots,X_n\}$ is the sets of <strong>nodes</strong> (or <strong>vertices</strong>) and $\mathcal{E}$ is the set of <strong>edges</strong>.
\begin{equation}
\mathcal{K}=(\mathcal{X},\mathcal{E})
\end{equation}</p><h3 id=nodes-edges>Nodes, Edges<a hidden class=anchor aria-hidden=true href=#nodes-edges>#</a></h3><p>Any pair of nodes $X_i,X_j$, for $i\neq j$ is connected by either a <strong>directed edge</strong> $X_i\rightarrow X_j$ or an <strong>undirected edge</strong> $X_i-X_j$<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>. We use the notation $X_i\rightleftharpoons X_j$ to denote that $X_i$ is connected to $X_j$ via some edge, whether directed (in any direction) or undirected.</p><p>If the graph contains directed edges only, we call it a <strong>directed graph</strong>, denoted $\mathcal{G}$, else if the graph established by undirected edge only, it is referred as <strong>undirected graph</strong>, denoted $\mathcal{H}$.</p><figure><img src=/images/pgm-representation/graph-eg.png alt="Graph example" width=50% height=50%><figcaption><b>Figure 1</b>: (taken from the <a href=#pgm-book>PGM book</a>) <b>Example of a partially directed graph $\mathcal{K}$</b></figcaption></figure><p>Following are some necessary notations:</p><ul id=number-list><li>If $X_i\rightarrow X_j\in\mathcal{E}$, we say that $X_i$ is the <b>parent</b> of $X_j$ while $X_j$ is the <b>child</b> of $X_i$.<br>E.g. node $I$ is a child of nodes $C,E$ and $H$ while $D$ is a parent of $G$.</li><li>If $X_i-X_j\in\mathcal{E}$, we say that $X_i$ is a <b id=neighbor>neighbor</b> of $X_j$, and vice versa.<br>E.g. node $F$ is a neighbor of $G$.</li><li>If $X\rightleftharpoons Y\in\mathcal{E}$, we say that $X$ and $Y$ are adjacent.<br>E.g. nodes $A$ and $C$ are adjacent, while $D$ is adjacent to $E$.</li><li>We use $\text{Pa}_X$ to denote the set of parents of $X$, $\text{Ch}_X$ to denote the set of its children and $\text{Nb}_X$ to denote its neighbors. The set $\text{Boundary}_X\doteq\text{Pa}_X\cup\text{Nb}_X$ is known as the <b>boundary</b> of $X$.<br>E.g. $\text{Pa}_I=\{C,E,H\}$ and $\text{Boundary}_F=\text{Pa}_F\cup\text{Nb}_F=\{C\}\cup\{G\}=\{C,G\}$.</li><li>The <b>degree of a node</b> $X$ is the number of edges in which it participates; its <b>indegree</b> is the number of directed edges $Y\rightarrow X$. The <b>degree of a graph</b> is the maximal degree of a node in the graph.<br>E.g. node $D$ has degree of $3$, indegree of $0$; the graph $\mathcal{K}$ has degree of $3$.</li></ul><h3 id=subgraphs>Subgraphs<a hidden class=anchor aria-hidden=true href=#subgraphs>#</a></h3><p>Consider the graph $\mathcal{K}=(\mathcal{X},\mathcal{E})$ and let $\mathbf{X}\subset\mathcal{X}$ be a subset of nodes in $\mathcal{K}$. Then:</p><ul id=number-list><li>The <b>induced subgraph</b> of $\mathcal{K}$, denoted $\mathcal{K}[\mathbf{X}]$ is defined as the graph $(\mathbf{X},\mathcal{E}')$ where
\begin{equation}
\mathcal{E}'=\{X\rightleftharpoons Y:X,Y\in\mathbf{X}\}
\end{equation}</li><li>A subgraph over $\mathbf{X}$ is <b>complete</b> if every two nodes in $\mathbf{X}$ are connected via some edges. The set $\mathbf{X}$ is known as a <b id=clique>clique</b>; or even a <b id=max-clique>maximal clique</b> if for any set of nodes $\mathbf{Y}\supset\mathbf{X}$, $\mathbf{Y}$ is not a clique, i.e.
\begin{equation}
\{\mathbf{Y}\text{ clique}:\mathbf{Y}\supset\mathbf{X}\}=\emptyset
\end{equation}</li><li>The set $\mathbf{X}$ is called <b>upward closed</b> in $\mathbf{K}$ if for any $X\in\mathbf{X}$, we have that
\begin{equation}
\text{Boundary}_X\subset\mathbf{X}
\end{equation}
The <b>upward closure</b> of $\mathbf{X}$ is the minimal closed subset $\mathbf{Y}$ covering $\mathbf{X}$, i.e.
\begin{equation}
\mathbf{Y}=\sup\{\bar{\mathbf{Y}}\text{ upward closed in }\mathcal{K}:\bar{\mathbf{Y}}\supset\mathbf{X}\}
\end{equation}
The <b>upwardly closed subgraph</b> of $\mathbf{X}$, denoted $\mathcal{K}^+[\mathbf{X}]$, is the induced subgraph over $\mathbf{Y}$, $\mathcal{K}[\mathbf{Y}]$.</li></ul><h3 id=paths-trails>Paths, Trails<a hidden class=anchor aria-hidden=true href=#paths-trails>#</a></h3><p>Consider the graph $\mathcal{K}=(\mathcal{X},\mathcal{E})$, the basic notion of edges gives rise to following definitions:</p><ul id=number-list><li>$X_1,\ldots,X_k$ form a <b id=path>path</b> in $\mathcal{K}$ if for every $i=1,\ldots,k-1$, we have that either $X_i\rightarrow X_{i+1}$ or $X_i-X_{i+1}$. A path is <b>directed</b> if there exists a directed edge $X_i\rightarrow X_{i+1}$.</li><li>$X_1,\ldots,X_k$ form a <b>trail</b> in $\mathcal{K}$ if for every $i=1,\ldots,k-1$, we have that $X_i\rightleftharpoons X_{i+1}$.</li><li>$\mathcal{K}$ is <b>connected</b> if for every pair $X_i,X_j$ there is a trail between $X_i$ and $X_j$.</li><li>$X$ is an <b>ancestor</b> of $Y$ and correspondingly $Y$ is a <b>descendant</b> of $X$ in $\mathcal{K}$ if there exists a directed path $X_1,\ldots,X_k$ with $X_1=X$ and $X_k=Y$.</li><li>An ordering of nodes $X_1,\ldots,X_n$ is a <b id=topo-order>topological ordering</b> relative to $\mathbf{K}$ if whenever we have $X_i\rightarrow X_j\in\mathcal{E}$, then $i\lt j$. This gives rise to critical results that for each node $X_i$, we have that
\begin{equation}
\text{Pa}_{X_i}\subset\{X_1,\ldots,X_{i-1}\},
\end{equation}
and
\begin{equation}
\text{Ch}_{X_i}\subset\{X_{i+1},\ldots,X_n\}
\end{equation}</li></ul><h3 id=cycles-loops>Cycles, Loops<a hidden class=anchor aria-hidden=true href=#cycles-loops>#</a></h3><ul id=number-list><li>A <b>cycle</b> in $\mathcal{K}$ is a directed path $X_1,\ldots,X_k$ where $X_1=X_k$. $\mathcal{K}$ is <b>acyclic</b> if it contains no cycles.</li><li>$\mathcal{K}$ is a <b>directed acyclic graph</b> (or <b>DAG</b>) if it is both directed and acyclic.</li><li>An acyclic graph containing both directed and undirected edges is known as a <b>partially directed acyclic graph</b> (or <b>PDAG</b>).<br>Let $\mathcal{K}$ be a PDAG over $\mathcal{X}$ and let $\mathbf{K}_1,\ldots,\mathbf{K}_\ell$ be a disjoint partition of $\mathcal{X}$ such that:<ul id=roman-list><li>the induced subgraph over $\mathbf{K}_i$ contains no directed edges;</li><li>for any pair of nodes $X\in\mathbf{K}_i$ and $Y\in\mathbf{K}_j$ for $i\lt j$, an edge between $X$ and $Y$ can only be a directed edge $X\rightarrow Y$.</li></ul>Each component $\mathbf{K}_i$ is called a <b>chain component</b>, while $\mathcal{K}$ is referred as a <b>chain graph</b>.</li><li>A <b>loop</b> in $\mathcal{K}$ is a trail $X_1,\ldots,X_k$ where $X_1=X_k$. A graph is <b>singly connected</b> if it contains no loops. A node in a singly connected graph is called a <b>leaf</b> if it has exactly one adjacent node.</li><li>A singly connected directed graph is called a <b>polytree</b>, while a singly connected undirected graph is known as a <b>forest</b>; if it is also connected, it is called a <b id=tree>tree</b>.</li><li>A directed graph is a <b>forest</b> if each node has at most one parent. A directed forest is a <b>tree</b> if it is also connected.</li></ul><h2 id=dgm>Directed Graphical Model<a hidden class=anchor aria-hidden=true href=#dgm>#</a></h2><p>A <strong>Directed Graphical Model</strong> (or <strong>Bayesian network</strong>) is a tuple $\mathcal{B}=(\mathcal{G},P)$ where</p><ul><li>$\mathcal{G}$ is a <strong>Bayesian network structure</strong>,</li><li>$P$ <strong>factorizes</strong> according to $\mathcal{G}$,</li><li>$P$ is specified as a set of CPDs associated with $\mathcal{G}$&rsquo;s nodes.</li></ul><h3 id=bayesian-network-structure>Bayesian Network Structure<a hidden class=anchor aria-hidden=true href=#bayesian-network-structure>#</a></h3><p>A <strong>Bayesian network structure</strong> (or <strong>Bayesian network graph</strong>, <strong>BN graph</strong>) is a DAG, denoted $\mathcal{G}=(\mathcal{X},\mathcal{E})$ with $\mathcal{X}=\{X_1,\ldots,X_n\}$ where</p><ul id=number-list><li>Each node $X_i\in\mathcal{X}$ represents a random variable.</li><li>Each node $X_i\in\mathcal{X}$ is associated with a conditional independencies assumption, called <b>local independencies</b>, denoted $\mathcal{I}_\ell(\mathcal{G})$, which says that $X_i$ is conditionally independent of its non-descendants given its parent, i.e.
\begin{equation}
(X_i\perp\text{NonDescendants}_{X_i}\vert\hspace{0.1cm}\text{Pa}_{X_i}),
\end{equation}
where $\text{NonDescendants}_{X_i}$ denotes the set of non-descendant nodes of $X_i$.</li></ul><h3 id=i-maps>I-Maps<a hidden class=anchor aria-hidden=true href=#i-maps>#</a></h3><p>Let $P$ be a distribution over $\mathcal{X}$, we define $\mathcal{I}(P)$ to be the set of independence assertions of the form $(X\perp Y\hspace{0.1cm}\vert Z)$ that hold in $P$, i.e.
\begin{equation}
P\models(X\perp Y\vert Z),
\end{equation}
or
\begin{equation}
P(X,Y\vert Z)=P(X\vert Z)P(Y\vert Z)
\end{equation}
Let $\mathcal{K}$ be a graph associated with a set of independencies $\mathcal{I}(\mathcal{K})$, then $\mathcal{K}$ is an <strong>I-map</strong> (for independence map) for a set of independencies $\mathcal{I}$ if $\mathcal{I}(\mathcal{K})\subset\mathcal{I}$.</p><p>Hence, if $P$ satisfies the local dependencies associated with $\mathcal{G}$, we have
\begin{equation}
\mathcal{I}_\ell(\mathcal{G})\subset\mathcal{I}(P),
\end{equation}
which implies that $\mathcal{G}$ is an I-map for $\mathcal{I}(P)$, or simply an I-map for $P$.</p><h3 id=factorization>Factorization<a hidden class=anchor aria-hidden=true href=#factorization>#</a></h3><p>Let $\mathcal{G}$ is a BN graph over $X_1,\ldots,X_n\in\mathcal{X}$. A distribution $P$ over $\mathcal{X}$ is said to <strong>factorize</strong> according to $\mathcal{G}$ if $P$ can be expressed as a product
\begin{equation}
P(X_1,\ldots,X_n)=\prod_{i=1}^{n}P(X_i\vert\text{Pa}_{X_i})
\end{equation}
This equation is known as the <strong>chain rule for Bayesian networks</strong>. Each individual factor $P(X_i\vert\text{Pa}_{X_i})$, which is a conditional probability distribution (CPD), is called the <strong>local probabilistic model</strong>.</p><h3 id=i-map---factorization-connection>I-Map - Factorization Connection<a hidden class=anchor aria-hidden=true href=#i-map---factorization-connection>#</a></h3><p><strong>Theorem 1</strong>: <em>Let $\mathcal{G}$ be a BN graph over a set of random variables $\mathcal{X}$ and let $P$ be a joint distribution over $\mathcal{X}$. Then $\mathcal{G}$ is an I-map for $P$ if and only if $P$ factorizes over $\mathcal{G}$</em>.</p><p><strong>Proof</strong></p><ul id=number-list><li>I-map $\Rightarrow$ Factorization<br>Without loss of generality, let $X_1,\ldots,X_n$ be a <a href=#topo-order>topological ordering</a> of the variables in $\mathcal{X}$.<br>Let us consider an arbitrary $X_i$ for $i\in\{1,\ldots,n\}$. As mentioning above, the topological ordering implies that
\begin{align}
\text{Pa}_{X_i}&\subset\{X_1,\ldots,X_{i-1}\}, \\ \text{Ch}_{X_i}&\subset\{X_{i+1},\ldots,X_n\}
		\end{align}
Consequently, none of descendants of $X_i$ is in $\{X_1,\ldots,X_{n-1}\}$. Thus, if we denote the set of all non-descendant nodes of $X_i$ as $\text{NonDescentdants}_{X_i}$ and let $\mathbf{Z}\subset\text{NonDescentdants}_{X_i}$, then
\begin{equation}
\mathbf{Z}\cup\text{Pa}_{X_i}=\{X_1,\ldots,X_{i-1}\}
\end{equation}
Moreover, the local independence for $X_i$ implies that
\begin{equation}
(X_i\perp\mathbf{Z}\vert\text{ Pa}_{X_i})
\end{equation}
Therefore, since $\mathcal{G}$ is an I-map for $P$ we obtain
\begin{equation}
P(X_i\vert X_1,\ldots,X_{i-1})=P(X_i\vert\text{Pa}_{X_i})
\end{equation}
Thus, by the chain rule for probabilities, we have
\begin{equation}
P(X_1,\ldots,X_n)=\prod_{i=1}^{n}P(X_i\vert X_1,\ldots,X_{i-1})=\prod_{i=1}^{n}P(X_i\vert\text{Pa}_{X_i})
\end{equation}</li><li>I-map $\Leftarrow$ Factorization<br>To prove that $\mathcal{G}$ is an I-map according to $P$, we need to show that $\mathcal{I}_\ell(\mathcal{G})$ holds in $P$. Consider an arbitrary node $X_i$ and the local independencies $(X_i\perp\text{NonDescendants}_{X_i}\vert\text{Pa}_{X_i})$, our problem remains to prove that
\begin{equation}
P(X_i\vert\mathcal{X}\backslash X_i)=P(X_i\vert\text{Pa}_{X_i})
\end{equation}
since
\begin{equation}
P(X_i\vert\mathcal{X}\backslash X_i)=P(X_i\vert\text{NonDescendants}_{X_i}\cup\text{Pa}_{X_i})
\end{equation}
By factorization, we have that
\begin{align}
P(\mathcal{X}\backslash X_i)&=\sum_{X_i}P(X_1,\ldots,X_n) \\ &=\sum_{X_i}\prod_{j=1}^{n}P(X_j\vert\text{Pa}_{X_j}) \\ &=\left(\prod_{j=1,j\neq i}^{n}P(X_j\vert\text{Pa}_{X_j})\right)\sum_{X_i}P(X_i\vert\text{Pa}_{X_i}) \\ &=\prod_{j=1,j\neq i}^{n}P(X_j\vert\text{Pa}_{X_j}),
\end{align}
where in the last step, we use the fact that the conditional probability function $P(X_i\vert\text{Pa}_{X_i})$ sum to $1$ over the sample space of $X_i$. This implies that by Bayes rules
\begin{align}
P(X_i\vert\mathcal{X}\backslash X_i)&=\frac{P(X_1,\ldots,X_n)}{P(\mathcal{X}\backslash X_i)} \\ &=\frac{\prod_{j=1}^{n}P(X_j\vert\text{Pa}_{X_j})}{\prod_{j=1,j\neq i}^{n}P(X_j\vert\text{Pa}_{X_j})} \\ &=P(X_i\vert\text{Pa}_{X_i})
		\end{align}</li></ul><h3 id=independencies-in-bayesian-network>Independencies in Bayesian Network<a hidden class=anchor aria-hidden=true href=#independencies-in-bayesian-network>#</a></h3><h4 id=d-separation>D-separation<a hidden class=anchor aria-hidden=true href=#d-separation>#</a></h4><p>Let $\mathcal{G}$ be a BN structure, $X_1\rightleftharpoons\ldots\rightleftharpoons X_n$ be a trail in $\mathcal{G}$ and let $\mathbf{Z}$ be a subset of observed variables. The trail $X_1\rightleftharpoons\ldots\rightleftharpoons X_n$ is <strong>active</strong> if</p><ul id=roman-list><li>Whenever we have a <b>v-structure</b> $X_{i-1}\rightarrow X_i\leftarrow X_{i+1}$, $X_i$ or one of its descendants are in $\mathbf{Z}$;</li><li>No other node along the trail are in $\mathbf{Z}$.</li></ul><figure><img src=/images/pgm-representation/two-edge-trails.png alt="Two-edge trails" width=70% height=70%><figcaption><b>Figure 2</b>: (taken from the <a href=#pgm-book>PGM book</a>) <b>The four possible two-edge trails from $X$ to $Y$ via $Z$</b>: (a) Causal trail; (b) Evidential trail; (c) Common cause trail; (d) Common effect trail</figcaption></figure><p><span id=two-edge-trail>Consider the trails forming from two edges as illustrated above</span>:</p><ul id=alpha-list><li>The trail $X\rightarrow Z\rightarrow Y$ is active $\Leftrightarrow$ $Z$ is not observed.</li><li>The trail $X\leftarrow Z\leftarrow Y$ is active $\Leftrightarrow$ $Z$ is not observed.</li><li>The trail $X\leftarrow Z\leftarrow Y$ is active $\Leftrightarrow$ $Z$ is not observed.</li><li>The trail $X\rightarrow Z\leftarrow Y$ is active $\Leftrightarrow$ either $Z$ or one of its descendants is observed.</li></ul><p>Let $\mathbf{X},\mathbf{Y},\mathbf{Z}$ be sets of nodes in $\mathcal{G}$. Then $\mathbf{X}$ and $\mathbf{Y}$ are said to be <strong>d-separated</strong> given $\mathbf{Z}$, denoted $\text{d-sep}_\mathcal{G}(\mathbf{X};\mathbf{Y}\vert\mathbf{Z})$, if there is no active trail between any node $X\in\mathbf{X}$ and $Y\in\mathbf{Y}$ given $\mathbf{Z}$.</p><p>We define the <strong>global Markov independencies</strong> associated with $\mathcal{G}$, denoted $\mathcal{I}(\mathcal{G})$, to be the set of all independencies that correspond to d-separation in $\mathcal{G}$
\begin{equation}
\mathcal{I}(\mathcal{G})=\big\{(\mathbf{X}\perp\mathbf{Y}\vert\mathbf{Z}):\text{d-sep}_\mathcal{G}(\mathbf{X};\mathbf{Y}\vert\mathbf{Z})\big\}
\end{equation}</p><h4 id=soundness-completeness-bn>Soundness, Completeness<a hidden class=anchor aria-hidden=true href=#soundness-completeness-bn>#</a></h4><p><strong>Theorem 2</strong> (Soundness of d-separation) <em>If a distribution $P$ factorizes according to $\mathcal{G}$, then</em>
\begin{equation}
\mathcal{I}(\mathcal{G})\subset\mathcal{I}(P)
\end{equation}
The soundness property says that if $\text{d-sep}_\mathcal{G}(X;Y\vert\mathbf{Z})$ then they are conditional independent given $\mathbf{Z}$, or $(X\perp Y\vert\mathbf{Z})$.</p><p><strong>Theorem 3</strong> (Completeness of d-separation) <em>If two variables $X$ and $Y$ are independent given $\mathbf{Z}$, then they are d-separated.</em></p><p>The completeness property says that d-separation detects all possible independencies.</p><p><strong>Theorem 4</strong>: <em>Let $\mathcal{G}$ be a BN graph. If $X$ and $Y$ are not d-separated given $\mathbf{Z}$, then $X$ and $Y$ are dependent given $\mathbf{Z}$ in some distribution $P$ that factorizes over $\mathcal{G}$</em>.</p><p><strong>Theorem 5</strong>: <em>For almost all distributions $P$ that factorize over $\mathcal{G}$, i.e. for all distributions except for a set of measure zero in the space of CPD parameterizations, we have that</em>
\begin{equation}
\mathcal{I}(\mathcal{G})=\mathcal{I}(P)
\end{equation}
These results state that for almost all parameterizations $P$ of the graph $\mathcal{G}$, the d-separation test precisely characterizes the independencies that hold for $P$.</p><h4 id=i-equivalence>I-Equivalence<a hidden class=anchor aria-hidden=true href=#i-equivalence>#</a></h4><p>Two graph $\mathcal{K}_1$ and $\mathcal{K}_2$ over $\mathcal{X}$ are said to be <strong>I-equivalent</strong> if they encode the same set of conditional independencies assertions, i.e.
\begin{equation}
\mathcal{I}(\mathcal{K}_1)=\mathcal{I}(\mathcal{K}_2)
\end{equation}
This implies that any distribution $P$ that factorizes over $\mathcal{K}_1$ also factorizes according to $\mathcal{K}_2$ and vice versa.</p><p>The <strong>skeleton</strong> of a BN graph $\mathcal{G}$ over $\mathcal{X}$ is an undirected graph over $\mathcal{X}$ containing an edge $\{X,Y\}$ for every edge $(X,Y)$ in $\mathcal{G}$.</p><p><strong>Theorem 6</strong> (skeleton + v-structures $\Rightarrow$ I-equivalence) <em>Let $\mathcal{G}_1$ and $\mathcal{G_2}$ be two graphs over $\mathcal{X}$. If $\mathcal{G}_1,\mathcal{G}_2$ both have the same skeleton and the same set of v-structures then they are I-equivalent</em>.<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup></p><figure><img src=/images/pgm-representation/I-equivalence.png alt="I-equivalent graphs" width=80% height=80%><figcaption><b>Figure 3</b>: (taken from the <a href=#pgm-book>PGM book</a>) <b>Two graphs have the same skeleton and set of v-structures</b>, i.e. $\{X\rightarrow Y\leftarrow Z\}$, and thus are I-equivalent</figcaption></figure><h5 id=immorality>Immorality<a hidden class=anchor aria-hidden=true href=#immorality>#</a></h5><p>A v-structure $X\rightarrow Z\leftarrow Y$ is an <strong>immorality</strong> if there is no direct edge between. If there is such an edge, it is called a <strong>covering edge</strong> for the v-structure.</p><p>It is easily seen that not every v-structure is an immorality, which implies that two networks with the same set of immoralities do not necessarily have the same set of v-structures.</p><p><strong>Theorem 7</strong> (skeleton + immoralities $\Leftrightarrow$ I-equivalence) <em>Let $\mathcal{G}_1$ and $\mathcal{G_2}$ be two graphs over $\mathcal{X}$. If $\mathcal{G}_1,\mathcal{G}_2$ both have the same skeleton and the same set of immoralities iff they are I-equivalent</em>.</p><p><strong>Proof</strong></p><ul id=number-list><li>To prove the theorem, we first introduce the notion of <b>minimal active trail</b> and <b>triangle</b>.<br><b>Definition</b> (Minimal active trail) An active trail $X_1,\ldots,X_m$ is <b>minimal</b> if there is no other active trail from $X_1$ to $X_m$ that shortcuts some of the nodes, i.e. there is no active trail
\begin{equation}
X_1\rightleftharpoons X_{i_1}\rightleftharpoons\ldots X_{i_k}\rightleftharpoons X_m\hspace{1cm}\text{for }1\lt i_1\lt\ldots\lt i_k\lt m
\end{equation}
<b>Definition</b> (Triangle) Any three consecutive nodes in a trail $X_1,\ldots,X_m$ are called a <b>triangle</b> if their skeleton is fully connected, i.e. forms a 3-clique.<br><br>Our attention now is to prove that the only possible triangle in minimal active trail is the one having form of $X_{i-1}\leftarrow X_i\rightarrow X_{i+1}$ and either $X_{i-1}\rightarrow X_{i+1}$ or $X_{i-1}\leftarrow X_{i+1}$.<br>Consider a two-edge trail from $X_{i-1}$ to $X_{i+1}$ via $X_i$, which as being <a href=#two-edge-trail>mentioned</a> above, has four possible forms<ul id=alpha-list><li>$X_{i-1}\rightarrow X_i\rightarrow X_{i+1}$<br>It is easily seen that $X_i$ has to be not observed to make the trail active. If $X_{i-1}$ is connected to $X_{i+1}$ via $X_{i-1}\rightarrow X_{i+1}$, this gives rise to a shortcut. On the other hand, if they are connected by $X_{i-1}\leftarrow X_{i+1}$, the triangle now induces a cycle.</li><li>$X_{i-1}\leftarrow X_i\leftarrow X_{i+1}$<br>This case is symmetrically identical to the previous one, and thus is not viable.</li><li>$X_{i-1}\leftarrow X_i\rightarrow X_{i+1}$<br>The first observation is that $X_i$ has to be not given. The second observation is $X_{i-1}$ and $X_{i+1}$ are symmetric through $X_i$, so we only need to consider some specific cases of $X_{i-1}$ and the same logic is applied to $X_{i+1}$ analogously.<br>Let us examine the two-edge trail $X_{i-2},X_{i-1},X_i$. On the one hand, if we have $X_{i-2}\rightarrow X_{i-1}$, $X_{i-1}$ then has to be given, which implies that<ul><li>If $X_{i-1}\leftarrow X_{i+1}$ exists, it will create a shortcut, which is not allowed.</li><li>If $X_{i-1}\rightarrow X_{i+1}$ exists, no shortcut appears, $X_{i-1},X_i,X_{i+1}$ satisfies the condition of a triangle in the minimal active trail $X_1,\ldots,X_m$.</li></ul>On the other hand, if we have $X_{i-2}\leftarrow X_{i-1}$, then $X_{i-1}$ is not observed, analogously, we instead have<ul><li>If $X_{i-1}\leftarrow X_{i+1}$ exists, no shortcut is formed, $X_{i-1},X_i,X_{i+1}$ create a triangle.</li><li>If $X_{i-1}\rightarrow X_{i+1}$ exists, $X_{i-1},X_i,X_{i+1}$ is do not form a triangle due to the appearance of a shortcut through $X_{i-1}$ to $X_{i+1}$.</li></ul></li><li>$X_{i-1}\rightarrow X_i\leftarrow X_{i+1}$<br>In this case, $X_i$ or one of its descendant is observed. Using the similar procedure to previous case gives us no viable triangle formed by $X_{i-1},X_i,X_{i+1}$.</li></ul>Given these results, we are now ready for the main part. Let us begin with the forward path.</li><li>Skeleton + Immoralities $\Rightarrow$ I-equivalence<br>Assume that there exists node $X,Y,Z$ such that
\begin{align}
(X\perp Y\vert Z)&\in\mathcal{I}(\mathcal{G}_1), \\ (X\perp Y\vert Z)&\not\in\mathcal{I}(\mathcal{G}_2),
\end{align}
which implies that there is an active trail through $X,Y$ and $Z$ in the graph $\mathcal{G}_2$. Let us consider the minimal one and continue by examining two cases that whether $Z$ is observed.<ul id=alpha-list><li>If $Z$ is observed, in $\mathcal{G}_1$, we have $X\rightarrow Z\rightarrow Y$, or $X\leftarrow Z\leftarrow Y$, or $X\leftarrow Z\rightarrow Y$, while we have $X\rightarrow Z\leftarrow Y$ in $\mathcal{G}_2$, which is a v-structure. To assure that both graphs have the same set of moralities, there exist an edge that directly connects $X$ and $Y$, or in other words, $X,Y,Z$ form a triangle. This contradicts to the claim we have proved in the previous part.</li><li>If $Z$ is not observed, thus in $\mathcal{G}_1$, $X,Y,Z$ now must form a v-structure $X\rightarrow Z\leftarrow Y$. And also, to guarantee that both graphs have the same moralities, there exists an edge, without loss of generality, we assume $X\rightarrow Y$. However, this edge will active the trail $X,Y,Z$, or in other words, in $\mathcal{G}_1$, we now have $(X\not\perp Y\vert Z)$, which is a contradiction of our assumption.</li></ul></li><li>Skeleton + Immoralities $\Leftarrow$ I-equivalence<br>Consider two I-equivalent graphs $\mathcal{G}_1$ and $\mathcal{G}_2$.<ul id=alpha-list><li>First assuming that they do not have that same skeleton. This implies without loss of generality that there exists a trail in $\mathcal{G}_1$ that does not appear in $\mathcal{G}_2$, which induces a conditional independence in $\mathcal{G}_1$ but not in $\mathcal{G}_2$, contradicts to the fact that they two graphs are I-equivalent.</li><li>Now assuming that two graphs do not have the same set of moralities.</li></ul></li></ul><h3 id=dist2graph-bn>From Distributions to Graphs<a hidden class=anchor aria-hidden=true href=#dist2graph-bn>#</a></h3><p>Given a distribution $P$, how can we represent the independencies of $P$ with a graph $\mathcal{G}$?</p><h4 id=min-imap>Minimal I-Maps<a hidden class=anchor aria-hidden=true href=#min-imap>#</a></h4><p>A graph $\mathcal{K}$ is a <strong>minimal I-map</strong> for a set of independencies $\mathcal{I}$ if it is an I-map for $\mathcal{I}$, and removing one edge from $\mathcal{K}$ makes it no longer be an I-map.</p><h4 id=perfect-maps>Perfect Maps<a hidden class=anchor aria-hidden=true href=#perfect-maps>#</a></h4><p>A graph $\mathcal{K}$ is a <strong>perfect map</strong> (or <strong>P-map</strong>) for a set of independencies $\mathcal{I}$ if we have that $\mathcal{I}(\mathcal{K})=\mathcal{I}$; and if $\mathcal{I}(\mathcal{K})=\mathcal{I}(P)$, $\mathcal{K}$ is said to be a <strong>perfect map</strong> for $P$.</p><h2 id=ugm>Undirected Graphical Model<a hidden class=anchor aria-hidden=true href=#ugm>#</a></h2><p>Similar to the directed case, each node in an undirected graphical model represents a random variable. However, as indicated from the name, each edge that connects two nodes is now undirected, and thus can not describe causal relationship between those nodes as in Bayesian network.</p><h3 id=markov-networks>Markov Networks<a hidden class=anchor aria-hidden=true href=#markov-networks>#</a></h3><h4 id=factors>Factors<a hidden class=anchor aria-hidden=true href=#factors>#</a></h4><p>Let $\mathbf{D}$ be a set of r.v.s. The function $\phi:\text{Val}(\mathbf{D})\mapsto\mathbb{R}$ is referred as a <strong>factor</strong> with the scope $\mathbf{D}$, denoted $\mathbf{D}=\text{Scope}(\phi)$.</p><p>A factor is nonnegative if all of its entries are nonnegative.</p><p>Let $\mathbf{X},\mathbf{Y},\mathbf{Z}$ be disjoint sets of variables, and let $\phi_1(\mathbf{X},\mathbf{Y})$ and $\phi_2(\mathbf{Y},\mathbf{Z})$ be factors. The product $\phi_1\times\phi_2$ is called a <strong>factor product</strong>, which is a factor $\psi:\text{Val}(\mathbf{X},\mathbf{Y},\mathbf{Z})\mapsto\mathbb{R}$, given as
\begin{equation}
\psi(\mathbf{X},\mathbf{Y},\mathbf{Z})=\phi_1(\mathbf{X},\mathbf{Y})\cdot\phi_2(\mathbf{Y},\mathbf{Z})
\end{equation}</p><figure id=fig4><img src=/images/pgm-representation/factor-product.png alt="Factor product" width=80% height=80%><figcaption><b>Figure 4</b>: (taken from the <a href=#pgm-book>PGM book</a>) <b>An example of factor product</b></figcaption></figure><p>It is worth remarking that both CPDs and joint distribution are factors. As each Bayesian network define a joint distribution factor, which is the product of the CPDs factor. Specifically, let $\phi_{X_i}(X_i,\text{Pa}_{X_i})$ denote $P(X\vert\text{Pa}_{X_i})$, we can write
\begin{equation}
P(X_1,\ldots,X_n)=\prod_{i=1}^{n}\phi_{X_i}
\end{equation}</p><h4 id=markov-random-fields>Markov Random Fields<a hidden class=anchor aria-hidden=true href=#markov-random-fields>#</a></h4><p>Given the notions of factor and factor product, we are now ready to define an undirected parameterization of a distribution.</p><p>An <strong>Undirected Graphical Model</strong> (or <strong>Markov Random Field</strong>, or <strong>Markov network</strong>) is defined by an undirected graph $\mathcal{H}$ and a probability distribution $P_\Phi$ parameterized by a set of factors $\Phi=\{\phi_1(\mathbf{D}_1),\ldots,\phi_K(\mathbf{D}_K)\}$ over variables $X_1,\ldots,X_n$ such that
\begin{equation}
P_\Phi(X_1,\ldots,X_n)=\frac{1}{Z}\tilde{P}_\Phi(X_1,\ldots,X_n),
\end{equation}
where</p><ul id=number-list><li>Each node of $\mathcal{H}$ correspond to a variable $X_i$.</li><li>The factor product
\begin{equation}
\tilde{P}_\Phi(X_1,\ldots,X_n)=\phi_1(\mathbf{D}_1)\times\ldots\times\phi_K(\mathbf{D}_K)
\end{equation}
is an unnormalized measure.</li><li>$Z$ is a normalizing constant called the <b>partition function</b>, given by
\begin{equation}
Z=\sum_{X_1,\ldots,X_n}\tilde{P}_\Phi(X_1,\ldots,X_n)
\end{equation}</li><li>$P_\Phi$ is also called a <b>Gibbs distribution</b>, which <b>factorizes</b> over $\mathcal{H}$, in the sense that each $\mathbf{D}_k$ for $k=1,\ldots,K$ is a complete subgraph (or <a href=#clique>clique</a>) of $\mathcal{H}$.</li><li>The factors $\phi_1,\ldots,\phi_K$ that parameterize $\mathcal{H}$ are referred as <b>clique potentials</b>, or <b>potential functions</b> of $\mathcal{H}$.</li></ul><h4 id=reduced-markov-networks>Reduced Markov Networks<a hidden class=anchor aria-hidden=true href=#reduced-markov-networks>#</a></h4><p>Consider the task of conditioning a distribution on some assignment $\mathbf{u}$ to some subset of variables $\mathbf{U}$. This task corresponds to the process</p><ul id=number-list><li><b>Step 1</b>. Eliminate all entries in the joint distribution that are inconsistent with the event $\mathbf{U}=\mathbf{u}$.</li><li><b>Step 2</b>. Normalize the remaining entries to sum to $1$.</li></ul><p>Consider the case that the distribution is in form of $P_\Phi$ for some set of factor $\Phi$.</p><h5 id=factor-reduction>Factor Reduction<a hidden class=anchor aria-hidden=true href=#factor-reduction>#</a></h5><p>Let $\phi(\mathbf{Y})$ be a factor, and let $\mathbf{U}=\mathbf{u}$ be an assignment for $\mathbf{U}\subset\mathbf{Y}$. The <strong>reduction</strong> of the factor $\phi$ to the context $\mathbf{U}=\mathbf{u}$, denoted $\phi[\mathbf{U}=\mathbf{u}]$, or $\phi[\mathbf{u}]$ for short, is defined to be a factor over scope $\mathbf{Y}&rsquo;=\mathbf{Y}\backslash\mathbf{U}$, such that
\begin{equation}
\phi[\mathbf{u}](\mathbf{y}&rsquo;)=\phi(\mathbf{y}&rsquo;,\mathbf{u})
\end{equation}
For $\mathbf{U}\not\subset\mathbf{Y}$, we define $\phi[\mathbf{u}]$ to be $\phi[\mathbf{U}&rsquo;=\mathbf{u}&rsquo;]$ where</p><ul><li>$\mathbf{U}&rsquo;=\mathbf{U}\cap\mathbf{Y}$;</li><li>$\mathbf{u}&rsquo;\doteq\mathbf{u}[\mathbf{U}&rsquo;]$, where $\mathbf{u}[\mathbf{U}&rsquo;]$ denotes the assignment in $\mathbf{u}$ to the variable in $\mathbf{U}&rsquo;$.</li></ul><p><strong>Example 1</strong>: Consider the factor $\phi$ with $\text{Scope}(\phi)=\{A,B,C\}$, as given in the right-most table of <a href=#fig4>Figure 4</a>. The reduction of $\phi$ to the context $C=c^1$ is a factor over scope $\{A,B,C\}\backslash\{C\}=\{A,B\}$, given by
\begin{equation}
\phi[c^1](a,b)=\phi(a,b,c^1),
\end{equation}
which is illustrated in the following table</p><figure><img src=/images/pgm-representation/factor-reduction.png alt="Factor reduction" width=20% height=20%><figcaption><b>Figure 5</b>: (taken from the <a href=#pgm-book>PGM book</a>) <b>Factor reduction</b>: The factor computed in <a href=fig4>Figure 4</a>, reduced to the context $C=c^1$.</figcaption></figure><p>With the definition of factor reduction, let us consider a product of factors. We have that an entry in the product is consistent with $\mathbf{u}$ iff it is a product of entries that are all consistent with $\mathbf{u}$.</p><h5 id=reduced-gibbs-distribution>Reduced Gibbs Distribution<a hidden class=anchor aria-hidden=true href=#reduced-gibbs-distribution>#</a></h5><p>Let $P_\Phi$ be a Gibbs distribution parameterized by $\Phi=\{\phi_1,\ldots,\phi_K\}$, and let $\mathbf{u}$ be a context. The <strong>reduced Gibbs distribution</strong> $P_\Phi[\mathbf{u}]$ is the Gibbs distribution defined by the set of factors
\begin{equation}
\Phi[\mathbf{u}]=\{\phi_1[\mathbf{u}],\ldots,\phi_K[\mathbf{u}]\}
\end{equation}</p><p><strong>Proposition 8</strong>: <em>Let $P_\Phi(\mathbf{X})$ be a Gibbs distribution, we then have</em>
\begin{equation}
P_\Phi[\mathbf{u}]=P_\Phi(\mathbf{W}\vert\mathbf{u}),
\end{equation}
<em>where $\mathbf{W}=\mathbf{X}\backslash\mathbf{U}$.</em></p><h5 id=reduced-markov-network>Reduced Markov Network<a hidden class=anchor aria-hidden=true href=#reduced-markov-network>#</a></h5><p>Let $\mathcal{H}$ be a Markov network over the nodes $\mathbf{X}$ and $\mathbf{U}=\mathbf{u}$ be a context. The <strong>reduced Markov network</strong> $\mathcal{H}[\mathbf{u}]$ is a Markov network over the nodes $\mathbf{W}=\mathbf{X}\backslash\mathbf{U}$, where we have an edge $X-Y$ if there is an edge $X-Y$ in $\mathcal{H}$.</p><p><strong>Proposition 9</strong>: <em>Let $P_\Phi(\mathbf{X})$ be a Gibbs distribution that factorizes over $\mathcal{H}$, and let $\mathbf{U}=\mathbf{u}$ be a context. Then we have that $P_\Phi[\mathbf{u}]$ factorizes over $\mathcal{H}[\mathbf{u}]$.</em></p><figure><img src=/images/pgm-representation/reduced-markov-network.png alt="Reduced Markov network" width=90% height=90%><figcaption><b>Figure 6</b>: (taken from the <a href=#pgm-book>PGM book</a>) <b>An example of a Markov network and the reduction of its factors to some contexts</b> (a) The initial Markov network; (b) The reduced network to the context $G=g$; (c) The reduced network to the context $G=g,S=s$.</figcaption></figure><h3 id=independencies-in-markov-network>Independencies in Markov Network<a hidden class=anchor aria-hidden=true href=#independencies-in-markov-network>#</a></h3><p>Analogy to Bayesian network, the graph structure in a Markov Random Field can be viewed as encoding a set of independence assumptions, which can be specified by considering the undirected paths through nodes.</p><h4 id=separation>Separation<a hidden class=anchor aria-hidden=true href=#separation>#</a></h4><p>Let $\mathcal{H}$ be a Markov network structure and let $X_1-\ldots-X_k$ be a <a href=#path>path</a> in $\mathcal{H}=(\mathcal{X},\mathcal{E})$. Let $\mathbf{Z}\subset\mathcal{X}$ be a set of observed variables. Then $X_1-\ldots-X_k$ is <strong>active</strong> given $\mathbf{Z}$ if none of $X_1,\ldots,X_k$ is in $\mathbf{Z}$.</p><p>Let $\mathbf{X},\mathbf{Y}$ be set of nodes in $\mathcal{H}$. We say that $\mathbf{Z}$ <strong>separates</strong> $\mathbf{X}$ and $\mathbf{Y}$, denoted $\text{sep}_\mathcal{H}(\mathbf{X};\mathbf{Y}\vert\mathbf{Z})$ if there is no active path between any node $X\in\mathbf{X}$ and $Y\in\mathbf{Y}$ given $\mathbf{Z}$.</p><h4 id=global-markov-independencies>Global Markov Independencies<a hidden class=anchor aria-hidden=true href=#global-markov-independencies>#</a></h4><p>As in the case of Bayesian network, we define the <strong>global Markov independencies</strong> associated with $\mathcal{H}$, denoted $\mathcal{I}(\mathcal{H})$, to be the set of all independencies correspond to separation in $\mathcal{H}$
\begin{equation}
\mathcal{I}(\mathcal{H})=\big\{(\mathbf{X}\perp\mathbf{Y}\vert\mathbf{Z}):\text{sep}_\mathcal{H}(\mathbf{X};\mathbf{Y}\vert\mathbf{Z})\big\}
\end{equation}</p><h4 id=local-markov-independencies>Local Markov Independencies<a hidden class=anchor aria-hidden=true href=#local-markov-independencies>#</a></h4><p>Let $\mathcal{H}$ be a Markov network. We define the <strong>pairwise independencies</strong> associated with $\mathcal{H}$ to be
\begin{equation}
\mathcal{I}_p(\mathcal{H})=\big\{(X\perp Y\vert\mathcal{X}\backslash\{X,Y\}):X-Y\notin\mathcal{H}\big\}
\end{equation}
Or in other words, the pairwise independencies states that $X$ and $Y$ are independent given all other nodes in $\mathcal{H}$.</p><p>For a given graph $\mathcal{H}$ and for an arbitrary node $X$ of $\mathcal{H}$, the set of <a href=#neighbor>neighbors</a> of $X$ is also called the <strong>Markov blanket</strong> of $X$, denoted $\text{MB}_\mathcal{H}(X)$. With this notion, we define the <strong>local independencies</strong>, or <strong>Markov local independencies</strong>, associated with $\mathcal{H}$ to be
\begin{equation}
\mathcal{I}_\ell(\mathcal{H})=\big\{\big(X\perp\mathcal{X}\backslash(\{X\}\cup\text{MB}_\mathcal{H}(X))\vert\text{MB}_\mathcal{H}(X)\big):X\in\mathcal{X}\big\}
\end{equation}
Or in other words, the Markov local independencies says that $X$ is independent of the rest of the nodes in $\mathcal{H}$ given its neighbors.</p><p>The definition of <strong>Markov blanket</strong> can also be rewritten using independencies assertions:<br>A set $\mathbf{U}$ is a <strong>Markov blanket</strong> of $X$ in a distribution $P$ if $X\notin\mathbf{U}$ and if $\mathbf{U}$ is a minimal set of nodes such that
\begin{equation}
\big(X\perp\mathcal{X}\backslash(\{X\}\cup\mathbf{U})\vert\mathbf{U}\big)\in\mathcal{I}(P)
\end{equation}</p><h4 id=markov-independencies-relationships>Markov Independencies Relationships<a hidden class=anchor aria-hidden=true href=#markov-independencies-relationships>#</a></h4><p><strong>Theorem 10</strong>: <em>Let $\mathcal{H}$ be a Markov network and $P$ be a positive distribution. The following three statement are then equivalent:</em></p><ul id=roman-list style=font-style:italic><li>$P\models\mathcal{I}_\ell(\mathcal{H})$.</li><li>$P\models\mathcal{I}_p(\mathcal{H})$.</li><li>$P\models\mathcal{I}(\mathcal{H})$.</li></ul><p><strong>Proof</strong></p><ul id=number-list><li>(i) $\Rightarrow$ (ii)<br>Consider an arbitrary node $X$ in $\mathcal{H}$. Let $Y\in\mathcal{X}$ such that $X-Y\notin\mathcal{H}$, then $Y\notin\text{MB}_\mathcal{H}(X)$, or in other words
\begin{equation}
Y\in\mathcal{X}\backslash(\{X\}\cup\text{MB}_\mathcal{H}(X))
\end{equation}
Moreover, since $P\models\mathcal{I}_\ell(\mathcal{H})$, we have that $P$ satisfies
\begin{equation}
\big(X\perp\mathcal{X}\backslash(\{X\}\cup\text{MB}_\mathcal{H}(X))\vert\text{MB}_\mathcal{H}(X)\big),
\end{equation}
which implies that
\begin{equation}
\big(X\perp Y\vert\text{MB}_\mathcal{X}\cup\mathcal{X}\backslash(\{X,Y\}\cup\text{MB}_\mathcal{H}(X))\big)
\end{equation}
holds for $P$. Or in other words, for any $X,Y$ such that $X-Y\notin\mathcal{H}$, we have
\begin{equation}
P\models(X\perp Y\vert\mathcal{X}\backslash\{X,Y\}),
\end{equation}
which proves our claim.</li><li>(ii) $\Rightarrow$ (iii)</li><li>(iii) $\Rightarrow$ (i)<br>This follows directly from the fact that if two nodes $X$ and $Y$ are not connected, then they are necessarily separated by all remaining nodes of the graph.</li></ul><h4 id=soundness-completeness-mn>Soundness, Completeness<a hidden class=anchor aria-hidden=true href=#soundness-completeness-mn>#</a></h4><p><strong>Theorem 11</strong> (Soundness of separation) <em>Let $\mathcal{H}=(\mathcal{X},\mathcal{E})$ be a Markov network structure and let $P$ be a distribution over $\mathcal{X}$. If $P$ is a Gibbs distribution that factorizes over $\mathcal{H}$, then $\mathcal{H}$ is an I-map for $P$.</em></p><p><strong>Proof</strong><br>Let $\mathbf{X},\mathbf{Y}$ and $\mathbf{Z}$ be any disjoint subsets of $\mathcal{X}$ such that $\text{sep}_\mathcal{H}(\mathbf{X};\mathbf{Y}\vert\mathbf{Z})$. We need to show that
\begin{equation}
P\models(\mathbf{X}\perp\mathbf{Y}\vert\mathbf{Z})
\end{equation}
We begin by considering the case that $\mathbf{X}\cup\mathbf{Y}\cup\mathbf{Z}=\mathcal{X}$. Since $\mathbf{Z}$ separates $\mathbf{X}$ and $\mathbf{Y}$, then for any $X\in\mathbf{X}$ and for any $Y\in\mathbf{Y}$, there is no direct edge between $X,Y$. This implies that any clique in $\mathcal{H}$ is either in $\mathbf{X}\cup\mathbf{Z}$ or in $\mathbf{Y}\cup\mathbf{Z}$.</p><p>Let $I_\mathbf{X}$ denote the indices of the set of cliques within $\mathbf{X}\cup\mathbf{Z}$ and let $I_\mathbf{Y}$ represent the indices of the ones in $\mathbf{Y}\cup\mathbf{Z}$. Thus, as $P$ factorizes over $\mathcal{H}$, we have that
\begin{align}
P(X_1,\ldots,X_n)&=\frac{1}{Z}\prod_{i}\phi_i(\mathbf{D}_i) \\ &=\frac{1}{Z}\left(\prod_{i\in I_\mathbf{X}}\phi_i(\mathbf{D}_i)\right)\cdot\left(\prod_{i\in I_\mathbf{Y}}\phi_i(\mathbf{D}_i)\right) \\ &=\frac{1}{Z}\phi_\mathbf{X}(\mathbf{X},\mathbf{Z})\phi_\mathbf{Y}(\mathbf{Y},\mathbf{Z}),
\end{align}
where $\phi_\mathbf{X},\phi_\mathbf{Y}$ are some factors with scopes $\mathbf{X}\cup\mathbf{Z}$ and $\mathbf{Y}\cup\mathbf{Z}$ respectively. Hence, it follows that
\begin{equation}
P\models(\mathbf{X}\perp\mathbf{Y}\vert\mathbf{Z})
\end{equation}
Now consider the case that $\mathbf{X}\cup\mathbf{Y}\cup\mathbf{Z}\subset\mathcal{X}$. Let $\mathbf{U}=\mathcal{X}\backslash(\mathbf{X}\cup\mathbf{Y}\cup\mathbf{Z})$. We can divide $\mathbf{U}$ into two disjoint sets $\mathbf{U}_1$ and $\mathbf{U}_2$ such that
\begin{equation}
\text{sep}_\mathcal{H}(\mathbf{X}\cup\mathbf{U}_1;\mathbf{Y}\cup\mathbf{U}_2\vert\mathbf{Z})
\end{equation}
And since $(\mathbf{X}\cup\mathbf{U}_1)\cup(\mathbf{Y}\cup\mathbf{U}_2)\cup\mathbf{Z}=\mathcal{X}$, we can follow the previous procedure to conclude that
\begin{equation}
P\models(\mathbf{X}\cup\mathbf{U}_1\perp\mathbf{Y}\cup\mathbf{U}_2\vert\mathbf{Z}),
\end{equation}
which implies that
\begin{equation}
P\models(\mathbf{X}\perp\mathbf{Y}\vert\mathbf{Z})
\end{equation}</p><p><strong>Theorem 12</strong> (Hammersley-Clifford) <em>Let $\mathcal{H}=(\mathcal{X},\mathcal{E})$ be a Markov network structure and let $P$ be a positive distribution over $\mathcal{X}$. If $\mathcal{H}$ is an I-map for $P$, then $P$ is a Gibbs distribution that factorizes over $\mathcal{H}$.</em></p><p><strong>Corollary 13</strong>: <em>The positive distribution $P$ factorizes a Markov network $\mathcal{H}$ iff $\mathcal{H}$ is an I-map for $P$</em>.</p><p><strong>Theorem 14</strong> (Completeness of separation) <em>Let $\mathcal{H}$ be a Markov network structure. If $X$ and $Y$ are not separated given $\mathbf{Z}$ in $\mathcal{H}$, then $X$ and $Y$ are dependent given $\mathbf{Z}$ in some distribution $P$ that factorizes over $\mathcal{H}$.</em></p><h3 id=dist2graph-mn>From Distributions to Graphs<a hidden class=anchor aria-hidden=true href=#dist2graph-mn>#</a></h3><p>As <a href=#min-imap>mentioned</a> above, the notion of minimal I-map lets us encode the independencies of a given distribution $P$ using a graph structure.</p><p>In particular, for a distribution $P$, we can construct the minimal I-map based on either the pairwise independencies or the local independencies.</p><p><strong>Theorem 15</strong>: <em>Let $P$ be a positive distribution and $\mathcal{H}$ be a Markov network defined by including an edge $X-Y$ for all $X,Y$ such that $P\not\models(X\perp Y\vert\mathcal{X}\backslash\{X,Y\})
$. Then $\mathcal{H}$ is the unique minimal I-map for $P$.</em></p><p><span id=theorem16><strong>Theorem 16</strong></span>: <em>Let P be a positive distribution and let $\mathcal{H}$ be a Markov network defined by including an edge $X-Y$ for all $X$ and all $Y\in\text{MB}_\mathcal{H}(X)$. Then $\mathcal{H}$ is the unique minimal I-map for $P$.</em></p><p><strong>Remark</strong>: Not every distribution has a perfect map as UGM (proof by contradiction).</p><h4 id=factor-graphs>Factor Graphs<a hidden class=anchor aria-hidden=true href=#factor-graphs>#</a></h4><p>A <strong>factor graph</strong> $\mathcal{F}$ is an undirected graph whose nodes are divided into two groups: variable nodes (denoted as ovals) and factor nodes (denoted as squares) and whose edges only connect each factor (potential function) $\psi_c$ to its dependent nodes $X\in X_c$.</p><figure id=fig7><img src=/images/pgm-representation/factor-graphs.png alt="Same Markov network different factor graphs"><figcaption><b>Figure 7</b>: (based on figure from the <a href=#pgm-book>PGM book</a>) <b>Different factor graphs for the same Markov network</b>: (a) A Markov network consists of nodes $X_1,X_2,X_3$; (b) A factor graph with a factor $\psi_{1,2,3}$ connected to each $X_1,X_2,X_3$; (c) A factor graph with three pairwise factors $\psi_{1,2}$ (connected to $X_1,X_2$), $\psi_{1,3}$ (connected to $X_1,X_3$) and $\psi_{2,3}$ (connected to $X_2,X_3$)</figcaption></figure><h4 id=log-linear-models>Log-Linear Models<a hidden class=anchor aria-hidden=true href=#log-linear-models>#</a></h4><p>A distribution $P$ is a <strong>log-linear model</strong> over a Markov network $\mathcal{H}$ if it is associated with</p><ul id=number-list><li>a set of features $\mathcal{F}=\{\phi_1(\mathbf{X}_1),\ldots,\phi_k(\mathbf{X}_k)\}$ where each $\mathbf{X}_i$ is a complete subgraph in $\mathcal{H}$,</li><li>a set of weight $w_1,\ldots,w_k$, such that
\begin{equation}
P(X_1,\ldots,X_n)=\frac{1}{Z}\exp\left[-\sum_{i=1}^{k}w_i\phi_i(\mathbf{X}_i)\right]
\end{equation}</li></ul><p>The function $\phi_i$ are called <strong>energy functions</strong>.</p><h4 id=canonical-parameterization>Canonical Parameterization<a hidden class=anchor aria-hidden=true href=#canonical-parameterization>#</a></h4><p>The <strong>canonical parameterization</strong> of a Gibbs distribution over $\mathcal{H}$ is defined via a set of energy functions over <em>all</em> cliques. For instance, the Markov network given in <a href=#fig7>Figure 7(a)</a> would have energy functions for each of the cliques
\begin{equation}
\{\{X_1,X_2,X_3\},\{X_1,X_2\},\{X_2,X_3\},\{X_1,X_3\},\{X_1\},\{X_2\},\{X_3\}\},
\end{equation}
plus a constant energy function for the empty clique.</p><h3 id=bayesian--markov-networks>Bayesian & Markov Networks<a hidden class=anchor aria-hidden=true href=#bayesian--markov-networks>#</a></h3><p>We are ready to derive the relationship between representations: Bayesian network and Markov network. Specifically, we can find a Bayesian network which is a minimal I-map for a given Markov network and vice versa.</p><h4 id=bn-2-mrf>Bayesian Networks to Markov Networks<a hidden class=anchor aria-hidden=true href=#bn-2-mrf>#</a></h4><p>Let us begin by considering a distribution $P_\mathcal{B}$, where $\mathcal{B}$ is a parameterized network over a graph $\mathcal{G}$. Then, $P_\mathcal{B}$ can be seen as a Gibbs distribution by considering each CPD $P(X_i\vert\text{Pa}_{X_i})$ as a factor with scope $X_i,\text{Pa}_{X_i}$. This Gibbs distribution then has $1$ as its partition function.</p><p><span id=prop17><strong>Proposition 17</strong></span>: <em>Let $\mathcal{B}$ be a Bayesian network over $\mathcal{X}$ and let $\mathbf{E}=\mathbf{e}$ be an observation. Let $\mathbf{W}=\mathcal{X}\backslash\mathbf{E}$. Then $P_\mathcal{B}(\mathbf{W}\vert\mathbf{e})$ is a Gibbs distribution, defined by the factors $\Phi=\{\phi_{X_i}\}_{X_i\in\mathcal{X}}$, where</em>
\begin{equation}
\phi_{X_i}=P_\mathcal{B}(X_i\vert\text{Pa}_{X_i})[\mathbf{E}=\mathbf{e}]
\end{equation}
<em>The partition function for this Gibbs distribution is $P(\mathbf{e})$</em>.</p><p>This result lets us consider any Bayesian network conditioned as evidence $\mathbf{e}$ as a Gibbs distribution with partion function $P(\mathbf{e})$.</p><p>To find the undirected graph serving as an I-map for a set of factors in a Bayesian network, we recall that we have considered each CPD $P(X_i\vert\text{Pa}_{X_i})$ as a factor with scope $X_i,\text{Pa}_{X_i}$, in the undirected I-map. Therefore, in the undirected I-map, we need to have an edge between $X_i$ and each of its parents, as well as between all of the parents of $X_i$ (due to each factor corresponds to a clique).</p><h5 id=moralized-graph>Moralized Graph<a hidden class=anchor aria-hidden=true href=#moralized-graph>#</a></h5><p>The <strong>moral graph</strong> $\mathcal{M}[\mathcal{G}]$ of a Bayesian network structure $\mathcal{G}$ over $\mathcal{X}$ is the undirected graph over $\mathcal{X}$ that consists of an undirected edge between $X$ and $Y$ if</p><ul id=alpha-list><li>there is a directed edge between them (in either direction), or</li><li>$X$ and $Y$ are both parents of the same node.</li></ul><figure><img src=/images/pgm-representation/moral-graph.png alt="Moral graph" width=70% height=70%><figcaption><b>Figure 8</b>: (based on figure from the <a href=#pgm-book>PGM book</a>) <b>A Bayesian network and its moral graph</b>: (a) A Bayesian network; (b) The moral graph established by converting directed edges into undirected, plus adding edges between non-connected nodes which are both parents of the same nodes (newly created edges are denoted as $\color{red}{red}$ color)</figcaption></figure><p>The construction of moral graphs follows directly to a result.</p><p><strong>Corollary 18</strong>: <em>Let $\mathcal{G}$ be a BN graph. Then for any distribution $P_\mathcal{B}$ such that $\mathcal{B}$ is a parameterization of $\mathcal{G}$, we have that $\mathcal{M}[\mathcal{G}]$ is an I-map for $P_\mathcal{B}$.</em></p><p><span id=prop19><strong>Proposition 19</strong></span>: <em>Let $\mathcal{G}$ be any BN graph. The moralized graph $\mathcal{M}[\mathcal{G}]$ is a minimal I-map for $\mathcal{G}$.</em></p><p><strong>Proof</strong><br>We begin by introducing the notion of <strong>Markov blanket</strong> in a Bayesian network $\mathcal{G}$.<br><strong>Definition</strong> (Markov blanket in BN) The <strong>Markov blanket</strong> of a node $X\in\mathcal{X}$ in a Bayesian network $\mathcal{G}$, denoted $\text{MB}_\mathcal{G}(X)$, is the set of $X$&rsquo;s parents, $X$&rsquo;s children, and other parents of $X$&rsquo;s children.</p><p>Let $X\in\mathcal{X}$ be a node of $\mathcal{G}$, we have that $\text{MB}_\mathcal{G}(X)$ d-separates $X$ from all other variables in $\mathcal{G}$; and that no subset of $\text{MB}_\mathcal{G}(X)$ has that property. Specifically:</p><ul id=roman-list><li>Let $\mathbf{W}=\mathcal{X}\backslash\big(\{X\}\cup\text{MB}_\mathcal{G}(X)\big)$, and let $Z\in\text{MB}_\mathcal{G}(X)$ be some node in the Markov blanket of $X$. Then for each $Y\in\mathbf{W}$ that connected to $X$ via a trail, we have three possible cases:
\begin{equation}
X\rightarrow Z\rightarrow Y;X\leftarrow Z\leftarrow Y;X\leftarrow Z\rightarrow Y
\end{equation}
The v-structure is excluded due to the definition of $\text{MB}_\mathcal{G}(X)$, i.e. if $X\rightarrow Z\leftarrow Y$ exists, then $Y\in\text{MB}_\mathcal{G}(X)$. As $\text{MB}_\mathcal{G}(X)$ is given, $Z$ is observed, all of those 2-edge trails are then in-active, which implies that $\text{d-sep}_\mathcal{G}(X;Y\vert Z)$, and thus $\text{d-sep}_\mathcal{G}(X;\mathbf{W}\vert\text{MB}_\mathcal{G}(X))$.</li><li>As we have mentioned above that if a v-structure exists, then $Y$ must be in the Markov blanket of $X$, it follows directly that $\text{MB}_\mathcal{G}(X)$ is the minimal set having the property.</li></ul><p>Thus, in other words, we can conclude that the Markov blanket of $X$, $\text{MB}_\mathcal{G}(X)$, the smallest set required to render $X$ independent of all other nodes in $\mathcal{G}$. For each $X\in\mathcal{X}$, by viewing its Markov blanket in $\mathcal{G}$ as the set of its neighbors in an undirected graph $\mathcal{H}$ (which is the definition of Markov blanket in a Markov network), we then have that $\mathcal{H}$ is a minimal I-map for $\mathcal{G}$. Additionally, by how it is constructed, $\mathcal{H}$ is also a moral graph of $\mathcal{G}$, and thus $\mathcal{I}(\mathcal{H})\subset\mathcal{I}(\mathcal{G})$.</p><p><strong>Remark</strong>:</p><ul id=number-list><li>The addition of the moralizing edges to the Markov network $\mathcal{H}$ leads to the loss of independence information implied by $\mathcal{G}$.</li><li>However, moralization causes loss of independencies assertions only when it introduces new edges into the graph.</li></ul><p><strong>Proposition 20</strong>: <em>If the directed graph $\mathcal{G}$ is <strong>moral</strong> (in the sense that it contains no <a href=#immorality>immoralities</a>, i.e. for any pair of $X,Y$ in $\mathcal{G}$ sharing a child, there is a covering edge between $X$ and $Y$), then its moralized graph $\mathcal{M}[\mathcal{G}]$, which now has the same edges as $\mathcal{G}$, is a perfect map of $\mathcal{G}$.</em></p><p>In other words, this result states that a moral graph $\mathcal{G}$ can be converted to a Markov network without losing independencies assertions.</p><p><strong>Proof</strong><br>Let $\mathcal{H}=\mathcal{M}[\mathcal{G}]$, then $\mathcal{H}$ and $\mathcal{G}$ have the same edges. As in <a href=#prop19>Proposition 19</a>, we have shown that $\mathcal{I}(\mathcal{H})\subset\mathcal{I}(\mathcal{G})$, our problem remains to prove that $\mathcal{I}(\mathcal{H})\supset\mathcal{I}(\mathcal{G})$.<br>Assume that there is an independence
\begin{equation}
(\mathbf{X}\perp\mathbf{Y}\vert\mathbf{Z})\in\mathcal{I}(\mathcal{G}),
\end{equation}
which is not in $\mathcal{I}(\mathcal{H})$. This implies that there exists some active trail from $\mathbf{X}$ to $\mathbf{Y}$ given $\mathbf{Z}$ in $\mathcal{H}$. Consider some such trail which is minimal. As $\mathcal{H},\mathcal{G}$ have same edges, the same trail must also exist in $\mathcal{G}$. Thus, it is also in-active in $\mathcal{G}$ given $\mathbf{Z}$, which implies that it contains a v-structure, say $X_1\rightarrow X_2\leftarrow X_3$. Moreover, as $\mathcal{G}$ is moral, there exists an edge connecting $X_1$ and $X_3$, contradicts the assumption that the trail is minimal.</p><h4 id=markov-networks-to-bayesian-networks>Markov Networks to Bayesian Networks<a hidden class=anchor aria-hidden=true href=#markov-networks-to-bayesian-networks>#</a></h4><p><strong>Theorem 21</strong>: <em>Let $\mathcal{H}$ be a Markov network graph, and let $\mathcal{G}$ be any Bayesian network minimal I-map for $\mathcal{H}$. Then $\mathcal{G}$ can have no immoralities.</em></p><h3 id=crf>Conditional Random Fields<a hidden class=anchor aria-hidden=true href=#crf>#</a></h3><p>A <strong>conditional random field</strong>, or <strong>CRF</strong>, is an undirected graph $\mathcal{H}$ whose nodes correspond to $\mathbf{X}\cup\mathbf{Y}$ where $\mathbf{X}$ is a set of observed variables and $\mathbf{Y}$ is a (disjoint) set of target variables which specifies a conditional distribution (instead of a joint distribution)
\begin{equation}
P(\mathbf{Y}\vert\mathbf{X})=\frac{1}{Z(\mathbf{X})}\prod_{c\in C}\psi_c(\mathbf{X}_c,\mathbf{Y}_c),
\end{equation}
where the partition function $Z(\mathbf{X})$ now depends on $\mathbf{X}$ (rather than being a constant)
\begin{equation}
Z(\mathbf{X})=\sum_\mathbf{Y}\prod_{c\in C}\psi_c(\mathbf{X}_c,\mathbf{Y}_c)
\end{equation}</p><h4 id=example---naive-markov>Example - Naive Markov<a hidden class=anchor aria-hidden=true href=#example---naive-markov>#</a></h4><p>Consider a CRF over the binary-value variables $\mathbf{X}=\{X_1,\ldots,X_k\}$ and $\mathbf{Y}=\{Y\}$, and a pairwise potential between $Y$ and each $X_i$. The model is referred as a <strong>naive Markov model</strong>. Assume that the pairwise potentials defined via the log-linear model
\begin{equation}
\psi_i(X_i,Y)=\exp\big[w_i\mathbf{1}\{X_i=1,Y=1\}\big]
\end{equation}
Additionally, we also have a single-node potential
\begin{equation}
\psi_0(Y)=\exp\big[w_0\mathbf{1}\{Y=1\}\big]
\end{equation}
We then have that
\begin{equation}
P(Y=1\vert x_1,\ldots,x_k)=\frac{1}{1+\exp\left[-\left(w_0+\sum_{i=1}^{k}w_i x_i\right)\right]}
\end{equation}</p><h2 id=local-probabilistic-models>Local Probabilistic Models<a hidden class=anchor aria-hidden=true href=#local-probabilistic-models>#</a></h2><h3 id=tabular-cpds>Tabular CPDs<a hidden class=anchor aria-hidden=true href=#tabular-cpds>#</a></h3><p>For a space of discrete-valued random variables only, we can encode the CPDs $P(X\vert\text{Pa}_X)$ as a table where each entry corresponds to a pair of $X,\text{Pa}_X$.</p><p>It is easily seen that this representation raises a disadvantage that the number of parameters required grows exponentially in the number of parents. Also, it is impossible to store the conditional probability corresponding to a continuous-valued random variables.</p><p>To avoid these problems, instead of viewing CPDs as tables listing all of the conditional probabilities $P(x\vert\text{pa}_X)$, we should consider them as functions that given $\text{pa}_X$ and $x$, return the conditional probability $P(x\vert\text{pa}_X)$.</p><h3 id=deterministic-cpds>Deterministic CPDs<a hidden class=anchor aria-hidden=true href=#deterministic-cpds>#</a></h3><p>The simplest type of non-tabular CPD corresponds to a variable $X$ being a deterministic function of its parents $\text{Pa}_X$. It means, there exists $f:\text{Val}(Pa_X)\mapsto\text{Val}(X)$ such that
\begin{equation}
P(x\vert\text{pa}_X)=\begin{cases}1&\hspace{1cm}x=f(\text{pa}_X) \\ 0&\hspace{1cm}\text{otherwise}\end{cases}
\end{equation}
Deterministic variables are denoted as double-line ovals, as illustrated in the following example</p><figure id=fig9><img src=/images/pgm-representation/det-cpd.png alt="Network with a deterministic CPD" width=30% height=30%><figcaption><b>Figure 9</b>: (taken from the <a href=#pgm-book>PGM book</a>) <b>A network with $C$ being a deterministic function of $A$ and $B$.</b></figcaption></figure><p>Consider the above figure, as $C$ being a deterministic function of $A$ and $B$, we can deduce that $C$ is fully observed if $A$ and $B$ are both observed. In other words, we have that
\begin{equation}
(D\perp E\vert A,B)
\end{equation}</p><p><strong>Theorem 22</strong>: <em>Let $\mathcal{G}$ be a network structure, and let $\mathbf{X},\mathbf{Y},\mathbf{Z}$ be sets of variables, $\mathbf{D}$ be set of deterministic variables. If $\mathbf{X}$ is <strong>deterministically separated</strong> from $\mathbf{Y}$ given $\mathbf{Z}$<sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup>, then for all distributions $P$ such that $P\models\mathcal{I}_\ell(\mathcal{G})$ and where, for each $X\in\mathbf{D}$, $P(X\vert\text{Pa}_X)$ is a deterministic CPD, we have that $P\models(\mathbf{X}\perp\mathbf{Y}\vert\mathbf{Z})$</em>.</p><p><strong>Theorem 23</strong>: <em>Let $\mathcal{G}$ be a network structure, and let $\mathbf{X},\mathbf{Y},\mathbf{Z}$ be sets of variables, $\mathbf{D}$ be set of deterministic variables. If $\mathbf{X}$ is not deterministically separated from $\mathbf{Y}$ given $\mathbf{Z}$, then there exists a distribution $P$ such that $P\models\mathcal{I}_\ell(\mathcal{G})$ and where, for each $X\in\mathbf{D}$, $P(X\vert\text{Pa}_X)$ is a deterministic CPD, but we instead have $P\not\models(\mathbf{X}\perp\mathbf{Y}\vert\mathbf{Z})$</em>.</p><p>It is worth remarking that particular deterministic CPD might imply additional independencies. For instance, let us consider the following examples</p><p><strong>Example 2</strong>: Consider the following Bayesian network</p><figure id=fig10><img src=/images/pgm-representation/complex-det-cpd.png alt="Network with a deterministic CPD" width=40% height=40%><figcaption><b>Figure 10</b>: (taken from the <a href=#pgm-book>PGM book</a>) <b>Another Bayesian network with $C$ being a deterministic function of $A$ and $B$</b>.</figcaption></figure><p>In the above figure, if $C=A\text{ XOR }B$, we have that $A$ is fully determined given $C$ and $B$. In other words, we have that
\begin{equation}
(D\perp E\vert B,C)
\end{equation}
<strong>Example 3</strong>: Consider the network given in <a href=#fig9>Figure 9</a>, with $C=A\text{ OR }B$. Assume that we are given $A=a^1$, it is then immediately that $C=c^1$ without taking into account the value of $B$. Or in other words, we have that
\begin{equation}
P(D\vert B,a^1)=P(D\vert a^1)
\end{equation}
On the other hand, given $A=a^0$, the value of $C$ is not fully determined, and still depend the value of $B$.</p><h4 id=context-specific-independence>Context-Specific Independence<a hidden class=anchor aria-hidden=true href=#context-specific-independence>#</a></h4><p>Let $\mathbf{X},\mathbf{Y},\mathbf{Z}$ be pairwise disjoint sets of variables, let $\mathbf{C}$ be a set of variable (which might overlap with $\mathbf{X}\cup\mathbf{Y}\cup\mathbf{Z}$), and let $\mathbf{c}\in\text{Val}(\mathbf{C})$. We say that $X$ and $\mathbf{Y}$ are <strong>contextually independent</strong> given $\mathbf{Z}$ and the context $\mathbf{C}$ denoted $(\mathbf{X}\perp_c\mathbf{Y}\vert\mathbf{Z},\mathbf{c})$ if
\begin{equation}
P(\mathbf{Y},\mathbf{Z},\mathbf{c})>0\Rightarrow P(\mathbf{X}\vert\mathbf{Y},\mathbf{Z},\mathbf{c})=P(\mathbf{X}\vert\mathbf{Z},\mathbf{c})
\end{equation}
Independence statements of this form is known as the <strong>context-specific independencies (CSI)</strong>.</p><p>Given this definition, let us examine some examples.</p><p><strong>Example 4</strong>: Given the Bayesian network in <a href=#fig9>Figure 9</a> with $C$ being a deterministic function $\text{OR}$ of $A$ and $B$. By properties of $\text{OR}$ function, we can conclude some independence assertions
\begin{align}
&(C\perp_c B\hspace{0.1cm}\vert\hspace{0.1cm}a^1), \\ &(D\perp_c B\hspace{0.1cm}\vert\hspace{0.1cm}a^1), \\ &(A\perp_c B\hspace{0.1cm}\vert\hspace{0.1cm}c^0), \\ &(D\perp_c E\hspace{0.1cm}\vert\hspace{0.1cm}c^0), \\ &(D\perp_c E\hspace{0.1cm}\vert\hspace{0.1cm}b^0,c^1)
\end{align}
<strong>Example 5</strong>: Given the Bayesian network in <a href=#fig10>Figure 10</a> with $C$ being the exclusive or of $A$ and $B$. We can also conclude some independence assertions using properties of $\text{XOR}$ function
\begin{align}
&(D\perp_c E\hspace{0.1cm}\vert\hspace{0.1cm}b^1,c^0), \\ &(D\perp_c E\vert\hspace{0.1cm}b^0,c^1)
\end{align}</p><h3 id=context-specific-cpds>Context-specific CPDs<a hidden class=anchor aria-hidden=true href=#context-specific-cpds>#</a></h3><h4 id=tree-cpds>Tree-CPDs<a hidden class=anchor aria-hidden=true href=#tree-cpds>#</a></h4><p>A <strong>tree-CPD</strong> representing a CPD for variable $X$ is a rooted tree, where:</p><ul id=number-list><li>each leaf node is labeled with a distribution $P(X)$;</li><li>each internal node is labeled with some variable $Z\in\text{Pa}_X$;</li><li>each edge from an internal node, which is labeled as some $Z$, to its child nodes corresponds to a $z_i\in\text{Val}(Z)$.</li></ul><figure id=fig11><img src=/images/pgm-representation/tree-cpd.png alt=Tree-CPD width=30% height=30%><figcaption><b>Figure 11</b>: (taken from the <a href=#pgm-book>PGM book</a>) <b>A tree-CPD for $P(J\vert A,S,L)$</b>.</figcaption></figure><p>The structure is common in cases where a variable can depend on a set of r.v.s but we have uncertainty about which r.v.s it depends on. For example, in the above tree-CDP representing $P(J\vert A,S,L)$, we have that
\begin{align}
&(J\perp_c L,S\vert\hspace{0.1cm}a^0), \\ &(J\perp_c L\vert\hspace{0.1cm}a^1,s^1), \\ &(J\perp_c L\vert\hspace{0.1cm}s^1)
\end{align}</p><h5 id=multiplexer-cpd>Multiplexer CPD<a hidden class=anchor aria-hidden=true href=#multiplexer-cpd>#</a></h5><p>A CPD $P(Y\vert A,Z_1,\ldots,Z_k)$ is said to be a <strong>multiplexer CPD</strong> if $\text{Val}(A)=\{1,\ldots,k\}$ and
\begin{equation}
P(Y\vert a,Z_1,\ldots,Z_k)=\mathbf{1}\{Y=Z_a\},
\end{equation}
where $a$ is the value of $A$. The variable $A$ is referred as the <strong>selector variable</strong> for the CPD.</p><figure id=fig12><img src=/images/pgm-representation/multiplexer-cpd.png alt=Multiplexer-CPD><figcaption><b>Figure 12</b>: (based on figure from the <a href=#pgm-book>PGM book</a>) (a) A Bayesian network for $P(J,C,L_1,L_2)$; (b) Tree-CPD for $P(J\vert C,L_1,L_2)$; (c) Modified network with additional variable $L$ acting as a multiplexer CPD.</figcaption></figure><h4 id=rule-cpds>Rule CPDs<a hidden class=anchor aria-hidden=true href=#rule-cpds>#</a></h4><p>A <strong>rule</strong> $\rho$ is a pair $(\mathbf{c},p)$ where $\mathbf{c}$ is an assignment to some subset of variables $\mathbf{C}$ and $p\in[0,1]$. $\mathbf{C}$ is then referred as the <strong>scope</strong> of $\rho$, denoted $\mathbf{C}=\text{Scope}(\rho)$.</p><p>This representation decomposes a tree-CPD into its most basic elements.</p><p><strong>Example 6</strong>: Consider the tree-CPD given in <a href=#fig11>Figure 11</a>. The tree defines eight rules
\begin{equation}
\left\{\begin{array}{l}(a^0,j^0;0.8), \\ (a^0,j^1;0.2), \\ (a^1,s^0,l^0,j^0;0.9), \\ (a^1,s^0,l^0,j^1;0.1), \\ (a^1,s^0,l^1,j^0;0.4), \\ (a^1,s^0,l^1,j^1;0.6), \\ (a^1,s^1,j^0;0.1), \\ (a^1,s^1,j^1;0.9)\end{array}\right\}
\end{equation}
It is necessary that each conditional distribution $P(X\vert\text{Pa}_X)$ is specified by exactly one rule. Or in other words, the rules in a tree-CPD must be mutually exclusive and exhaustive.</p><h5 id=rule-based-cpd>Rule-based CPD<a hidden class=anchor aria-hidden=true href=#rule-based-cpd>#</a></h5><p>A <strong>rule-based CPD</strong> $P(X\vert\text{Pa}_X)$ is a set of rules $\mathcal{R}$ such that</p><ul id=roman-list><li>For each $\rho\in\mathcal{R}$, we have that
\begin{equation}
\text{Scope}(\rho)\subset\{X\}\cup\text{Pa}_X
\end{equation}</li><li>For each assignment $(x,\mathbf{u})$ to $\{X\}\cup\text{Pa}_X$, we have exactly one rule $(\mathbf{c};p)\in\mathcal{R}$ such that $\mathbf{c}$ is compatible with $(x,\mathbf{u})$. And we say that
\begin{equation}
P(X=x\vert\text{Pa}_X=\mathbf{u})=p
\end{equation}</li><li>$\sum_x P(x\vert\mathbf{u})=1$.</li></ul><p><span id=eg7><strong>Example 7</strong></span>: Let $X$ be a variable with $\text{Pa}_X=\{A,B,C\}$ with $X$&rsquo;s CPD is defined by sets of rules
\begin{equation}
\left\{\begin{array}{l}\rho_1:(a^1,b^1,x^0;0.1), \\ \rho_2:(a^1,b^1,x^1;0.9), \\ \rho_3:(a^0,c^1,x^0;0.2), \\ \rho_4:(a^0,c^1,x^1;0.8), \\ \rho_5:(b^0,c^0,x^0;0.3), \\ \rho_6:(b^0,c^0,x^1;0.7), \\ \rho_7:(a^1,b^0,c^1,x^0;0.4), \\ \rho_8:(a^1,b^0,c^1,x^1;0.6), \\ \rho_9:(a^0,b^1,c^0;0.5)\end{array}\right\}
\end{equation}
The tree-CPD corresponds to the above rule-based CPD $P(X\vert A,B,C)$ is given as:</p><figure><img src=/images/pgm-representation/rule-based-cpd.png alt=Rule-based-CPD width=50% height=50%></figure>It is worth noticing that both CPD entries $P(x^0\vert a^0,b^1,c^0)$ and $P(x^1\vert a^0,b^1,c^0)$ are determined by rule $\rho_9$ only. This kind of rule only works for uniform distribution.<h4 id=independencies-in-context-specific-cpds>Independencies in Context-specific CPDs<a hidden class=anchor aria-hidden=true href=#independencies-in-context-specific-cpds>#</a></h4><p>If $\mathbf{c}$ be a context associated with a branch in the tree-CPD for $X$, then $X$ is independent of the remaining parents, $\text{Pa}_X\backslash\text{Scope}(\mathbf{c})$, given $\mathbf{c}$. Moreover, there might exist CSI statements conditioned on contexts which are not induced by complete branches.</p><p><strong>Example 8</strong>: Consider the tree-CPD given in <a href=#fig11>Figure 11</a>, as mentioned above, we have that
\begin{equation}
(J\perp_c L\hspace{0.1cm}\vert\hspace{0.1cm}s^1),
\end{equation}
where $s^1$ is not the full assignment associated with a branch.<br>Also, consider the tree-CPD given in <a href=#fig12>Figure 12(b)</a>, we have that
\begin{align}
&(J\perp_c L_2\hspace{0.1cm}\vert\hspace{0.1cm}c^1), \\ &(J\perp_c L_1\hspace{0.1cm}\vert\hspace{0.1cm}c^2),
\end{align}
where neither $c^1$ nor $c^2$ is the full assignment associated with a branch.</p><h5 id=reduced-rule>Reduced Rule<a hidden class=anchor aria-hidden=true href=#reduced-rule>#</a></h5><p>Let $\rho=(\mathbf{c}&rsquo;;p)$ be a rule and $\mathbf{c}$ be a context. If $\mathbf{c}&rsquo;$ is compatible with $\mathbf{c}$, we say that $\rho\sim\mathbf{c}$.</p><p>In this case, let $\mathbf{c}&rsquo;&rsquo;$ be the assignment in $c&rsquo;$ to the variables in $\text{Scope}(\mathbf{c}&rsquo;)\backslash\text{Scope}(\mathbf{c})$. We then define the <strong>reduced rule</strong> $\rho[\mathbf{c}]=(\mathbf{c}&rsquo;&rsquo;;p)$. If $\mathcal{R}$ be a set of rules, we define the <strong>reduced rule set</strong>
\begin{equation}
\mathcal{R}[\mathbf{c}]=\{\rho[\mathbf{c}]:\rho\in\mathcal{R},\rho\sim\mathbf{c}\}
\end{equation}</p><p><strong>Example 9</strong>: Consider the rule set $\mathcal{R}$ given in <a href=#eg7>Example 7</a>, we have that the reduced set corresponding to context $a^1$ is
\begin{equation}
\mathcal{R}[a^1]=\left\{\begin{array}{l}\rho_1&rsquo;:(b^1,x^0;0.1), \\ \rho_2:(b^1,x^1;0.9), \\ \rho_5:(b^0,c^0,x^0;0.3), \\ \rho_6:(b^0,c^0,x^1;0.7), \\ \rho_7:(b^0,c^1,x^0;0.4), \\ \rho_8&rsquo;:(b^0,c^1,x^1;0.6),\end{array}\right\}
\end{equation}
which is obtained by selecting rules compatible with $a^1$, i.e. $\{\rho_1,\rho_2,\rho_5,\rho_6,\rho_7,\rho_8\}$, then canceling out $a^1$ from all the rules where it appeared.</p><p><strong>Proposition 20</strong>: Let $\mathcal{R}$ be the rules in the rule-based CPD for a variable $X$, and let $\mathcal{R}_\mathbf{c}$ be the rules in $\mathcal{R}$ compatible with $\mathbf{c}$. Let $\mathbf{Y}\subset\text{Pa}_X$ be a subset such that $\mathbf{Y}\cap\text{Scope}(\mathbf{c})=\emptyset$. If for all $\rho\in\mathcal{R}[\mathbf{c}]$, we have that $\mathbf{Y}\cap\text{Scope}(\rho)=\emptyset$, then
\begin{equation}
(X\perp_c\mathbf{Y}\hspace{0.1cm}\vert\hspace{0.1cm}\text{Pa}_X\backslash\mathbf{Y},\mathbf{c})
\end{equation}</p><h5 id=spurious-edge>Spurious Edge<a hidden class=anchor aria-hidden=true href=#spurious-edge>#</a></h5><p>Let $P(X\vert\text{Pa}_X)$ be a CPD, $Y\in\text{Pa}_X$ be a set and let $\mathbf{c}$ be a context. The edge $Y\rightarrow X$ is said to be <strong>spurious</strong> in the context $\mathbf{c}$ if $P(X\vert\text{Pa}_X)$ satisfies $(X\perp_c Y\hspace{0.1cm}\vert\hspace{0.1cm}\text{Pa}_X\backslash\{Y\},\mathbf{c})$, where $\mathbf{c}&rsquo;$ is the restriction of $\mathbf{c}$ to variables in $\text{Pa}_X$.</p><p>Hence, by examining the reduced rule set, we can specify whether an edge is spurious, i.e. if $\mathcal{R}$ be the rule-based CPD for $P(X\vert\text{Pa}_X)$, then $Y\rightarrow X$ is spurious in context $\mathbf{c}$ if $Y$ does not appear in $\mathcal{R}[\mathbf{c}]$.</p><p><strong>Theorem 21</strong>: <em>Let $\mathcal{G}$ be a network structure, $P$ be a distribution such that $P\models\mathcal{I}_\ell(\mathcal{G})$, $\mathbf{c}$ be a context, and $\mathbf{X},\mathbf{Y},\mathbf{Z}$ be sets of variables. If $\mathbf{X}$ is <strong>CSI-separated</strong> from $\mathbf{Y}$ given $\mathbf{Z}$ in the context $\mathbf{c}$<sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup>, then we have that $P\models(\mathbf{X}\perp_c\mathbf{Y}\hspace{0.1cm}\vert\hspace{0.1cm}\mathbf{Z},\mathbf{c})$.</em></p><h3 id=independence-of-causal-influence>Independence of Causal Influence<a hidden class=anchor aria-hidden=true href=#independence-of-causal-influence>#</a></h3><h4 id=noisy-or-model>Noisy-Or Model<a hidden class=anchor aria-hidden=true href=#noisy-or-model>#</a></h4><p>Let $Y$ be a binary-valued r.v with $k$ binary-valued parents $X_1,\ldots,X_k$. The CPD $P(Y\vert X_1,\ldots,X_k)$ is a <strong>noisy-or</strong> if there are $k+1$ noise parameters $\lambda_0,\lambda_1,\ldots,\lambda_k$ such that
\begin{align}
P(y^0\vert X_1,\ldots,X_k)&=(1-\lambda_0)\prod_{i:X_i=x_i^1}(1-\lambda_i)\label{eq:nom.1} \\ P(y^1\vert X_1,\ldots,X_k)&=1-(1-\lambda_0)\prod_{i:X_i=x_i^1}(1-\lambda_i)
\end{align}
If we interpret $x_i^0$ as $0$ and $x_i^1$ as $1$, \eqref{eq:nom.1} can be rewritten as
\begin{equation}
P(y^0\vert X_1,\ldots,X_k)=(1-\lambda_0)\prod_{i=1}^{k}(1-\lambda_i)^{x_i}
\end{equation}</p><h4 id=glm>Generalized Linear Models<a hidden class=anchor aria-hidden=true href=#glm>#</a></h4><h5 id=binary-valued-variables>Binary-valued Variables<a hidden class=anchor aria-hidden=true href=#binary-valued-variables>#</a></h5><h5 id=multivalued-variables>Multivalued Variables<a hidden class=anchor aria-hidden=true href=#multivalued-variables>#</a></h5><h3 id=continuous-variables>Continuous Variables<a hidden class=anchor aria-hidden=true href=#continuous-variables>#</a></h3><h3 id=cbn>Conditional Bayesian Networks<a hidden class=anchor aria-hidden=true href=#cbn>#</a></h3><p>A <strong>conditional Bayesian network</strong> $\mathcal{B}$ over $\mathbf{Y}$ given $\mathbf{X}$ is defined as a DAG $\mathcal{G}$ whose nodes are $\mathbf{X}\cup\mathbf{Y}\cup\mathbf{Z}$ where $\mathbf{X},\mathbf{Y},\mathbf{Z}$ are disjoint. The variables in $\mathbf{X}$ are called <strong>inputs</strong>, the ones in $\mathbf{Y}$ are referred as <strong>outputs</strong> and the others in $\mathbf{Z}$ are known as <strong>encapsulated</strong>.</p><p>The variables in $\mathbf{X}$ have no parents in $\mathcal{G}$, while the variables in $\mathbf{Y}\cup\mathbf{Z}$ are associated with a CPD. The network defines a CPD using chain rule
\begin{equation}
P_\mathcal{B}(\mathbf{Y},\mathbf{Z}\vert\mathbf{X})=\prod_{T\in\mathbf{Y}\cup\mathbf{Z}}P(T\vert\text{Pa}_T)
\end{equation}
The distribution $P_\mathcal{B}(\mathbf{Y}\vert\mathbf{X})$ is defined as the marginal of $P_\mathcal{B}(\mathbf{Y},\mathbf{Z}\vert\mathbf{X})$
\begin{equation}
P_\mathcal{B}(\mathbf{Y}\vert\mathbf{X})=\sum_\mathbf{Z}P_\mathcal{B}(\mathbf{Y},\mathbf{Z}\vert\mathbf{X})
\end{equation}
The conditional Bayesian network is the directed version of <a href=#crf>CRF</a> mentioned above.</p><h4 id=encapsulated-cpd>Encapsulated CPD<a hidden class=anchor aria-hidden=true href=#encapsulated-cpd>#</a></h4><p>Let $Y$ be a r.v with $k$ parents $X_1,\ldots,X_k$. The CPD $P(Y\vert X_1,\ldots,X_k)$ is an <strong>encapsulated CPD</strong> if it is represented using a conditional Bayesian network over $Y$ given $X_1,\ldots,X_k$.</p><h2 id=template-based-representations>Template-based Representations<a hidden class=anchor aria-hidden=true href=#template-based-representations>#</a></h2><h3 id=temporal-models>Temporal Models<a hidden class=anchor aria-hidden=true href=#temporal-models>#</a></h3><p>In a <strong>temporal model</strong>, for each $X_i\in\mathcal{X}$, we let $X_i^{(t)}$ denote its instantiation at time $t$. The variables $X_i$ are referred as <strong>template variables</strong>.</p><p>Consider a distribution over trajectories sampled over time $t=0,1,\ldots,T$ - $P(\mathcal{X}^{(0)},\mathcal{X}^{(1)},\ldots,\mathcal{X}^{(T)})$, or $P(\mathcal{X}^{(0:T)})$ where $\mathcal{X}^{(t)}=\{X_i^{(t)}\}$. Using the chain rule for probabilities, we have that
\begin{equation}
P(\mathcal{X}^{(0:T)})=P(\mathcal{X}^{(0)},\mathcal{X}^{(1)},\ldots,\mathcal{X}^{(T)})=P(\mathcal{X}^{(0)})\prod_{t=0}^{T-1}P(\mathcal{X}^{(t+1)}\vert \mathcal{X}^{(0:t)}),\label{eq:tm.1}
\end{equation}
where $\mathcal{X}^{(t_1:t_2)}\doteq\{\mathcal{X}^{(t_1)},\mathcal{X}^{(t_1+1)},\ldots,\mathcal{X}^{(t_2-1)},\mathcal{X}^{(t_2)}\}$ for $t_1&lt;t_2$. In other words, the distribution over trajectories is the product of conditional distribution, over the variables in each time step $t$ given the preceding one.</p><h4 id=markovian-system>Markovian System<a hidden class=anchor aria-hidden=true href=#markovian-system>#</a></h4><p>A dynamic system over the template variables $\mathcal{X}$ is referred as <strong>Markovian</strong> if it satisfies the <strong>Markov assumption</strong>, in the sense that
\begin{equation}
(\mathcal{X}^{(t+1)}\perp\mathcal{X}^{(0:t-1)}\vert\mathcal{X}^{(t)})
\end{equation}
In other words, in such systems, we have a more compact form of \eqref{eq:tm.1}, which is
\begin{equation}
P(\mathcal{X}^{(0)},\mathcal{X}^{(1)},\ldots,\mathcal{X}^{(T)})=P(\mathcal{X}^{(0)})\prod_{t=0}^{T-1}P(\mathcal{X}^{(t+1)}\vert\mathcal{X}^{(t)})
\end{equation}
A Markovian dynamic system is said to be <span id=stationary><strong>stationary</strong></span> (or <strong>time invariant</strong>, or <strong>homogeneous</strong>) if $P(\mathcal{X}^{(t+1)}\vert\mathcal{X}^{(t)})$ is the same for all $t$. In this case, we can represent the process using a <strong>transition model</strong> $P(\mathcal{X}&rsquo;\vert\mathcal{X})$, so that for any $t\geq0$, we have
\begin{equation}
P(\mathcal{X}^{(t+1)}=\xi&rsquo;\vert\mathcal{X}^{(t)}=\xi)=P(\mathcal{X}&rsquo;=\xi&rsquo;\vert\mathcal{X}=\xi)
\end{equation}</p><h4 id=dbn>Dynamic Bayesian Networks<a hidden class=anchor aria-hidden=true href=#dbn>#</a></h4><p>A <strong>2-time-slice Bayesian network</strong> (<strong>2-TBN</strong>) for a process over $\mathcal{X}$ is a conditional Bayesian network over $\mathcal{X}&rsquo;$ given $\mathcal{X}_I$, where $\mathcal{X}_I\subset\mathcal{X}$ is a set of interface variables.</p><p>Hence, as mentioned <a href=#cbn>above</a>, we have</p><ul id=number-list><li>Only the variables $\mathcal{X}'$ are associated with CPDs (i.e. having parents).</li><li>The interface variables $\mathcal{X}_I$ are variables whose values at time $t$ have a direct effect on the variables at time $t+1$. Thus, only the variables in $\mathcal{X}_I$ can be parents of variables in $\mathcal{X}'$.</li><li>The 2-TBN represents the distribution
\begin{equation}
P(\mathcal{X}'\vert\mathcal{X})=P(\mathcal{X}'\vert\mathcal{X}_I)=\prod_{i=1}^{n}P(X_i'\vert\text{Pa}_{X_i'})
\end{equation}</li><li>For each template variable $X_i$, the CPD $P(X_i'\vert\text{Pa}_{X_i'})$ is a <b>template factor</b>, i.e. it will be instantiated multiple times within the model, for multiple variables $X_i^{(t)}$ (and their parents).</li></ul><p>In a 2-TBN, edges that go between time slices are called <strong>inter-time-slice</strong>, while the ones connecting variables in the same slices are known as <strong>intra-time-slice</strong>. Additionally, inter-time-slice edges having the form of $X\rightarrow X&rsquo;$ are referred as <strong>persistence</strong>. The variable $X$ for which we have an edge $X\rightarrow X&rsquo;$ is also called <strong>persistent variable</strong>.</p><figure id=fig13><img src=/images/pgm-representation/2-tbn.png alt=2-TBN style=display:block;margin-left:auto;margin-right:auto;height:80%;width:80%><figcaption><b>Figure 13</b>: (based on figure from the <a href=#pgm-book>PGM book</a>) <b>A 2-TBN</b>.</figcaption></figure><p>Based on the <a href=#stationary>stationary property</a>, a 2-TBN defines the probability distribution $P(\mathcal{X}^{(t+1)}\vert\mathcal{X}^{(t)})$ for any $t$. Given a distribution over the initial states, we can unroll the network over sequences of any length, to define a Bayesian network that induces a distribution over trajectories of that length.</p><p>A <strong>dynamic Bayesian network</strong> (or <strong>DBN</strong>) is a tuple $(\mathcal{B}_0,\mathcal{B}_\rightarrow)$, where</p><ul id=number-list><li>$\mathcal{B}_0$ is a Bayesian network over $\mathcal{X}^{(0)}$ representing the initial distribution over states;</li><li>$\mathcal{B}_\rightarrow$ is a 2-TBN for the process.</li></ul><p>For any time span $T\geq0$, the distribution over $\mathcal{X}^{(0:T)}$ is defined as an <strong>unrolled Bayesian network</strong>, where, for any $i=1,\ldots,n$:</p><ul id=number-list><li>The structure and CPDs of $X_i^{(0)}$ are the same as those for $X_i$ in $\mathcal{B}_0$.</li><li>The structure and CPDs of $X_i^{(t)}$ for $t>0$ are the same as those for $X_i'$ in $\mathcal{B}_\rightarrow$.</li></ul><p>Or in other words, $\mathcal{B}_0$ is the initial state, while $\mathcal{B}_\rightarrow$ represents the transition model.</p><p><strong>Remark</strong>: Hence, we can view a DBN as a compact representation from which we can generate an infinite set of Bayesian networks (one for every $T>0$).</p><figure><img src=/images/pgm-representation/dbn.png alt=DBN><figcaption><b>Figure 14</b>: (based on figure from the <a href=#pgm-book>PGM book</a>) (a) $\mathcal{B}_\rightarrow$; (b) $\mathcal{B}_0$; (c) 3-step unrolled DBN.</figcaption></figure><p>In DBNs, we can partition the variables $\mathcal{X}$ into disjoint subsets $\mathbf{X}$ and $\mathbf{O}$ such that variables in $\mathbf{X}$ are always hidden, while ones in $\mathbf{O}$ are always observed. This introduces us to an another way of representing temporal process, which is the <strong>state-observation model</strong>.</p><h4 id=state-observation-models>State-Observation Models<a hidden class=anchor aria-hidden=true href=#state-observation-models>#</a></h4><p>A <strong>state-observation model</strong> utilizes two independent assumptions:</p><ul id=roman-list><li>Markov assumption:
\begin{equation}
(\mathbf{X}^{(t+1)}\perp\mathbf{X}^{(0:t-1)}\vert\mathbf{X}^{(t)})
\end{equation}</li><li>Observations depend on current state only:
\begin{equation}
(\mathbf{O}^{(t)}\perp\mathbf{X}^{(0:t-1)},\mathbf{X}^{(t+1:\infty)}\vert\mathbf{X}^{(t)})
\end{equation}</li></ul><p>Therefore, we can view our probabilistic model containing two components: the <strong>transition model</strong>, $P(\mathbf{X}&rsquo;\vert\mathbf{X})$, and the <strong>observation model</strong>, $P(\mathbf{O}\vert\mathbf{X})$. This corresponds to a 2-TBN structure where the observation variables $\mathbf{O}&rsquo;$ are all leaves, and have parents only in $\mathbf{X}&rsquo;$. For instance, as considering <a href=#fig13>Figure 13</a>, $\textit{Observation}&rsquo;$ are acting as $\mathbf{O}&rsquo;$.</p><h5 id=hmm>Hidden Markov Models<a hidden class=anchor aria-hidden=true href=#hmm>#</a></h5><p>A <strong>Hidden Markov model</strong>, or <strong>HMM</strong>, is the simplest example of a state-observation model, and also a special case of a simple DBN, which has a sparse transition model $P(S&rsquo;\vert S)$. Thus, HMMs are often represented using a different graphical notation which visualizes this sparse transition model.</p><p>Specifically, in the is representation, the transition model is encoded using a directed graph, where</p><ul id=number-list><li>Nodes represent the different states of the system, i.e. the values in $\text{Val}(S)$.</li><li>Each directed edge $s\rightarrow s'$ represents a possible transitioning from $s$ to $s'$, i.e. $P(s'\vert s)>0$.</li></ul><p><strong>Example 10</strong>: Consider an HMM with state variable $S$ that takes 4 possible values $s_1,s_2,s_3,s_4$ and with a transition model</p><table><thead><tr><th></th><th>$s_1$</th><th>$s_2$</th><th>$s_3$</th><th>$s_4$</th></tr></thead><tbody><tr><td>$s_1$</td><td>0.3</td><td>0.7</td><td>0</td><td>0</td></tr><tr><td>$s_2$</td><td>0</td><td>0</td><td>0.4</td><td>0.6</td></tr><tr><td>$s_3$</td><td>0.5</td><td>0</td><td>0</td><td>0.5</td></tr><tr><td>$s_4$</td><td>0</td><td>0.9</td><td>0</td><td>0.1</td></tr></tbody></table><p>where the rows correspond to states $s$, while the columns to next states $s&rsquo;$. On other words, the $i$-th row represents the CPD $P(s&rsquo;\vert s=s_i)$, and thus must sum to $1$. Its transition graph is shown below</p><figure><img src=/images/pgm-representation/hmm.png alt=HMM height=50% width=50%></figure><h5 id=linear-dynamical-systems>Linear Dynamical Systems<a hidden class=anchor aria-hidden=true href=#linear-dynamical-systems>#</a></h5><p>A <strong>linear dynamical system</strong>, or <strong>Kalman filter</strong> represents a system of one or more real-valued variable that evolve linearly over time, with some Gaussian noise.</p><p>Such systems can be viewed as DBNs where the variables are all continuous and all of the dependencies are linear Gaussian.</p><p>They are traditionally represented as a state-observation model, where the state and the observation are both vector-valued r.v.s; and where the transition model and observation model are both encoded using matrices. In more specific, the model is generally defined via the set of equations
\begin{align}
P(\mathbf{X}^{(t)}\vert\mathbf{X}^{(t-1)})&=\mathcal{N}(A\mathbf{X}^{(t-1)};Q), \\ P(O^{(t)}\vert\mathbf{X}^{(t)})&=\mathcal{N}(H\mathbf{X}^{(t)};R),
\end{align}
where</p><ul><li>$\mathbf{X}\in\mathbb{R}^n$ is the vector of state variables;</li><li>$O\in\mathbb{R}^m$ is the vector of observation variables;</li><li>$A\in\mathbb{R}^{n\times n}$ (precisely $A\in[0,1]^{n\times n}$) is the <strong>transition matrix</strong>, defines the linear transition model;</li><li>$H\in\mathbb{R}^{n\times m}$ (also $H\in[0,1]^{n\times m}$ to be exact) defines the linear observation model;</li><li>$R\in\mathbb{R}^{m\times m}$ defines the Gaussian noise associated with the observations.</li></ul><h6 id=extended-kalman-filters>Extended Kalman Filters<a hidden class=anchor aria-hidden=true href=#extended-kalman-filters>#</a></h6><p>A nonlinear variant of the linear dynamical system, known as <strong>extended Kalman filter</strong>, is a system where the state transition and observation model are nonlinear functions, i.e.
\begin{align}
P(\mathbf{X}^{(t)}\vert\mathbf{X}^{(t-1)})&=f(\mathbf{X}^{(t-1)},\mathbf{U}^{(t-1)}) \\ P(O^{(t)}\vert\mathbf{X}^{(t)})&=g(\mathbf{X}^{(t)},\mathbf{W}^{(t)}),
\end{align}
where</p><ul><li>$f,g$ are nonlinear functions;</li><li>$\mathbf{U}^{(t)},\mathbf{W}^{(t)}$ are Gaussian r.v.s.</li></ul><h3 id=template-variables--template-factors>Template Variables & Template Factors<a hidden class=anchor aria-hidden=true href=#template-variables--template-factors>#</a></h3><p>As viewing the world as a set of objects, each of which can be divided into a set of mutually exclusive and exhaustive classes $\mathcal{Q}=Q_1,\ldots,Q_k$.</p><p>An <strong>attribute</strong> $A$ is a function $A(U_1,\ldots,U_k)$ whose range is some set $\text{Val}(A)$ and where each argument $U_i$ is known as a <strong>logical variable</strong> associated with a particular class $Q[U_i]\doteq Q_i$. The tuple $(U_1,\ldots,U_k)$ is called the <strong>argument signature</strong> of the attribute $A$, denoted $\alpha(A)$
\begin{equation}
\alpha(A)\doteq(U_1,\ldots,U_k)
\end{equation}
<strong>Example 11</strong>: The argument signature of $\textit{Grade}$ attribute would have two logical variables $S,C$ where $S$ is of class $\textit{Student}$, and where $C$ is of class $\textit{Course}$.</p><p>Let $\mathcal{Q}$ be a set of classes, and $\aleph$ be a set of attributes over $\mathcal{Q}$. An <strong>object skeleton</strong> $\kappa$ specifies a fixed, finite set of objects $\mathcal{O}^\kappa[Q]$ for every $Q\in\mathcal{Q}$. We also define
\begin{equation}
\mathcal{O}^\kappa[\alpha(A)]=\mathcal{O}^\kappa[U_1,\ldots,U_k]\doteq\mathcal{O}^\kappa[Q[U_1]]\times\ldots\times\mathcal{O}^\kappa[Q[U_k]]
\end{equation}
By default, we let $\Gamma_\kappa[A]=\mathcal{O}^\kappa[\alpha(A)]$ to be the set of possible assignments to the logical variables in the argument signature of $A$. However, an object skeleton might also specify a subset of legal assignments, i.e. $\Gamma_\kappa[A]\subset\mathcal{O}^\kappa[\alpha(A)]$.</p><p>For an object skeleton $\kappa$ over $\mathcal{Q},\aleph$. We define sets of <span id=ground-rv><strong>ground random variables</strong></span>
\begin{align}
\mathcal{X}_\kappa[A]&\doteq\{A(\gamma):\gamma\in\Gamma_\kappa[A]\} \\ \mathcal{X}_\kappa[\aleph]&\doteq\bigcup_{A\in\aleph}\mathcal{X}_\kappa[A]
\end{align}
Here, we are abusing notation, identifying an argument $\gamma=(U_1\mapsto u_1,\ldots,U_k\mapsto u_k)$ with the tuple $(u_1,\ldots,u_k)$.</p><p>A <strong>template factor</strong> $\xi$ is a function defined over a tuple of template attributes $A_1,\ldots,A_l$ where each $A_i$ has a range $\text{Val}(A_i)$. It defines a mapping $\text{Val}(A_1)\times\ldots\times\text{Val}(A_l)\mapsto\mathbb{R}$. Given r.v.s $X_1,\ldots,X_l$ such that $\text{Val}(X_i)=\text{Val}(A_i)$ for all $i=1,\ldots,j$, we define $\xi(X_1,\ldots,X_l)$ to be the instantiated factor from $\mathbf{X}$ to $\mathbb{R}$.</p><h3 id=directed-probabilistic-models-for-object-relational>Directed Probabilistic Models for Object-Relational<a hidden class=anchor aria-hidden=true href=#directed-probabilistic-models-for-object-relational>#</a></h3><h4 id=plate-models>Plate Models<a hidden class=anchor aria-hidden=true href=#plate-models>#</a></h4><p>A <strong>plate model</strong> $\mathcal{M}_\text{Plate}$ defines for each template attribute $A\in\aleph$ with argument signature $U_1,\ldots,U_k$:</p><ul id=number-list><li>a set of <b>template parents</b>
\begin{equation}
\text{Pa}_A=\{B_1(\mathbf{U}_1),\ldots,B_l(\mathbf{U}_l)\},
\end{equation}
such that for each $B_i(\mathbf{U}_i)$, we have that $\mathbf{U}_i\subset\{U_1,\ldots,U_k\}$. The variables $\mathbf{U}_i$ are the <b>argument signature</b> of the parent $B_i$.</li><li>a template CPD $P(A\vert\text{Pa}_A)$.</li></ul><figure id=fig15><img src=/images/pgm-representation/plate-models.png alt="Plate models" height=80% width=80%><figcaption><b>Figure 15</b>: (based on figure from the <a href=#pgm-book>PGM book</a>) <b>Plate models and induced ground Bayesian networks</b>: (a) Single plate: for any student $s$, $P(I(s))$ and $P(G(s)\vert I(s))$ are the same; (b) Nested plates: for any (student, course) pair $(s,c)$, $\textit{Grade}(s,c)$ depends on $\textit{Difficulty}(c)$ and on $\textit{Intelligence}(s,c)$; (c) Intersecting plates: for any (student, course) pair $(s,c)$, $\text{Grade}(s,c)$ depends on $\textit{Difficulty}(c)$ and on $\textit{Intelligence}(s)$.</figcaption></figure><h5 id=ground-bayesian-networks-for-plate-models>Ground Bayesian Networks for Plate Models<a hidden class=anchor aria-hidden=true href=#ground-bayesian-networks-for-plate-models>#</a></h5><p>A plate model $\mathcal{M}_\text{Plate}$ and object skeleton $\kappa$ define a <strong>ground Bayesian network</strong> $\mathcal{B}_\kappa^{\mathcal{M}_\text{Plate}}$ as follows. Let $A(U_1,\ldots,U_k)$ be any template attribute in $\aleph$. Then, for any $\gamma=(U_1\mapsto u_1,\ldots,U_k\mapsto u_k)\in\Gamma_\kappa[A]$, we have a variable $A(\gamma)$ in the ground network, with parents $B(\gamma)$ for all $B\in\text{Pa}_A$, and the instantiated CPD $P(A(\gamma)\vert\text{Pa}_A(\gamma))$.</p><p><strong>Example 12</strong>: Consider the <a href=#fig15>Figure 15(c)</a>, without loss of generality, we have that:</p><ul id=number-list><li>The plate model $\mathcal{M}_\text{Plate}$ is defined over a set $\aleph=\{\textit{Grade},\textit{Difficulty},\textit{Intelligence}\}$ of template attributes, for each of which:<ul id=roman-list><li>$\alpha(\textit{Grade})=(S,C)$ and $\text{Pa}_\textit{Grade}=\{\textit{Difficulty}(C),\textit{Intelligence}(S)\}$;</li><li>$\alpha(\textit{Difficulty})=(C)$ and $\text{Pa}_\textit{Difficulty}=\emptyset$;</li><li>$\alpha(\textit{Intelligence})=(S)$ and $\text{Pa}_\textit{Intelligence}=\emptyset$,</li></ul>where $S$ is logical variable of class $\textit{Student}$, and $C$ is a logical variable of class $\textit{Course}$.</li><li>Let $(S\mapsto s,C\mapsto c)$ be some assignment to some logical variables $S,C$ where $S$ is of class $\textit{Student}$, $C$ is of class $\textit{Course}$. We then have instantiated CPDs:
\begin{align}
P(G(s,c)\vert\text{Pa}_G(s,c))&=P(G(s,c)\vert D(s,c),I(s,c))=P(G(s,c)\vert D(c),I(s)), \\ P(D(c)\vert\text{Pa}_D(c))&=P(D(c)), \\ P(I(s)\vert\text{Pa}_I(s))&=P(I(s))
		\end{align}
</li></ul><h4 id=probabilistic-relational-models>Probabilistic Relational Models<a hidden class=anchor aria-hidden=true href=#probabilistic-relational-models>#</a></h4><p>For a template attribute $A$, we define a <strong>contingent dependency model</strong> as a tuple containing:</p><ul id=number-list><li>A <b>parent argument signature</b> $\alpha(\text{Pa}_A)$, which is a tuple of typed logical variables $U_i$ such that $\alpha(\text{Pa}_A)\supset\alpha(A)$.</li><li>A <b>guard</b> $\Gamma$, which is a binary-valued formula defined in terms of a set of template attributes $\text{Pa}_A^\Gamma$ over the argument signature $\alpha(\text{Pa}_A)$.</li><li>A set of template parents
\begin{equation}
\text{Pa}_A=\{B_1(\mathbf{U}_1),\ldots,B_l(\mathbf{U}_l)\},
\end{equation}
such that for each $B_i(\mathbf{U}_i)$, we have that $\mathbf{U}_i\subset\alpha(\text{Pa}_A)$.</li></ul><br><p>A <strong>probabilistic relational model</strong> (or <strong>PRM</strong>) $\mathcal{M}_\text{PRM}$ defines, for each $A\in\aleph$ a contingent dependency model and a template CPD.</p><h5 id=ground-bayesian-networks-for-prms>Ground Bayesian Networks for PRMs<a hidden class=anchor aria-hidden=true href=#ground-bayesian-networks-for-prms>#</a></h5><p>A PRM $\mathcal{M}_\text{PRM}$ and object skeleton $\kappa$ define a <strong>ground Bayesian network</strong> $\mathcal{B}_\kappa^{\mathcal{M}_\text{PRM}}$ as follows. Let $A(U_1,\ldots,U_k)$ be any template attribute in $\aleph$. Then, for any assignment $\gamma\in\Gamma_\kappa[A]$, we have a variable $A(\gamma)$ in the ground network. This variable has, for any $B\in\text{Pa}_A^\Gamma\cup\text{Pa}_A$ and any assignment $\gamma&rsquo;$ to $\alpha(\text{Pa}_A)\backslash\alpha(A)$, the parent that is the instantiated variable $B(\gamma,\gamma&rsquo;)$.</p><h3 id=undirected-representation>Undirected Representation<a hidden class=anchor aria-hidden=true href=#undirected-representation>#</a></h3><p>A <strong>relational Markov network</strong> $\mathcal{M}_\text{RMN}$ is defined in terms of a set $\Lambda$ of template features, where each $\lambda\in\Lambda$ contains:</p><ul id=number-list><li>a real-valued template feature $f_\lambda$ whose arguments are $\aleph(\lambda)=\{A_1(\mathbf{U}_1),\ldots,A_l(\mathbf{U}_l)\}$;</li><li>a weight $w_\lambda\in\mathbb{R}$.</li></ul><h4 id=ground-gibbs-distribution>Ground Gibbs Distribution<a hidden class=anchor aria-hidden=true href=#ground-gibbs-distribution>#</a></h4><p>Given an RMN $\mathcal{M}_\text{RMN}$, an object skeleton $\kappa$, we can define a <strong>ground Gibbs distribution</strong> $P_\kappa^{\mathcal{M}_\text{RMN}}$ as:</p><ul id=roman-list><li>The variables in the network are $\mathcal{X}_\kappa[\aleph]$ (as defined <a href=#ground-rv>above</a>);</li><li>$P_\kappa^{\mathcal{M}_\text{RMN}}$ contains a term
\begin{equation}
\exp\big(w_\lambda f_\lambda(\gamma)\big),
\end{equation}
for each feature template $\lambda\in\Lambda$ and each assignment $\gamma\in\Gamma_\kappa[\alpha(\lambda)]$.</li></ul><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2><p>[1] <span id=pgm-book>Daphne Koller, Nir Friedman. <a href=https://mitpress.mit.edu/9780262013192/probabilistic-graphical-models/>Probabilistic Graphical Models</a>. The MIT Press.</span></p><p>[2] Michael I. Jordan. <a href=http://people.eecs.berkeley.edu/~jordan/prelims/>An Introduction to Probabilistic Graphical Models</a>. In preparation.</p><p>[3] Eric P. Xing. <a href=https://www.cs.cmu.edu/~epxing/Class/10708-20/>10-708: Probabilistic Graphical Model</a>. CMU Spring 2020.</p><p>[4] Stefano Ermon. <a href=https://cs.stanford.edu/~ermon/cs228/index.html>CS228: Probabilistic Graphical Model</a>. Stanford Winter 2017-2018.</p><h2 id=footnotes>Footnotes<a hidden class=anchor aria-hidden=true href=#footnotes>#</a></h2><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>Note that $X_i\rightarrow X_j\equiv X_j\leftarrow X_i$ but $X_i\rightarrow X_j\not\equiv X_i\leftarrow X_j$, while $X_i-X_j\equiv X_j-X_i$.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>Note that the inverse is not true.&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p>This can be specified by doing the procedure</p><blockquote><p>Let $\mathbf{Z}^+\leftarrow\mathbf{Z}$<br>While $\exists X_i$ such that $X_i\in\mathbf{D}$ and $\text{Pa}_{X_i}\subset\mathbf{Z}^+$<br>$\hspace{1cm}\mathbf{Z}^+\leftarrow\mathbf{Z}\cup\{X_i\}$<br>return $\text{d-sep}(\mathbf{X};\mathbf{Y}\vert\mathbf{Z})$</p></blockquote>&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></li><li id=fn:4>&#160;<a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></li></ol></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://trunghng.github.io/tags/machine-learning/>machine-learning</a></li><li><a href=https://trunghng.github.io/tags/probabilistic-graphical-model/>probabilistic-graphical-model</a></li></ul><nav class=paginav><a class=prev href=https://trunghng.github.io/posts/reinforcement-learning/maxent-sql-sac/><span class=title>« Prev</span><br><span>Maximum Entropy Reinforcement Learning via Soft Q-learning & Soft Actor-Critic</span></a>
<a class=next href=https://trunghng.github.io/posts/reinforcement-learning/deterministic-policy-gradients/><span class=title>Next »</span><br><span>Deterministic Policy Gradients</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Probabilistic Graphical Models - Representation on twitter" href="https://twitter.com/intent/tweet/?text=Probabilistic%20Graphical%20Models%20-%20Representation&url=https%3a%2f%2ftrunghng.github.io%2fposts%2fmachine-learning%2fpgm-representation%2f&hashtags=machine-learning%2cprobabilistic-graphical-model"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Probabilistic Graphical Models - Representation on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2ftrunghng.github.io%2fposts%2fmachine-learning%2fpgm-representation%2f&title=Probabilistic%20Graphical%20Models%20-%20Representation&summary=Probabilistic%20Graphical%20Models%20-%20Representation&source=https%3a%2f%2ftrunghng.github.io%2fposts%2fmachine-learning%2fpgm-representation%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Probabilistic Graphical Models - Representation on reddit" href="https://reddit.com/submit?url=https%3a%2f%2ftrunghng.github.io%2fposts%2fmachine-learning%2fpgm-representation%2f&title=Probabilistic%20Graphical%20Models%20-%20Representation"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Probabilistic Graphical Models - Representation on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2ftrunghng.github.io%2fposts%2fmachine-learning%2fpgm-representation%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Probabilistic Graphical Models - Representation on whatsapp" href="https://api.whatsapp.com/send?text=Probabilistic%20Graphical%20Models%20-%20Representation%20-%20https%3a%2f%2ftrunghng.github.io%2fposts%2fmachine-learning%2fpgm-representation%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Probabilistic Graphical Models - Representation on telegram" href="https://telegram.me/share/url?text=Probabilistic%20Graphical%20Models%20-%20Representation&url=https%3a%2f%2ftrunghng.github.io%2fposts%2fmachine-learning%2fpgm-representation%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer><script src=https://utteranc.es/client.js repo=trunghng/trunghng.github.io issue-term=pathname theme=github-light crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2023 <a href=https://trunghng.github.io>Trung's Place</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>