<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Posts | Littleroot</title>
<script type=text/x-mathjax-config>
  MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": {availableFonts: []}
  });
</script><script type=text/javascript src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><meta name=keywords content><meta name=description content="Posts - Littleroot"><meta name=author content="Trung H. Nguyen"><link rel=canonical href=https://trunghng.github.io/posts/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.e9f4bcad0f9fc853201ee998afd06c07a01cb19320ff7cb62155b43ffdb33cea.css integrity="sha256-6fS8rQ+fyFMgHumYr9BsB6AcsZMg/3y2IVW0P/2zPOo=" rel="preload stylesheet" as=style><link rel=icon href=https://trunghng.github.io/images/favicon/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://trunghng.github.io/images/favicon/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://trunghng.github.io/images/favicon/favicon-32x32.png><link rel=apple-touch-icon href=https://trunghng.github.io/images/favicon/apple-touch-icon.png><link rel=mask-icon href=https://trunghng.github.io/images/favicon/android-chrome-512x512.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://trunghng.github.io/posts/index.xml><link rel=alternate hreflang=en href=https://trunghng.github.io/posts/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-GF0KK4E3F0"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-GF0KK4E3F0")</script><style>.post-content{text-align:justify;font-size:15px;font-family:"goudy bookletter 1911",sans-serif}.post-content h1,h2,h3,h4,h5,h6{text-align:left}.post-content a,.post-content a:link,.post-content a:active{box-shadow:none;color:#4682b4}.post-content a:hover{color:skyblue}.post-content a:visited{color:#00008b}.post-content ol,.post-content ul{margin-left:10px}.post-content li>ol,.post-content li>ul{margin-left:30px}.roman-list,.number-list,.alpha-list{counter-reset:section;margin-bottom:10px}.roman-list>li{list-style:none;position:relative}.number-list>li{list-style:none;position:relative}.alpha-list>li{list-style:none;position:relative}.roman-list>li:before{counter-increment:section;content:"(" counter(section,lower-roman)") ";position:absolute;left:-2em}.number-list>li:before{counter-increment:section;content:"(" counter(section,decimal)") ";position:absolute;left:-2em}.alpha-list>li:before{counter-increment:section;content:"(" counter(section,lower-alpha)") ";position:absolute;left:-2em}#non-style-list{margin-bottom:10px;margin-left:0}#non-style-list>li{position:relative}.toc{font-size:15px}.post-footer{font-size:15px}.post-content figure>img{display:block;margin-left:auto;margin-right:auto}.post-content figure>figcaption{all:revert;text-align:justify;font-size:12px;font-style:italic;width:70%;margin-left:15%}.post-content figure>figcaption>p{all:revert}.post-content h3{font-size:28px}.post-content h4{font-size:24px}.post-content h5{font-size:20px}.post-content h6{font-size:16px}</style><script async src="https://www.googletagmanager.com/gtag/js?id=G-GF0KK4E3F0"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-GF0KK4E3F0")}</script><meta property="og:title" content="Posts"><meta property="og:description" content="ExampleSite description"><meta property="og:type" content="website"><meta property="og:url" content="https://trunghng.github.io/posts/"><meta property="og:image" content="https://trunghng.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="og:site_name" content="Littleroot"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://trunghng.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Posts"><meta name=twitter:description content="ExampleSite description"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://trunghng.github.io/posts/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://trunghng.github.io/ accesskey=h title="Littleroot (Alt + H)"><img src=https://trunghng.github.io/images/others/littleroottown.png alt aria-label=logo height=27>Littleroot</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://trunghng.github.io/posts/ title=Posts><span class=active>Posts</span></a></li><li><a href=https://trunghng.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://trunghng.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://trunghng.github.io/about/ title=About><span>About</span></a></li><li><a href=https://trunghng.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><header class=page-header><h1>Posts
<a href=/posts/index.xml title=RSS aria-label=RSS><svg viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1></header><article class=post-entry><header class=entry-header><h2>Function Approximation</h2></header><div class=entry-content><p>All of the tabular methods we have been considering so far might scale well within a small state space. However, when dealing with Reinforcement Learning problems in continuous state space, an exact solution is nearly impossible to find. But instead, an approximated answer could be found.
...</p></div><footer class=entry-footer><span title='2022-02-11 15:26:00 +0700 +0700'>February 11, 2022</span>&nbsp;·&nbsp;21 min&nbsp;·&nbsp;Trung H. Nguyen</footer><a class=entry-link aria-label="post link to Function Approximation" href=https://trunghng.github.io/posts/reinforcement-learning/func-approx/></a></article><article class=post-entry><header class=entry-header><h2>Temporal-Difference Learning</h2></header><div class=entry-content><p>So far in this series, we have gone through the ideas of dynamic programming (DP) and Monte Carlo. What will happen if we combine these ideas together? Temporal-difference (TD) learning is our answer.
...</p></div><footer class=entry-footer><span title='2022-01-31 16:55:00 +0700 +0700'>January 31, 2022</span>&nbsp;·&nbsp;21 min&nbsp;·&nbsp;Trung H. Nguyen</footer><a class=entry-link aria-label="post link to Temporal-Difference Learning" href=https://trunghng.github.io/posts/reinforcement-learning/td-learning/></a></article><article class=post-entry><header class=entry-header><h2>Gaussian Distribution & Gaussian Network Models</h2></header><div class=entry-content><p>Notes on Gaussian distribution & Gaussian network models.
...</p></div><footer class=entry-footer><span title='2021-11-22 14:46:00 +0700 +0700'>November 22, 2021</span>&nbsp;·&nbsp;15 min&nbsp;·&nbsp;Trung H. Nguyen</footer><a class=entry-link aria-label="post link to Gaussian Distribution & Gaussian Network Models" href=https://trunghng.github.io/posts/probability-statistics/gaussian-dist-gaussian-bn/></a></article><article class=post-entry><header class=entry-header><h2>Power Series</h2></header><div class=entry-content><p>Recall that in the previous note, Infinite Series of Constants, we mentioned a type of series called power series a lot. In the content of this note, we will be diving deeper into details of its.
...</p></div><footer class=entry-footer><span title='2021-09-21 15:40:00 +0700 +0700'>September 21, 2021</span>&nbsp;·&nbsp;15 min&nbsp;·&nbsp;Trung H. Nguyen</footer><a class=entry-link aria-label="post link to Power Series" href=https://trunghng.github.io/posts/calculus/power-series/></a></article><article class=post-entry><header class=entry-header><h2>Infinite Series of Constants</h2></header><div class=entry-content><p>Notes on infinite series of constants.
...</p></div><footer class=entry-footer><span title='2021-09-06 11:20:00 +0700 +0700'>September 6, 2021</span>&nbsp;·&nbsp;20 min&nbsp;·&nbsp;Trung H. Nguyen</footer><a class=entry-link aria-label="post link to Infinite Series of Constants" href=https://trunghng.github.io/posts/calculus/infinite-series-of-constants/></a></article><article class=post-entry><header class=entry-header><h2>Monte Carlo Methods in Reinforcement Learning</h2></header><div class=entry-content><p>Recall that when using Dynamic Programming algorithms to solve RL problems, we made an assumption about the complete knowledge of the environment. With Monte Carlo methods, we only require experience - sample sequences of states, actions, and rewards from simulated or real interaction with an environment.
...</p></div><footer class=entry-footer><span title='2021-08-21 13:03:00 +0700 +0700'>August 21, 2021</span>&nbsp;·&nbsp;20 min&nbsp;·&nbsp;Trung H. Nguyen</footer><a class=entry-link aria-label="post link to Monte Carlo Methods in Reinforcement Learning" href=https://trunghng.github.io/posts/reinforcement-learning/monte-carlo-in-rl/></a></article><article class=post-entry><header class=entry-header><h2>Solving MDPs with Dynamic Programming</h2></header><div class=entry-content><p>In two previous notes, MDPs and Bellman equations and Optimal Policy Existence, we have known how MDPs, Bellman equations were defined and how they worked. In this note, we are going to find the solution for the MDP framework with Dynamic Programming.
...</p></div><footer class=entry-footer><span title='2021-07-25 15:30:00 +0700 +0700'>July 25, 2021</span>&nbsp;·&nbsp;9 min&nbsp;·&nbsp;Trung H. Nguyen</footer><a class=entry-link aria-label="post link to Solving MDPs with Dynamic Programming" href=https://trunghng.github.io/posts/reinforcement-learning/dp-in-mdp/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://trunghng.github.io/posts/page/4/>«&nbsp;Prev&nbsp;
</a><a class=next href=https://trunghng.github.io/posts/page/6/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2024 <a href=https://trunghng.github.io/>Littleroot</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>