<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>CMA Evolution Strategy | Trung's Place</title><meta name=keywords content="machine-learning,evolution-strategy,neuroevolution"><meta name=description content="
Notes on CMA - Evolution Strategy.
"><meta name=author content="Trung H. Nguyen"><link rel=canonical href=https://trunghng.github.io/posts/evolution-strategy/cma-es/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.bc1149f4a72aa4858d3a9f71462f75e5884ffe8073ea9d6d5761d5663d651e20.css integrity="sha256-vBFJ9KcqpIWNOp9xRi915YhP/oBz6p1tV2HVZj1lHiA=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://trunghng.github.io/images/favicon/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://trunghng.github.io/images/favicon/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://trunghng.github.io/images/favicon/favicon-32x32.png><link rel=apple-touch-icon href=https://trunghng.github.io/images/favicon/apple-touch-icon.png><link rel=mask-icon href=https://trunghng.github.io/images/favicon/android-chrome-512x512.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=text/x-mathjax-config>
  MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": {availableFonts: []}
  });
</script><script type=text/x-mathjax-config>
    MathJax.Hub.Config({
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
      "HTML-CSS": {availableFonts: []},
      TeX: {
        equationNumbers: { autoNumber: "AMS" },
      },
    });
  </script><script type=text/javascript src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><style>.post-content{text-align:justify;font-size:15px}.post-content h1,h2,h3,h4,h5,h6{text-align:left}.post-content a{text-decoration:none}.post-content ol,.post-content ul{margin-left:10px}.post-content li>ol,.post-content li>ul{margin-left:30px}#roman-list,#number-list{counter-reset:section}#roman-list,#number-list>li{list-style:none;position:relative}#roman-list>li:before{counter-increment:section;content:"(" counter(section,lower-roman)") ";position:absolute;left:-.75em}#number-list>li:before{counter-increment:section;content:"(" counter(section,decimal)") ";position:absolute;left:-2em}figcaption{font-size:14px}.toc{font-size:15px}.post-footer{font-size:15px}.post-content figure>figcaption{all:revert;font-size:12px;width:70%;text-align:center;margin-left:15%}.post-content figure>figcaption>p{all:revert}</style><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="CMA Evolution Strategy"><meta property="og:description" content="
Notes on CMA - Evolution Strategy.
"><meta property="og:type" content="article"><meta property="og:url" content="https://trunghng.github.io/posts/evolution-strategy/cma-es/"><meta property="og:image" content="https://trunghng.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-09-14T13:00:00+07:00"><meta property="article:modified_time" content="2022-09-14T13:00:00+07:00"><meta property="og:site_name" content="Trung's Place"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://trunghng.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="CMA Evolution Strategy"><meta name=twitter:description content="
Notes on CMA - Evolution Strategy.
"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://trunghng.github.io/posts/"},{"@type":"ListItem","position":3,"name":"CMA Evolution Strategy","item":"https://trunghng.github.io/posts/evolution-strategy/cma-es/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"CMA Evolution Strategy","name":"CMA Evolution Strategy","description":" Notes on CMA - Evolution Strategy.\n","keywords":["machine-learning","evolution-strategy","neuroevolution"],"articleBody":" Notes on CMA - Evolution Strategy.\nPreliminaries The condition number of a matrix $\\mathbf{A}$ is defined by \\begin{equation} \\kappa(\\mathbf{A})\\doteq\\Vert\\mathbf{A}\\Vert\\Vert\\mathbf{A}^{-1}\\Vert, \\end{equation} where $\\Vert\\mathbf{A}\\Vert=\\sup_{\\Vert\\mathbf{x}\\Vert=1}\\Vert\\mathbf{Ax}\\Vert$.\nFor $\\mathbf{A}$ that is non-singular, $\\kappa(\\mathbf{A})=\\infty$.\nFor $\\mathbf{A}$ which is positive definite, we thus have $\\Vert\\mathbf{A}\\Vert=\\lambda_\\text{max}$ where $\\lambda_\\text{max}$ denotes the largest eigenvalue of $\\mathbf{A}$, correspondingly $\\lambda_\\text{min}$ denotes the smallest eigenvalue of $\\mathbf{A}$. The condition number of $\\mathbf{A}$ therefore can be written as \\begin{equation} \\kappa(\\mathbf{A})=\\frac{\\lambda_\\text{max}}{\\lambda_\\text{min}}\\geq 1, \\end{equation} since corresponding to each eigenvalue $\\lambda$ of $\\mathbf{A}$, the inverse matrix $\\mathbf{A}^{-1}$ takes $1/\\lambda$ as its eigenvalue.\nBasic equation In the CMA-ES, a population of new search points is generated by sampling an MVN, in which at generation $t+1$, for $t=0,1,2,\\ldots$ \\begin{equation} \\mathbf{x}_k^{(t+1)}\\sim\\boldsymbol{\\mu}^{(t)}+\\sigma^{(t)}\\mathcal{N}(\\mathbf{0},\\boldsymbol{\\Sigma}^{(t)})\\sim\\mathcal{N}\\left(\\boldsymbol{\\mu}^{(t)},{\\sigma^{(t)}}^2\\boldsymbol{\\Sigma}^{(t)}\\right),\\hspace{1cm}k=1,\\ldots,\\lambda\\label{eq:be.1} \\end{equation} where\n$\\mathbf{x}_k^{(t+1)}\\in\\mathbb{R}^n$: the $k$-th sample at generation $t+1$. $\\boldsymbol{\\mu}^{(t)}\\in\\mathbb{R}^n$: mean of the search distribution at generation $t$. $\\sigma^{(t)}\\in\\mathbb{R}$: step-size at generation $t$. $\\boldsymbol{\\Sigma}^{(t)}$: covariance matrix at generation $t$. ${\\sigma^{(t)}}^2\\boldsymbol{\\Sigma}^{(t)}$: covariance matrix of the search distribution at generation $t$. $\\lambda\\geq 2$: sample size. Updating the mean The mean $\\boldsymbol{\\mu}^{(t+1)}$ of the search distribution is defined as the weighted average of $\\gamma$ selected points from the sample $\\mathbf{x}_1^{(t+1)},\\ldots,\\mathbf{x}_\\lambda^{(t+1)}$: \\begin{equation} \\boldsymbol{\\mu}^{(t+1)}=\\sum_{i=1}^{\\gamma}w_i\\mathbf{x}_{i:\\lambda}^{(t+1)},\\label{eq:um.1} \\end{equation} where\n$\\sum_{i=1}^{\\gamma}w_i=1$ with $w_1\\geq w_2\\geq\\ldots\\geq w_{\\gamma}\u003e0$. $\\gamma\\leq\\lambda$: number of selected points. $\\mathbf{x}_{i:\\lambda}^{(t+1)}$: $i$-th best sample out of $\\mathbf{x}_1^{(t+1)},\\ldots,\\mathbf{x}_\\lambda^{(t+1)}$ from \\eqref{eq:be.1}, i.e. with $f$ is the objective function to be minimized, we have \\begin{equation} f(\\mathbf{x}_{1:\\lambda}^{(t+1)})\\geq f(\\mathbf{x}_{2:\\lambda}^{(t+1)})\\geq\\ldots\\geq f(\\mathbf{x}_{\\lambda:\\lambda}^{(t+1)}) \\end{equation} We can rewrite \\eqref{eq:um.1} as an update rule for the mean $\\boldsymbol{\\mu}$ \\begin{equation} \\boldsymbol{\\mu}^{(t+1)}=\\boldsymbol{\\mu}^{(t)}+\\alpha_\\boldsymbol{\\mu}\\sum_{i=1}^{\\gamma}w_i\\left(\\mathbf{x}_{i:\\lambda}^{(t+1)}-\\boldsymbol{\\mu}^{(t)}\\right), \\end{equation} where $\\alpha_\\boldsymbol{\\mu}\\leq 1$ is the learning rate, which is usually set to $1$.\nWhen choosing the weight values $w_i$ and population size $\\gamma$ for recombination, we take into account the variance effective selection mass, denoted as $\\gamma_\\text{eff}$, given by \\begin{equation} \\gamma_\\text{eff}\\doteq\\left(\\frac{\\Vert\\mathbf{w}\\Vert_1}{\\Vert\\mathbf{w}\\Vert_2}\\right)=\\frac{\\Vert\\mathbf{w}\\Vert_1^2}{\\Vert\\mathbf{w}\\Vert_2^2}=\\frac{1}{\\sum_{i=1}^{\\gamma}w_i^2} \\end{equation} where $\\mathbf{w}$ is defined as the weight vector \\begin{equation} \\mathbf{w}=(w_1,\\ldots,w_\\gamma)^\\text{T} \\end{equation}\nAdapting the covariance matrix The covariance matrix can be estimated from scratch using the population of the current generation or can be estimated with covariance matrix from previous generations.\nEstimating from scratch Rather than using the empirical covariance matrix as an estimator for $\\boldsymbol{\\Sigma}^{(t)}$, in the CMA-ES, we consider the following estimation \\begin{equation} \\boldsymbol{\\Sigma}_\\lambda^{(t+1)}=\\frac{1}{\\lambda{\\sigma^{(t)}}^2}\\sum_{i=1}^{\\lambda}\\left(\\mathbf{x}_i^{(t+1)}-\\boldsymbol{\\mu}^{(t)}\\right)\\left(\\mathbf{x}_i^{(t+1)}-\\boldsymbol{\\mu}^{(t)}\\right)^\\text{T}\\label{eq:es.1} \\end{equation} Notice that in the above estimation \\eqref{eq:es.1}, we have used all of the $\\lambda$ samples. We thus can estimate a better covariance matrix by select some of the best individual out of $\\lambda$ samples, which is analogous to how we update the mean $\\boldsymbol{\\mu}$.\nIn particular, we instead consider the estimation \\begin{equation} \\boldsymbol{\\Sigma}_{\\gamma}^{(t+1)}=\\frac{1}{{\\sigma^{(t)}}^2}\\sum_{i=1}^{\\gamma}w_i\\left(\\mathbf{x}_{i:\\lambda}^{(t+1)}-\\boldsymbol{\\mu}^{(t)}\\right)\\left(\\mathbf{x}_{i:\\lambda}^{(t+1)}-\\boldsymbol{\\mu}^{(t)}\\right)^\\text{T},\\label{eq:es.2} \\end{equation} where $\\gamma\\leq\\lambda$ is the number of selected points; the weights $w_i$ and selected points $\\mathbf{x}_{i:\\lambda}^{(t+1)}$ are defined as given in the update for $\\boldsymbol{\\mu}$.\nRank-$\\gamma$ update In order to ensure that \\eqref{eq:es.2} is a reliable estimator, the selected population must be large enough. However, to get a fast search, the population size $\\lambda$ must be small, which lets the selected sample size consequently small also. Thus, we can not get a reliable estimator for a good covariance matrix from \\eqref{eq:es.2}. However, we can use the history as a helping hand.\nIn particular, if we have experienced a sufficient number of generations, the mean of the $\\boldsymbol{\\Sigma}_\\gamma$ from all previous generations \\begin{equation} \\boldsymbol{\\Sigma}^{(t+1)}=\\frac{1}{t+1}\\sum_{i=0}^{t}\\boldsymbol{\\Sigma}_\\gamma^{(i+1)}\\label{eq:rlmu.1} \\end{equation} would be a reliable estimator.\nIn addition, it is reasonable that the recent generations will have more affection to the current generation than the distant ones. Hence, rather than assigning estimated covariance matrices $\\boldsymbol{\\Sigma}_\\gamma$ from preceding generations the same weight as in \\eqref{eq:rlmu.1}, it would be a better choice to give the more recent generations the higher weight.\nSpecifically, starting with an initial $\\boldsymbol{\\Sigma}^{(0)}=\\mathbf{I}$, we consider the update, called rank-$\\gamma$ update, for the covariance matrix at generation $t+1$ using exponential smoothing1 as \\begin{align} \\boldsymbol{\\Sigma}^{(t+1)}\u0026=(1-\\alpha_\\gamma)\\boldsymbol{\\Sigma}^{(t)}+\\alpha_\\gamma\\boldsymbol{\\Sigma}_\\gamma^{(t+1)} \\\\ \u0026=(1-\\alpha_\\gamma)\\boldsymbol{\\Sigma}^{(t)}+\\alpha_\\gamma\\frac{1}{{\\sigma^{(t)}}^2}\\sum_{i=1}^{\\gamma}w_i\\left(\\mathbf{x}_{i:\\lambda}^{(t+1)}-\\boldsymbol{\\mu}^{(t)}\\right)\\left(\\mathbf{x}_{i:\\lambda}^{(t+1)}-\\boldsymbol{\\mu}^{(t)}\\right)^\\text{T} \\\\ \u0026=(1-\\alpha_\\gamma)\\boldsymbol{\\Sigma}^{(t)}+\\alpha_\\gamma\\sum_{i=1}^{\\gamma}w_i\\mathbf{y}_{i:\\lambda}^{(t+1)}{\\mathbf{y}_{i:\\lambda}^{(t+1)}}^\\text{T},\\label{eq:rlmu.2} \\end{align} where\n$\\alpha_\\gamma\\leq 1$: learning rate. $w_1,\\ldots,w_\\gamma$ and $\\mathbf{x}_{1:\\lambda}^{(t+1)},\\ldots,\\mathbf{x}_{\\lambda:\\lambda}^{(g+1)}$ are defined as usual. $\\mathbf{y}_{i:\\lambda}^{(t+1)}=(\\mathbf{x}_{i:\\lambda}^{(t+1)}-\\boldsymbol{\\mu}^{(t)})/\\sigma^{(t)}$. The update \\eqref{eq:rlmu.2} can be generalized to $\\lambda$ weights values which neither necessarily sum to $1$, nor be non-negative anymore, as \\begin{align} \\boldsymbol{\\Sigma}^{(t+1)}\u0026=\\left(1-\\alpha_\\gamma\\sum_{i=1}^{\\lambda}w_i\\right)\\boldsymbol{\\Sigma}^{(t)}+\\alpha_\\gamma\\sum_{i=1}^{\\lambda}w_i\\mathbf{y}_{i:\\lambda}^{(t+1)}{\\mathbf{y}_{i:\\lambda}^{(t+1)}}^\\text{T}\\label{eq:rlmu.3} \\\\ \u0026={\\boldsymbol{\\Sigma}^{(t)}}^{1/2}\\left[\\mathbf{I}+\\alpha_\\gamma\\sum_{i=1}^{\\lambda}w_i\\left(\\mathbf{z}_{i:\\lambda}^{(t+1)}{\\mathbf{z}_{i:\\lambda}^{(t+1)}}^\\text{T}-\\mathbf{I}\\right)\\right]{\\boldsymbol{\\Sigma}^{(t)}}^{1/2}, \\end{align} where\n$w_1\\geq\\ldots\\geq w_\\gamma\u003e0\\geq w_{\\gamma+1}\\geq\\ldots\\geq w_\\lambda\\in\\mathbb{R}$, and usually $\\sum_{i=1}^{\\gamma}w_i=1$ and $\\sum_{i=1}^{\\lambda}w_i\\approx 0$. $\\mathbf{z}_{i:\\lambda}^{(t+1)}={\\boldsymbol{\\Sigma}^{(t)}}^{1/2}\\mathbf{y}_{i:\\lambda}^{(t+1)}$ is the mutation vector. Rank-one-update We first consider a method that produces an $n$-dimensional normal distribution with zero mean. Specifically, let $\\mathbf{y}_1,\\ldots,\\mathbf{y}_{t_0}\\in\\mathbb{R}^n$, for $t_0\\geq n$ be vectors span $\\mathbb{R}^n$. We thus have that \\begin{align} \\mathcal{N}(0,1)\\mathbf{y}_1+\\ldots+\\mathcal{N}(0,1)\\mathbf{y}_{t_0}\u0026\\sim\\mathcal{N}(\\mathbf{0},\\mathbf{y}_1\\mathbf{y}_1^\\text{T})+\\ldots+\\mathcal{N}(\\mathbf{0},\\mathbf{y}_{t_0}\\mathbf{y}_{t_0}^\\text{T}) \\\\ \u0026\\sim\\mathcal{N}\\left(\\mathbf{0},\\sum_{i=1}^{t_0}\\mathbf{y}_i\\mathbf{y}_i^\\text{T}\\right) \\end{align} The covariance matrix $\\mathbf{y}_i\\mathbf{y}_i^\\text{T}$ has rank one, with only one eigenvalue $\\Vert\\mathbf{y}_i\\Vert^2$ and a corresponding eigenvector within the form $\\alpha\\mathbf{y}_i$ for $\\alpha\\in\\mathbb{R}$. Using the above equation, we can generate any MVN distribution.\nConsider the update \\eqref{eq:rlmu.3} with $\\gamma=1$ and let $\\mathbf{y}_{t+1}=\\left(\\mathbf{x}_{1:\\lambda}^{(t+1)}-\\boldsymbol{\\mu}^{(t)}\\right)/\\sigma^{(t)}$, the rank-one update for the covariance matrix $\\boldsymbol{\\Sigma}^{(t+1)}$ is given by \\begin{equation} \\boldsymbol{\\Sigma}^{t+1}=(1-\\alpha_1)\\boldsymbol{\\Sigma}^{(t)}+\\alpha_1\\mathbf{y}_{t+1}\\mathbf{y}_{t+1}^\\text{T} \\end{equation} The latter summand in the RHS has rank one and adds the maximum likelihood term for $\\mathbf{y}_{t+1}$ into the covariance matrix $\\boldsymbol{\\Sigma}^{(t)}$, which makes the probability of generating $\\mathbf{y}_{t+1}$ in the generation $t+1$ increase.\nWe continue by noticing that to update the covariance matrix $\\boldsymbol{\\Sigma}^{(t+1)}$, in \\eqref{eq:rlmu.3}, we have used the selected steps \\begin{equation} \\mathbf{y}_{i:\\lambda}^{(g+1)}=\\frac{\\mathbf{x}_{i:\\lambda}^{(g+1)}-\\boldsymbol{\\mu}^{(g)}}{\\sigma^{(g)}} \\end{equation} However, since \\begin{equation} \\mathbf{y}_{i:\\lambda}^{(g+1)}{\\mathbf{y}_{i:\\lambda}^{(g+1)}}^\\text{T}=-\\mathbf{y}_{i:\\lambda}^{(g+1)}\\left(-\\mathbf{y}_{i:\\lambda}^{(g+1)}\\right)^\\text{T}, \\end{equation} which means the sign information is lost when computing the covariance matrix. To track the sign information to the update rule of $\\boldsymbol{\\Sigma}^{(t+1)}$, we use evolution path, which defined as a sequence of successive steps over number of generations.\nIn particular, analogy to \\eqref{eq:rlmu.3}, we use exponential smoothing to establish the evolution path, $\\mathbf{p}_c\\in\\mathbb{R}^n$, which starting with an initial value $\\mathbf{p}_c^{(0)}=\\mathbf{0}$ and being updated with \\begin{align} \\mathbf{p}_c^{(t+1)}\u0026=(1-\\alpha_c)\\mathbf{p}_c^{(t)}+\\sqrt{(1-(1-\\alpha_c)^2)\\mu_\\text{eff}}\\sum_{i=1}^{\\gamma}w_i\\mathbf{y}_{i:\\lambda}^{(t+1)} \\\\ \u0026=(1-\\alpha_c)\\mathbf{p}_c^{(t)}+\\sqrt{\\alpha_c(2-\\alpha_c)\\gamma_\\text{eff}}\\sum_{i=1}^{\\gamma}\\frac{w_i\\left(\\mathbf{x}_{i:\\lambda}^{(t+1)}-\\boldsymbol{\\mu}^{(t)}\\right)}{\\sigma^{(t)}} \\\\ \u0026=(1-\\alpha_c)\\mathbf{p}_c^{(t)}+\\sqrt{\\alpha_c(2-\\alpha_c)\\gamma_\\text{eff}}\\frac{1}{\\sigma^{(t)}}\\left[\\left(\\sum_{i=1}^{\\gamma}w_i\\mathbf{x}_{i:\\lambda}^{(t+1)}\\right)-\\boldsymbol{\\mu}^{(t)}\\sum_{i=1}^{\\gamma}w_i\\right] \\\\ \u0026=(1-\\alpha_c)\\mathbf{p}_c^{(t)}+\\sqrt{\\alpha_c(2-\\alpha_c)\\gamma_\\text{eff}}\\frac{\\boldsymbol{\\mu}^{(t+1)}-\\boldsymbol{\\mu}^{(t)}}{\\sigma^{(t)}}, \\end{align} where\n$\\mathbf{p}_c^{(t)}\\in\\mathbb{R}^n$ is the evolution path at generation $t$. $\\alpha_c\\leq 1$ is the learning rate. $\\sqrt{\\alpha_c(2-\\alpha_c)\\gamma_\\text{eff}}$ is a normalization factor for $\\mathbf{p}_c^{(t+1)}$ such that \\begin{equation} \\mathbf{p}_c^{(t+1)}\\sim\\mathcal{N}(\\mathbf{0},\\boldsymbol{\\Sigma}), \\end{equation} since by $\\mathbf{y}_{i:\\lambda}^{(t+1)}=(\\mathbf{x}_{i:\\lambda}^{(t+1)}-\\boldsymbol{\\mu}^{(t)})/\\sigma^{(t)}$ we have that \\begin{equation} \\mathbf{p}_c^{(t)}\\sim\\mathbf{y}_{i:\\lambda}^{(t+1)}\\sim\\mathcal{N}(\\mathbf{0},\\boldsymbol{\\Sigma}),\\hspace{1cm}\\forall i=1,\\ldots,\\gamma \\end{equation} which by $\\gamma_\\text{eff}=\\left(\\sum_{i=1}^{\\gamma}w_i^2\\right)^{-1}$ implies that \\begin{equation} \\sum_{i=1}^{\\gamma}w_i\\mathbf{y}_{i:\\lambda}^{(t+1)}\\sim\\frac{1}{\\sqrt{\\gamma_\\text{eff}}}\\mathcal{N}(\\mathbf{0},\\boldsymbol{\\Sigma}) \\end{equation} The rank-one update for the covariance matrix $\\boldsymbol{\\Sigma}^{(t)}$ via the evolution path $\\mathbf{p}_c^{(t+1)}$ then given as \\begin{equation} \\boldsymbol{\\Sigma}^{(t+1)}=(1-\\alpha_1)\\boldsymbol{\\Sigma}^{(t)}+\\alpha_1\\mathbf{p}_c^{(t+1)}{\\mathbf{p}_c^{(t+1)}}^\\text{T},\\label{eq:rou.1} \\end{equation} An empirical validated choice for the learning rate $\\alpha_1$ is $\\alpha_1\\approx 2/n^2$.\nFinal update Combining rank-$\\gamma$ update \\eqref{eq:rlmu.3} and rank-one update \\eqref{eq:rou.1} together, we obtain the final update for the covariance matrix $\\boldsymbol{\\Sigma}^{(t+1)}$ as \\begin{equation} \\boldsymbol{\\Sigma}^{(t+1)}=\\left(1-\\alpha_1-\\alpha_\\gamma\\sum_{i=1}^{\\lambda}w_i\\right)\\boldsymbol{\\Sigma}^{(t)}+\\alpha_1\\mathbf{p}_c^{(t+1)}{\\mathbf{p}_c^{(t+1)}}^\\text{T}+\\alpha_\\gamma\\sum_{i=1}^{\\lambda}w_i\\mathbf{y}_{i:\\lambda}^{(t+1)}{\\mathbf{y}_{i:\\lambda}^{(t+1)}}^\\text{T}, \\end{equation} where\n$\\alpha_1\\approx 2/n^2$. $\\alpha_\\gamma\\approx\\min(\\gamma_\\text{eff}/n^2,1-\\alpha_1)$. $\\mathbf{y}_{i:\\lambda}^{(t+1)}=\\left(\\mathbf{x}_{i:\\lambda}^{(t+1)}-\\boldsymbol{\\mu}^{(t)}\\right)/\\sigma^{(t)}$. $\\sum_{i=1}^{\\lambda}w_i\\approx-\\alpha_1/\\alpha_\\gamma$. Controlling the step-size To control the step-size $\\sigma^{(t)}$, similar to how we cumulatively update the covariance matrix by rank-one covariance matrices, we also use an evolution path, which is defined as sum of successive steps $\\boldsymbol{\\mu}^{(t+1)}-\\boldsymbol{\\mu}^{(t)}$.\nHowever, in this step-size adaption, we utilize a conjugate evolution path $\\mathbf{p}_\\sigma$, which begins with an initial value $\\mathbf{p}_\\sigma^{(0)}=\\mathbf{0}$ and is repeatedly updated by \\begin{align} \\mathbf{p}_\\sigma^{(t+1)}\u0026=(1-\\alpha_\\sigma)\\mathbf{p}_\\sigma^{(t)}+\\sqrt{(1-(1-\\alpha_\\sigma)^2)\\gamma_\\text{eff}}{\\boldsymbol{\\Sigma}^{(t)}}^{-1/2}\\sum_{i=1}^{\\gamma}w_i\\mathbf{y}_{i:\\lambda}^{(t+1)} \\\\ \u0026=1-\\alpha_\\sigma)\\mathbf{p}_\\sigma^{(t)}+\\sqrt{\\alpha_\\sigma(2-\\alpha_\\sigma)\\gamma_\\text{eff}}{\\boldsymbol{\\Sigma}^{(t)}}^{-1/2}\\sum_{i=1}^{\\gamma}w_i\\frac{\\mathbf{x}_{i:\\lambda}^{(t+1)}-\\boldsymbol{\\mu}^{(t)}}{\\sigma^{(t)}} \\\\ \u0026=1-\\alpha_\\sigma)\\mathbf{p}_\\sigma^{(t)}+\\sqrt{\\alpha_\\sigma(2-\\alpha_\\sigma)\\gamma_\\text{eff}}{\\boldsymbol{\\Sigma}^{(t)}}^{-1/2}\\frac{1}{\\sigma^{(t)}}\\left[\\left(\\sum_{i=1}^{\\gamma}w_i\\mathbf{x}_{i:\\lambda}^{(t+1)}\\right)-\\boldsymbol{\\mu}^{(t)}\\sum_{i=1}^{\\gamma}w_i\\right] \\\\ \u0026=1-\\alpha_\\sigma)\\mathbf{p}_\\sigma^{(t)}+\\sqrt{\\alpha_\\sigma(2-\\alpha_\\sigma)\\gamma_\\text{eff}}{\\boldsymbol{\\Sigma}^{(t)}}^{-1/2}\\frac{\\boldsymbol{\\mu}^{(t+1)}-\\boldsymbol{\\mu}^{(t)}}{\\sigma^{(t)}}, \\end{align} where\n$\\mathbf{p}_\\sigma^{(t)}\\in\\mathbb{R}^n$ is the conjugate evolution path at generation $t$. $\\alpha_\\sigma\u003c1$ is the learning rate. $\\sqrt{\\alpha_c(2-\\alpha_c)\\gamma_\\text{eff}}$ is a normalization factor for $\\mathbf{p}_\\sigma^{(t+1)}$, which analogously to the covariance matrix adaption, lets \\begin{equation} \\mathbf{p}_\\sigma^{(t+1)}\\sim\\mathcal{N}(\\mathbf{0},\\mathbf{I}) \\end{equation} The covariance matrix ${\\boldsymbol{\\Sigma}^{(t)}}^{-1/2}$ is defined as \\begin{equation} {\\boldsymbol{\\Sigma}^{(t)}}^{-1/2}\\doteq\\mathbf{Q}^{(t)}{\\boldsymbol{\\Lambda}^{(t)}}^{-1/2}{\\mathbf{Q}^{(t)}}^\\text{T},\\label{eq:cs.1} \\end{equation} where \\begin{equation} \\hspace{-0.8cm}\\boldsymbol{\\Sigma}^{(t)}=\\mathbf{Q}^{(t)}\\boldsymbol{\\Lambda}^{(t)}{\\mathbf{Q}^{(t)}}^\\text{T}=\\left[\\begin{matrix}\\vert\u0026\u0026\\vert \\\\ \\mathbf{q}_1^{(t)}\u0026\\ldots\u0026\\mathbf{q}_n^{(t)} \\\\ \\vert\u0026\u0026\\vert\\end{matrix}\\right]\\left[\\begin{matrix}\\lambda_1^{(t)}\u0026\u0026 \\\\ \u0026\\ddots\u0026 \\\\ \u0026\u0026 \\lambda_n^{(t)}\\end{matrix}\\right]\\left[\\begin{matrix}\\vert\u0026\u0026\\vert \\\\ \\mathbf{q}_1^{(t)}\u0026\\ldots\u0026\\mathbf{q}_n^{(t)} \\\\ \\vert\u0026\u0026\\vert\\end{matrix}\\right]^\\text{T} \\end{equation} is an eigendecomposition of the positive definite covariance matrix $\\boldsymbol{\\Sigma}^{(t)}$, where $\\mathbf{Q}^{(t)}\\in\\mathbb{R}^{n\\times n}$ is an orthonormal matrix whose columns are unit eigenvectors $\\mathbf{q}_i^{(t)}$ of $\\boldsymbol{\\Sigma}^{(t)}$ and $\\boldsymbol{\\Lambda}^{(t)}\\in\\mathbb{R}^{n\\times n}$ is a diagonal matrix whose diagonal entries are eigenvalues $\\lambda_i^{(t)}$ of $\\boldsymbol{\\Sigma}^{(t)}$.\nMoreover, for each eigenvalue, eigenvector pair $(\\lambda_i^{(t)},\\mathbf{q}_i^{(t)})$ of $\\boldsymbol{\\Sigma}^{(t)}$ we have \\begin{equation} \\lambda_i^{(t)}{\\boldsymbol{\\Sigma}^{(t)}}^{-1}\\mathbf{q}_i^{(t)}={\\boldsymbol{\\Sigma}^{(t)}}^{-1}\\boldsymbol{\\Sigma}^{(t)}\\mathbf{q}_i^{(t)}=\\mathbf{q}_i^{(t)}, \\end{equation} or \\begin{equation} {\\boldsymbol{\\Sigma}^{(t)}}^{-1}\\mathbf{q}_i^{(t)}=\\frac{1}{\\lambda_i^{(t)}}\\mathbf{q}_i^{(t)}, \\end{equation} or in other words, $(1/\\lambda_i^{(t)},\\mathbf{q}_i^{(t)})$ is an eigenvalue, eigenvector pair of ${\\boldsymbol{\\Sigma}^{(t)}}^{-1}$. Therefore, the inverse of $\\boldsymbol{\\Sigma}^{(t)}$, which is also positive definite can be written by \\begin{equation} {\\boldsymbol{\\Sigma}^{(t)}}^{-1}=\\mathbf{Q}^{(t)}\\left[\\begin{matrix}1/\\lambda_1^{(t)}\u0026\u0026 \\\\ \u0026\\ddots\u0026 \\\\ \u0026\u0026 1/\\lambda_n^{(t)}\\end{matrix}\\right]{\\mathbf{Q}^{(t)}}^\\text{T}=\\mathbf{Q}^{(t)}{\\boldsymbol{\\Lambda}^{(t)}}^{-1}{\\mathbf{Q}^{(t)}}^\\text{T}, \\end{equation} which allows us to obtain the representation \\eqref{eq:cs.1} of ${\\boldsymbol{\\Sigma}^{(t)}}^{-1/2}$. The transformation ${\\boldsymbol{\\Sigma}^{(t)}}^{-1/2}=\\mathbf{Q}^{(t)}{\\boldsymbol{\\Lambda}^{(t)}}^{-1/2}{\\mathbf{Q}^{(t)}}^\\text{T}$ re-scales length of the step $\\boldsymbol{\\mu}^{(t+1)}-\\boldsymbol{\\mu}^{(t)}$ without changing its direction. In more specific:\n${\\mathbf{Q}^{(t)}}^\\text{T}$ transform the original space into the coordinate space with columns of $\\mathbf{Q}^{(t)}$, which is also the eigenvectors of $\\boldsymbol{\\Sigma}^{(t)}$ or the principle axes of $\\mathcal{N}(\\mathbf{0},\\boldsymbol{\\Sigma}^{(t)})$, as its principle axes. ${\\boldsymbol{\\Lambda}^{(t)}}^{-1/2}$ re-scales the principle axes to have the same length. $\\mathbf{Q}^{(t)}$ transforms the coordinate system back to the original space. It means that this transformation makes the expected length of $\\mathbf{p}_\\sigma^{(t+1)}$ independent of its direction.\nWe then update $\\sigma^{(t)}$ by according to the ratio of its length with its expected length $\\Vert\\mathbf{p}_\\sigma^{(t+1)}\\Vert/\\mathbb{E}\\Vert\\mathcal{N}(\\mathbf{0},\\mathbf{I})\\Vert$, given by \\begin{equation} \\log\\sigma^{(t+1)}=\\log\\sigma^{(t)}+\\frac{\\alpha_\\sigma}{d_\\sigma}\\left(\\frac{\\Vert\\mathbf{p}_\\sigma^{(t+1)}\\Vert}{\\mathbb{E}\\Vert\\mathcal{N}(\\mathbf{0},\\mathbf{I})\\Vert}-1\\right), \\end{equation} where $d_\\sigma\\approx 1$ is the damping parameter, which controls the update size. Therefore, since $\\sigma^{(t)}\u003e0$, we have the update rule for $\\sigma^{(t)}$ is given by \\begin{equation} \\sigma^{(t+1)}=\\sigma^{(t)}\\exp\\left(\\frac{\\alpha_\\sigma}{d_\\sigma}\\left(\\frac{\\Vert\\mathbf{p}_\\sigma^{(t+1)}\\Vert}{\\mathbb{E}\\Vert\\mathcal{N}(\\mathbf{0},\\mathbf{I})\\Vert}-1\\right)\\right) \\end{equation}\nTesting on Rastrigin function Let us give the CMA-ES algorithm a try on the Rastrigin function, $f:\\mathbb{R}^n\\to\\mathbb{R}$, which is given by \\begin{equation} f(\\mathbf{x})=10 n+\\sum_{i=1}^{n}x_i^2-10\\cos\\left(2\\pi x_i\\right) \\end{equation} The global minimum of $f(\\mathbf{x})$ is $0$ at $\\mathbf{x}=\\mathbf{0}$. We will be using the experimental settings given in this paper proposed by CMA-ES’s original author. Each time we end up with a result less than $f_\\text{stop}=10^{-10}$, we count it a success run.\nThe result obtained is illustrated in the following figure.\nFigure 1: Success rate to reach $f_\\text{stop}=10^{-10}$ versus population size for Rastrigin function.\nThe code can be found here References [1] Nikolaus Hansen. The CMA Evolution Strategy: A Tutorial. arXiv:1604.00772, 2016.\n[2] Nikolaus Hansen, Youhei Akimoto \u0026 Petr Baudis. CMA-ES/pycma on Github. Zenodo, DOI:10.5281/zenodo.2559634, February 2019.\n[3] Nikolaus Hansen, Stefan Kern. Evaluating the CMA Evolution Strategy on Multimodal Test Functions. Parallel Problem Solving from Nature - PPSN VIII. PPSN 2004.\n[4] Ha, David. A Visual Guide to Evolution Strategies. blog.otoro.net, 2017.\nFootnotes The simplest form of exponential smoothing is given by the formula \\begin{align*} s_0\u0026=x_0 \\\\ s_t\u0026=\\alpha x_t+(1-\\alpha)s_{t-1},\\hspace{1cm}t\u003e0 \\end{align*} where $0\u003c\\alpha\u003c1$ is referred as the smoothing factor. ↩︎\n","wordCount":"1529","inLanguage":"en","datePublished":"2022-09-14T13:00:00+07:00","dateModified":"2022-09-14T13:00:00+07:00","author":{"@type":"Person","name":"Trung H. Nguyen"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://trunghng.github.io/posts/evolution-strategy/cma-es/"},"publisher":{"@type":"Organization","name":"Trung's Place","logo":{"@type":"ImageObject","url":"https://trunghng.github.io/images/favicon/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://trunghng.github.io accesskey=h title="Trung's Place (Alt + H)"><img src=https://trunghng.github.io/images/others/pokeball.png alt aria-label=logo height=27>Trung's Place</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://trunghng.github.io/ title=Posts><span>Posts</span></a></li><li><a href=https://trunghng.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://trunghng.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://trunghng.github.io/about/ title=About><span>About</span></a></li><li><a href=https://trunghng.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>CMA Evolution Strategy</h1><div class=post-meta><span title='2022-09-14 13:00:00 +0700 +0700'>September 14, 2022</span>&nbsp;·&nbsp;8 min&nbsp;·&nbsp;Trung H. Nguyen</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#preliminaries>Preliminaries</a></li><li><a href=#bsc-eqn>Basic equation</a></li><li><a href=#upd-mean>Updating the mean</a></li><li><a href=#adp-cov>Adapting the covariance matrix</a><ul><li><a href=#est-scratch>Estimating from scratch</a></li><li><a href=#rank-lambda-mu-update>Rank-$\gamma$ update</a></li><li><a href=#rank-one-update>Rank-one-update</a></li><li><a href=#final-update>Final update</a></li></ul></li><li><a href=#ctrl-sigma>Controlling the step-size</a></li><li><a href=#test-on-rast>Testing on Rastrigin function</a></li><li><a href=#references>References</a></li><li><a href=#footnotes>Footnotes</a></li></ul></nav></div></details></div><div class=post-content><blockquote><p>Notes on CMA - Evolution Strategy.</p></blockquote><h2 id=preliminaries>Preliminaries<a hidden class=anchor aria-hidden=true href=#preliminaries>#</a></h2><p>The <strong>condition number</strong> of a matrix $\mathbf{A}$ is defined by
\begin{equation}
\kappa(\mathbf{A})\doteq\Vert\mathbf{A}\Vert\Vert\mathbf{A}^{-1}\Vert,
\end{equation}
where $\Vert\mathbf{A}\Vert=\sup_{\Vert\mathbf{x}\Vert=1}\Vert\mathbf{Ax}\Vert$.</p><p>For $\mathbf{A}$ that is non-singular, $\kappa(\mathbf{A})=\infty$.</p><p>For $\mathbf{A}$ which is positive definite, we thus have $\Vert\mathbf{A}\Vert=\lambda_\text{max}$ where $\lambda_\text{max}$ denotes the largest eigenvalue of $\mathbf{A}$, correspondingly $\lambda_\text{min}$ denotes the smallest eigenvalue of $\mathbf{A}$. The condition number of $\mathbf{A}$ therefore can be written as
\begin{equation}
\kappa(\mathbf{A})=\frac{\lambda_\text{max}}{\lambda_\text{min}}\geq 1,
\end{equation}
since corresponding to each eigenvalue $\lambda$ of $\mathbf{A}$, the inverse matrix $\mathbf{A}^{-1}$ takes $1/\lambda$ as its eigenvalue.</p><h2 id=bsc-eqn>Basic equation<a hidden class=anchor aria-hidden=true href=#bsc-eqn>#</a></h2><p>In the CMA-ES, a population of new search points is generated by sampling an MVN, in which at generation $t+1$, for $t=0,1,2,\ldots$
\begin{equation}
\mathbf{x}_k^{(t+1)}\sim\boldsymbol{\mu}^{(t)}+\sigma^{(t)}\mathcal{N}(\mathbf{0},\boldsymbol{\Sigma}^{(t)})\sim\mathcal{N}\left(\boldsymbol{\mu}^{(t)},{\sigma^{(t)}}^2\boldsymbol{\Sigma}^{(t)}\right),\hspace{1cm}k=1,\ldots,\lambda\label{eq:be.1}
\end{equation}
where</p><ul><li>$\mathbf{x}_k^{(t+1)}\in\mathbb{R}^n$: the $k$-th sample at generation $t+1$.</li><li>$\boldsymbol{\mu}^{(t)}\in\mathbb{R}^n$: mean of the search distribution at generation $t$.</li><li>$\sigma^{(t)}\in\mathbb{R}$: step-size at generation $t$.</li><li>$\boldsymbol{\Sigma}^{(t)}$: covariance matrix at generation $t$.</li><li>${\sigma^{(t)}}^2\boldsymbol{\Sigma}^{(t)}$: covariance matrix of the search distribution at generation $t$.</li><li>$\lambda\geq 2$: sample size.</li></ul><h2 id=upd-mean>Updating the mean<a hidden class=anchor aria-hidden=true href=#upd-mean>#</a></h2><p>The mean $\boldsymbol{\mu}^{(t+1)}$ of the search distribution is defined as the weighted average of $\gamma$ selected points from the sample $\mathbf{x}_1^{(t+1)},\ldots,\mathbf{x}_\lambda^{(t+1)}$:
\begin{equation}
\boldsymbol{\mu}^{(t+1)}=\sum_{i=1}^{\gamma}w_i\mathbf{x}_{i:\lambda}^{(t+1)},\label{eq:um.1}
\end{equation}
where</p><ul><li>$\sum_{i=1}^{\gamma}w_i=1$ with $w_1\geq w_2\geq\ldots\geq w_{\gamma}>0$.</li><li>$\gamma\leq\lambda$: number of selected points.</li><li>$\mathbf{x}_{i:\lambda}^{(t+1)}$: $i$-th best sample out of $\mathbf{x}_1^{(t+1)},\ldots,\mathbf{x}_\lambda^{(t+1)}$ from \eqref{eq:be.1}, i.e. with $f$ is the objective function to be minimized, we have
\begin{equation}
f(\mathbf{x}_{1:\lambda}^{(t+1)})\geq f(\mathbf{x}_{2:\lambda}^{(t+1)})\geq\ldots\geq f(\mathbf{x}_{\lambda:\lambda}^{(t+1)})
\end{equation}</li></ul><p>We can rewrite \eqref{eq:um.1} as an update rule for the mean $\boldsymbol{\mu}$
\begin{equation}
\boldsymbol{\mu}^{(t+1)}=\boldsymbol{\mu}^{(t)}+\alpha_\boldsymbol{\mu}\sum_{i=1}^{\gamma}w_i\left(\mathbf{x}_{i:\lambda}^{(t+1)}-\boldsymbol{\mu}^{(t)}\right),
\end{equation}
where $\alpha_\boldsymbol{\mu}\leq 1$ is the learning rate, which is usually set to $1$.</p><p>When choosing the weight values $w_i$ and population size $\gamma$ for recombination, we take into account the <strong>variance effective selection mass</strong>, denoted as $\gamma_\text{eff}$, given by
\begin{equation}
\gamma_\text{eff}\doteq\left(\frac{\Vert\mathbf{w}\Vert_1}{\Vert\mathbf{w}\Vert_2}\right)=\frac{\Vert\mathbf{w}\Vert_1^2}{\Vert\mathbf{w}\Vert_2^2}=\frac{1}{\sum_{i=1}^{\gamma}w_i^2}
\end{equation}
where $\mathbf{w}$ is defined as the weight vector
\begin{equation}
\mathbf{w}=(w_1,\ldots,w_\gamma)^\text{T}
\end{equation}</p><h2 id=adp-cov>Adapting the covariance matrix<a hidden class=anchor aria-hidden=true href=#adp-cov>#</a></h2><p>The covariance matrix can be estimated from scratch using the population of the current generation or can be estimated with covariance matrix from previous generations.</p><h3 id=est-scratch>Estimating from scratch<a hidden class=anchor aria-hidden=true href=#est-scratch>#</a></h3><p>Rather than using the empirical covariance matrix as an estimator for $\boldsymbol{\Sigma}^{(t)}$, in the CMA-ES, we consider the following estimation
\begin{equation}
\boldsymbol{\Sigma}_\lambda^{(t+1)}=\frac{1}{\lambda{\sigma^{(t)}}^2}\sum_{i=1}^{\lambda}\left(\mathbf{x}_i^{(t+1)}-\boldsymbol{\mu}^{(t)}\right)\left(\mathbf{x}_i^{(t+1)}-\boldsymbol{\mu}^{(t)}\right)^\text{T}\label{eq:es.1}
\end{equation}
Notice that in the above estimation \eqref{eq:es.1}, we have used all of the $\lambda$ samples. We thus can estimate a better covariance matrix by select some of the best individual out of $\lambda$ samples, which is analogous to how we update the mean $\boldsymbol{\mu}$.</p><p>In particular, we instead consider the estimation
\begin{equation}
\boldsymbol{\Sigma}_{\gamma}^{(t+1)}=\frac{1}{{\sigma^{(t)}}^2}\sum_{i=1}^{\gamma}w_i\left(\mathbf{x}_{i:\lambda}^{(t+1)}-\boldsymbol{\mu}^{(t)}\right)\left(\mathbf{x}_{i:\lambda}^{(t+1)}-\boldsymbol{\mu}^{(t)}\right)^\text{T},\label{eq:es.2}
\end{equation}
where $\gamma\leq\lambda$ is the number of selected points; the weights $w_i$ and selected points $\mathbf{x}_{i:\lambda}^{(t+1)}$ are defined as given in the update for $\boldsymbol{\mu}$.</p><h3 id=rank-lambda-mu-update>Rank-$\gamma$ update<a hidden class=anchor aria-hidden=true href=#rank-lambda-mu-update>#</a></h3><p>In order to ensure that \eqref{eq:es.2} is a reliable estimator, the selected population must be large enough. However, to get a fast search, the population size $\lambda$ must be small, which lets the selected sample size consequently small also. Thus, we can not get a reliable estimator for a good covariance matrix from \eqref{eq:es.2}. However, we can use the history as a helping hand.</p><p>In particular, if we have experienced a sufficient number of generations, the mean of the $\boldsymbol{\Sigma}_\gamma$ from all previous generations
\begin{equation}
\boldsymbol{\Sigma}^{(t+1)}=\frac{1}{t+1}\sum_{i=0}^{t}\boldsymbol{\Sigma}_\gamma^{(i+1)}\label{eq:rlmu.1}
\end{equation}
would be a reliable estimator.</p><p>In addition, it is reasonable that the recent generations will have more affection to the current generation than the distant ones. Hence, rather than assigning estimated covariance matrices $\boldsymbol{\Sigma}_\gamma$ from preceding generations the same weight as in \eqref{eq:rlmu.1}, it would be a better choice to give the more recent generations the higher weight.</p><p>Specifically, starting with an initial $\boldsymbol{\Sigma}^{(0)}=\mathbf{I}$, we consider the update, called <strong>rank-$\gamma$ update</strong>, for the covariance matrix at generation $t+1$ using <strong>exponential smoothing</strong><sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> as
\begin{align}
\boldsymbol{\Sigma}^{(t+1)}&=(1-\alpha_\gamma)\boldsymbol{\Sigma}^{(t)}+\alpha_\gamma\boldsymbol{\Sigma}_\gamma^{(t+1)} \\ &=(1-\alpha_\gamma)\boldsymbol{\Sigma}^{(t)}+\alpha_\gamma\frac{1}{{\sigma^{(t)}}^2}\sum_{i=1}^{\gamma}w_i\left(\mathbf{x}_{i:\lambda}^{(t+1)}-\boldsymbol{\mu}^{(t)}\right)\left(\mathbf{x}_{i:\lambda}^{(t+1)}-\boldsymbol{\mu}^{(t)}\right)^\text{T} \\ &=(1-\alpha_\gamma)\boldsymbol{\Sigma}^{(t)}+\alpha_\gamma\sum_{i=1}^{\gamma}w_i\mathbf{y}_{i:\lambda}^{(t+1)}{\mathbf{y}_{i:\lambda}^{(t+1)}}^\text{T},\label{eq:rlmu.2}
\end{align}
where</p><ul><li>$\alpha_\gamma\leq 1$: learning rate.</li><li>$w_1,\ldots,w_\gamma$ and $\mathbf{x}_{1:\lambda}^{(t+1)},\ldots,\mathbf{x}_{\lambda:\lambda}^{(g+1)}$ are defined as usual.</li><li>$\mathbf{y}_{i:\lambda}^{(t+1)}=(\mathbf{x}_{i:\lambda}^{(t+1)}-\boldsymbol{\mu}^{(t)})/\sigma^{(t)}$.</li></ul><p>The update \eqref{eq:rlmu.2} can be generalized to $\lambda$ weights values which neither necessarily sum to $1$, nor be non-negative anymore, as
\begin{align}
\boldsymbol{\Sigma}^{(t+1)}&=\left(1-\alpha_\gamma\sum_{i=1}^{\lambda}w_i\right)\boldsymbol{\Sigma}^{(t)}+\alpha_\gamma\sum_{i=1}^{\lambda}w_i\mathbf{y}_{i:\lambda}^{(t+1)}{\mathbf{y}_{i:\lambda}^{(t+1)}}^\text{T}\label{eq:rlmu.3} \\ &={\boldsymbol{\Sigma}^{(t)}}^{1/2}\left[\mathbf{I}+\alpha_\gamma\sum_{i=1}^{\lambda}w_i\left(\mathbf{z}_{i:\lambda}^{(t+1)}{\mathbf{z}_{i:\lambda}^{(t+1)}}^\text{T}-\mathbf{I}\right)\right]{\boldsymbol{\Sigma}^{(t)}}^{1/2},
\end{align}
where</p><ul><li>$w_1\geq\ldots\geq w_\gamma>0\geq w_{\gamma+1}\geq\ldots\geq w_\lambda\in\mathbb{R}$, and usually $\sum_{i=1}^{\gamma}w_i=1$ and $\sum_{i=1}^{\lambda}w_i\approx 0$.</li><li>$\mathbf{z}_{i:\lambda}^{(t+1)}={\boldsymbol{\Sigma}^{(t)}}^{1/2}\mathbf{y}_{i:\lambda}^{(t+1)}$ is the mutation vector.</li></ul><h3 id=rank-one-update>Rank-one-update<a hidden class=anchor aria-hidden=true href=#rank-one-update>#</a></h3><p>We first consider a method that produces an $n$-dimensional normal distribution with zero mean. Specifically, let $\mathbf{y}_1,\ldots,\mathbf{y}_{t_0}\in\mathbb{R}^n$, for $t_0\geq n$ be vectors span $\mathbb{R}^n$. We thus have that
\begin{align}
\mathcal{N}(0,1)\mathbf{y}_1+\ldots+\mathcal{N}(0,1)\mathbf{y}_{t_0}&\sim\mathcal{N}(\mathbf{0},\mathbf{y}_1\mathbf{y}_1^\text{T})+\ldots+\mathcal{N}(\mathbf{0},\mathbf{y}_{t_0}\mathbf{y}_{t_0}^\text{T}) \\ &\sim\mathcal{N}\left(\mathbf{0},\sum_{i=1}^{t_0}\mathbf{y}_i\mathbf{y}_i^\text{T}\right)
\end{align}
The covariance matrix $\mathbf{y}_i\mathbf{y}_i^\text{T}$ has rank one, with only one eigenvalue $\Vert\mathbf{y}_i\Vert^2$ and a corresponding eigenvector within the form $\alpha\mathbf{y}_i$ for $\alpha\in\mathbb{R}$. Using the above equation, we can generate any MVN distribution.</p><p>Consider the update \eqref{eq:rlmu.3} with $\gamma=1$ and let $\mathbf{y}_{t+1}=\left(\mathbf{x}_{1:\lambda}^{(t+1)}-\boldsymbol{\mu}^{(t)}\right)/\sigma^{(t)}$, the <strong>rank-one update</strong> for the covariance matrix $\boldsymbol{\Sigma}^{(t+1)}$ is given by
\begin{equation}
\boldsymbol{\Sigma}^{t+1}=(1-\alpha_1)\boldsymbol{\Sigma}^{(t)}+\alpha_1\mathbf{y}_{t+1}\mathbf{y}_{t+1}^\text{T}
\end{equation}
The latter summand in the RHS has rank one and adds the maximum likelihood term for $\mathbf{y}_{t+1}$ into the covariance matrix $\boldsymbol{\Sigma}^{(t)}$, which makes the probability of generating $\mathbf{y}_{t+1}$ in the generation $t+1$ increase.</p><p>We continue by noticing that to update the covariance matrix $\boldsymbol{\Sigma}^{(t+1)}$, in \eqref{eq:rlmu.3}, we have used the selected steps
\begin{equation}
\mathbf{y}_{i:\lambda}^{(g+1)}=\frac{\mathbf{x}_{i:\lambda}^{(g+1)}-\boldsymbol{\mu}^{(g)}}{\sigma^{(g)}}
\end{equation}
However, since
\begin{equation}
\mathbf{y}_{i:\lambda}^{(g+1)}{\mathbf{y}_{i:\lambda}^{(g+1)}}^\text{T}=-\mathbf{y}_{i:\lambda}^{(g+1)}\left(-\mathbf{y}_{i:\lambda}^{(g+1)}\right)^\text{T},
\end{equation}
which means the sign information is lost when computing the covariance matrix. To track the sign information to the update rule of $\boldsymbol{\Sigma}^{(t+1)}$, we use <strong>evolution path</strong>, which defined as a sequence of successive steps over number of generations.</p><p>In particular, analogy to \eqref{eq:rlmu.3}, we use exponential smoothing to establish the evolution path, $\mathbf{p}_c\in\mathbb{R}^n$, which starting with an initial value $\mathbf{p}_c^{(0)}=\mathbf{0}$ and being updated with
\begin{align}
\mathbf{p}_c^{(t+1)}&=(1-\alpha_c)\mathbf{p}_c^{(t)}+\sqrt{(1-(1-\alpha_c)^2)\mu_\text{eff}}\sum_{i=1}^{\gamma}w_i\mathbf{y}_{i:\lambda}^{(t+1)} \\ &=(1-\alpha_c)\mathbf{p}_c^{(t)}+\sqrt{\alpha_c(2-\alpha_c)\gamma_\text{eff}}\sum_{i=1}^{\gamma}\frac{w_i\left(\mathbf{x}_{i:\lambda}^{(t+1)}-\boldsymbol{\mu}^{(t)}\right)}{\sigma^{(t)}} \\ &=(1-\alpha_c)\mathbf{p}_c^{(t)}+\sqrt{\alpha_c(2-\alpha_c)\gamma_\text{eff}}\frac{1}{\sigma^{(t)}}\left[\left(\sum_{i=1}^{\gamma}w_i\mathbf{x}_{i:\lambda}^{(t+1)}\right)-\boldsymbol{\mu}^{(t)}\sum_{i=1}^{\gamma}w_i\right] \\ &=(1-\alpha_c)\mathbf{p}_c^{(t)}+\sqrt{\alpha_c(2-\alpha_c)\gamma_\text{eff}}\frac{\boldsymbol{\mu}^{(t+1)}-\boldsymbol{\mu}^{(t)}}{\sigma^{(t)}},
\end{align}
where</p><ul><li>$\mathbf{p}_c^{(t)}\in\mathbb{R}^n$ is the evolution path at generation $t$.</li><li>$\alpha_c\leq 1$ is the learning rate.</li><li>$\sqrt{\alpha_c(2-\alpha_c)\gamma_\text{eff}}$ is a normalization factor for $\mathbf{p}_c^{(t+1)}$ such that
\begin{equation}
\mathbf{p}_c^{(t+1)}\sim\mathcal{N}(\mathbf{0},\boldsymbol{\Sigma}),
\end{equation}
since by $\mathbf{y}_{i:\lambda}^{(t+1)}=(\mathbf{x}_{i:\lambda}^{(t+1)}-\boldsymbol{\mu}^{(t)})/\sigma^{(t)}$ we have that
\begin{equation}
\mathbf{p}_c^{(t)}\sim\mathbf{y}_{i:\lambda}^{(t+1)}\sim\mathcal{N}(\mathbf{0},\boldsymbol{\Sigma}),\hspace{1cm}\forall i=1,\ldots,\gamma
\end{equation}
which by $\gamma_\text{eff}=\left(\sum_{i=1}^{\gamma}w_i^2\right)^{-1}$ implies that
\begin{equation}
\sum_{i=1}^{\gamma}w_i\mathbf{y}_{i:\lambda}^{(t+1)}\sim\frac{1}{\sqrt{\gamma_\text{eff}}}\mathcal{N}(\mathbf{0},\boldsymbol{\Sigma})
\end{equation}</li></ul><p>The <strong>rank-one update</strong> for the covariance matrix $\boldsymbol{\Sigma}^{(t)}$ via the evolution path $\mathbf{p}_c^{(t+1)}$ then given as
\begin{equation}
\boldsymbol{\Sigma}^{(t+1)}=(1-\alpha_1)\boldsymbol{\Sigma}^{(t)}+\alpha_1\mathbf{p}_c^{(t+1)}{\mathbf{p}_c^{(t+1)}}^\text{T},\label{eq:rou.1}
\end{equation}
An empirical validated choice for the learning rate $\alpha_1$ is $\alpha_1\approx 2/n^2$.</p><h3 id=final-update>Final update<a hidden class=anchor aria-hidden=true href=#final-update>#</a></h3><p>Combining rank-$\gamma$ update \eqref{eq:rlmu.3} and rank-one update \eqref{eq:rou.1} together, we obtain the final update for the covariance matrix $\boldsymbol{\Sigma}^{(t+1)}$ as
\begin{equation}
\boldsymbol{\Sigma}^{(t+1)}=\left(1-\alpha_1-\alpha_\gamma\sum_{i=1}^{\lambda}w_i\right)\boldsymbol{\Sigma}^{(t)}+\alpha_1\mathbf{p}_c^{(t+1)}{\mathbf{p}_c^{(t+1)}}^\text{T}+\alpha_\gamma\sum_{i=1}^{\lambda}w_i\mathbf{y}_{i:\lambda}^{(t+1)}{\mathbf{y}_{i:\lambda}^{(t+1)}}^\text{T},
\end{equation}
where</p><ul><li>$\alpha_1\approx 2/n^2$.</li><li>$\alpha_\gamma\approx\min(\gamma_\text{eff}/n^2,1-\alpha_1)$.</li><li>$\mathbf{y}_{i:\lambda}^{(t+1)}=\left(\mathbf{x}_{i:\lambda}^{(t+1)}-\boldsymbol{\mu}^{(t)}\right)/\sigma^{(t)}$.</li><li>$\sum_{i=1}^{\lambda}w_i\approx-\alpha_1/\alpha_\gamma$.</li></ul><h2 id=ctrl-sigma>Controlling the step-size<a hidden class=anchor aria-hidden=true href=#ctrl-sigma>#</a></h2><p>To control the step-size $\sigma^{(t)}$, similar to how we cumulatively update the covariance matrix by rank-one covariance matrices, we also use an evolution path, which is defined as sum of successive steps $\boldsymbol{\mu}^{(t+1)}-\boldsymbol{\mu}^{(t)}$.</p><p>However, in this step-size adaption, we utilize a conjugate evolution path $\mathbf{p}_\sigma$, which begins with an initial value $\mathbf{p}_\sigma^{(0)}=\mathbf{0}$ and is repeatedly updated by
\begin{align}
\mathbf{p}_\sigma^{(t+1)}&=(1-\alpha_\sigma)\mathbf{p}_\sigma^{(t)}+\sqrt{(1-(1-\alpha_\sigma)^2)\gamma_\text{eff}}{\boldsymbol{\Sigma}^{(t)}}^{-1/2}\sum_{i=1}^{\gamma}w_i\mathbf{y}_{i:\lambda}^{(t+1)} \\ &=1-\alpha_\sigma)\mathbf{p}_\sigma^{(t)}+\sqrt{\alpha_\sigma(2-\alpha_\sigma)\gamma_\text{eff}}{\boldsymbol{\Sigma}^{(t)}}^{-1/2}\sum_{i=1}^{\gamma}w_i\frac{\mathbf{x}_{i:\lambda}^{(t+1)}-\boldsymbol{\mu}^{(t)}}{\sigma^{(t)}} \\ &=1-\alpha_\sigma)\mathbf{p}_\sigma^{(t)}+\sqrt{\alpha_\sigma(2-\alpha_\sigma)\gamma_\text{eff}}{\boldsymbol{\Sigma}^{(t)}}^{-1/2}\frac{1}{\sigma^{(t)}}\left[\left(\sum_{i=1}^{\gamma}w_i\mathbf{x}_{i:\lambda}^{(t+1)}\right)-\boldsymbol{\mu}^{(t)}\sum_{i=1}^{\gamma}w_i\right] \\ &=1-\alpha_\sigma)\mathbf{p}_\sigma^{(t)}+\sqrt{\alpha_\sigma(2-\alpha_\sigma)\gamma_\text{eff}}{\boldsymbol{\Sigma}^{(t)}}^{-1/2}\frac{\boldsymbol{\mu}^{(t+1)}-\boldsymbol{\mu}^{(t)}}{\sigma^{(t)}},
\end{align}
where</p><ul><li>$\mathbf{p}_\sigma^{(t)}\in\mathbb{R}^n$ is the conjugate evolution path at generation $t$.</li><li>$\alpha_\sigma&lt;1$ is the learning rate.</li><li>$\sqrt{\alpha_c(2-\alpha_c)\gamma_\text{eff}}$ is a normalization factor for $\mathbf{p}_\sigma^{(t+1)}$, which analogously to the covariance matrix adaption, lets
\begin{equation}
\mathbf{p}_\sigma^{(t+1)}\sim\mathcal{N}(\mathbf{0},\mathbf{I})
\end{equation}</li><li>The covariance matrix ${\boldsymbol{\Sigma}^{(t)}}^{-1/2}$ is defined as
\begin{equation}
{\boldsymbol{\Sigma}^{(t)}}^{-1/2}\doteq\mathbf{Q}^{(t)}{\boldsymbol{\Lambda}^{(t)}}^{-1/2}{\mathbf{Q}^{(t)}}^\text{T},\label{eq:cs.1}
\end{equation}
where
\begin{equation}
\hspace{-0.8cm}\boldsymbol{\Sigma}^{(t)}=\mathbf{Q}^{(t)}\boldsymbol{\Lambda}^{(t)}{\mathbf{Q}^{(t)}}^\text{T}=\left[\begin{matrix}\vert&&\vert \\ \mathbf{q}_1^{(t)}&\ldots&\mathbf{q}_n^{(t)} \\ \vert&&\vert\end{matrix}\right]\left[\begin{matrix}\lambda_1^{(t)}&& \\ &\ddots& \\ && \lambda_n^{(t)}\end{matrix}\right]\left[\begin{matrix}\vert&&\vert \\ \mathbf{q}_1^{(t)}&\ldots&\mathbf{q}_n^{(t)} \\ \vert&&\vert\end{matrix}\right]^\text{T}
\end{equation}
is an eigendecomposition of the positive definite covariance matrix $\boldsymbol{\Sigma}^{(t)}$, where $\mathbf{Q}^{(t)}\in\mathbb{R}^{n\times n}$ is an orthonormal matrix whose columns are unit eigenvectors $\mathbf{q}_i^{(t)}$ of $\boldsymbol{\Sigma}^{(t)}$ and $\boldsymbol{\Lambda}^{(t)}\in\mathbb{R}^{n\times n}$ is a diagonal matrix whose diagonal entries are eigenvalues $\lambda_i^{(t)}$ of $\boldsymbol{\Sigma}^{(t)}$.<br>Moreover, for each eigenvalue, eigenvector pair $(\lambda_i^{(t)},\mathbf{q}_i^{(t)})$ of $\boldsymbol{\Sigma}^{(t)}$ we have
\begin{equation}
\lambda_i^{(t)}{\boldsymbol{\Sigma}^{(t)}}^{-1}\mathbf{q}_i^{(t)}={\boldsymbol{\Sigma}^{(t)}}^{-1}\boldsymbol{\Sigma}^{(t)}\mathbf{q}_i^{(t)}=\mathbf{q}_i^{(t)},
\end{equation}
or
\begin{equation}
{\boldsymbol{\Sigma}^{(t)}}^{-1}\mathbf{q}_i^{(t)}=\frac{1}{\lambda_i^{(t)}}\mathbf{q}_i^{(t)},
\end{equation}
or in other words, $(1/\lambda_i^{(t)},\mathbf{q}_i^{(t)})$ is an eigenvalue, eigenvector pair of ${\boldsymbol{\Sigma}^{(t)}}^{-1}$. Therefore, the inverse of $\boldsymbol{\Sigma}^{(t)}$, which is also positive definite can be written by
\begin{equation}
{\boldsymbol{\Sigma}^{(t)}}^{-1}=\mathbf{Q}^{(t)}\left[\begin{matrix}1/\lambda_1^{(t)}&& \\ &\ddots& \\ && 1/\lambda_n^{(t)}\end{matrix}\right]{\mathbf{Q}^{(t)}}^\text{T}=\mathbf{Q}^{(t)}{\boldsymbol{\Lambda}^{(t)}}^{-1}{\mathbf{Q}^{(t)}}^\text{T},
\end{equation}
which allows us to obtain the representation \eqref{eq:cs.1} of ${\boldsymbol{\Sigma}^{(t)}}^{-1/2}$.</li></ul><p>The transformation ${\boldsymbol{\Sigma}^{(t)}}^{-1/2}=\mathbf{Q}^{(t)}{\boldsymbol{\Lambda}^{(t)}}^{-1/2}{\mathbf{Q}^{(t)}}^\text{T}$ re-scales length of the step $\boldsymbol{\mu}^{(t+1)}-\boldsymbol{\mu}^{(t)}$ without changing its direction. In more specific:</p><ul id=number-list><li>${\mathbf{Q}^{(t)}}^\text{T}$ transform the original space into the coordinate space with columns of $\mathbf{Q}^{(t)}$, which is also the eigenvectors of $\boldsymbol{\Sigma}^{(t)}$ or the principle axes of $\mathcal{N}(\mathbf{0},\boldsymbol{\Sigma}^{(t)})$, as its principle axes.</li><li>${\boldsymbol{\Lambda}^{(t)}}^{-1/2}$ re-scales the principle axes to have the same length.</li><li>$\mathbf{Q}^{(t)}$ transforms the coordinate system back to the original space.</li></ul><p>It means that this transformation makes the expected length of $\mathbf{p}_\sigma^{(t+1)}$ independent of its direction.</p><p>We then update $\sigma^{(t)}$ by according to the ratio of its length with its expected length $\Vert\mathbf{p}_\sigma^{(t+1)}\Vert/\mathbb{E}\Vert\mathcal{N}(\mathbf{0},\mathbf{I})\Vert$, given by
\begin{equation}
\log\sigma^{(t+1)}=\log\sigma^{(t)}+\frac{\alpha_\sigma}{d_\sigma}\left(\frac{\Vert\mathbf{p}_\sigma^{(t+1)}\Vert}{\mathbb{E}\Vert\mathcal{N}(\mathbf{0},\mathbf{I})\Vert}-1\right),
\end{equation}
where $d_\sigma\approx 1$ is the <strong>damping parameter</strong>, which controls the update size. Therefore, since $\sigma^{(t)}>0$, we have the update rule for $\sigma^{(t)}$ is given by
\begin{equation}
\sigma^{(t+1)}=\sigma^{(t)}\exp\left(\frac{\alpha_\sigma}{d_\sigma}\left(\frac{\Vert\mathbf{p}_\sigma^{(t+1)}\Vert}{\mathbb{E}\Vert\mathcal{N}(\mathbf{0},\mathbf{I})\Vert}-1\right)\right)
\end{equation}</p><h2 id=test-on-rast>Testing on Rastrigin function<a hidden class=anchor aria-hidden=true href=#test-on-rast>#</a></h2><p>Let us give the CMA-ES algorithm a try on the <a href=https://en.wikipedia.org/wiki/Rastrigin_function><strong>Rastrigin function</strong></a>, $f:\mathbb{R}^n\to\mathbb{R}$, which is given by
\begin{equation}
f(\mathbf{x})=10 n+\sum_{i=1}^{n}x_i^2-10\cos\left(2\pi x_i\right)
\end{equation}
The global minimum of $f(\mathbf{x})$ is $0$ at $\mathbf{x}=\mathbf{0}$. We will be using the experimental settings given in this <a href=#cmaes-exp>paper</a> proposed by CMA-ES&rsquo;s original author. Each time we end up with a result less than $f_\text{stop}=10^{-10}$, we count it a success run.</p><p>The result obtained is illustrated in the following figure.</p><figure><img src=/images/cma-es/cmaes-rastrigin.png alt="CMA-ES on rastrigin" style=display:block;margin-left:auto;margin-right:auto><figcaption style=text-align:center;font-style:italic><b>Figure 1</b>: Success rate to reach $f_\text{stop}=10^{-10}$ versus population size for Rastrigin function.<br>The code can be found <a href=https://github.com/trunghng/evolution-strategies/blob/main/testing_ground.py target=_blank>here</a></figcaption></figure><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2><p>[1] Nikolaus Hansen. <a href=https://arxiv.org/abs/1604.00772>The CMA Evolution Strategy: A Tutorial</a>. arXiv:1604.00772, 2016.</p><p>[2] Nikolaus Hansen, Youhei Akimoto & Petr Baudis. <a href=https://github.com/CMA-ES/pycma>CMA-ES/pycma on Github</a>. Zenodo, <a href=https://doi.org/10.5281/zenodo.2559634>DOI:10.5281/zenodo.2559634</a>, February 2019.</p><p>[3] <span id=cmaes-exp>Nikolaus Hansen, Stefan Kern. <a href=https://doi.org/10.1007/978-3-540-30217-9_29>Evaluating the CMA Evolution Strategy on Multimodal Test Functions</a>. Parallel Problem Solving from Nature - PPSN VIII. PPSN 2004.</span></p><p>[4] Ha, David. <a href=https://blog.otoro.net/2017/10/29/visual-evolution-strategies/>A Visual Guide to Evolution Strategies</a>. blog.otoro.net, 2017.</p><h2 id=footnotes>Footnotes<a hidden class=anchor aria-hidden=true href=#footnotes>#</a></h2><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>The simplest form of <strong>exponential smoothing</strong> is given by the formula
\begin{align*}
s_0&=x_0 \\ s_t&=\alpha x_t+(1-\alpha)s_{t-1},\hspace{1cm}t>0
\end{align*}
where $0&lt;\alpha&lt;1$ is referred as the <strong>smoothing factor</strong>.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://trunghng.github.io/tags/machine-learning/>machine-learning</a></li><li><a href=https://trunghng.github.io/tags/evolution-strategy/>evolution-strategy</a></li><li><a href=https://trunghng.github.io/tags/neuroevolution/>neuroevolution</a></li></ul><nav class=paginav><a class=prev href=https://trunghng.github.io/posts/reinforcement-learning/policy-gradient/><span class=title>« Prev</span><br><span>Policy Gradient</span></a>
<a class=next href=https://trunghng.github.io/posts/machine-learning/neural-nets/><span class=title>Next »</span><br><span>Neural networks</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share CMA Evolution Strategy on twitter" href="https://twitter.com/intent/tweet/?text=CMA%20Evolution%20Strategy&url=https%3a%2f%2ftrunghng.github.io%2fposts%2fevolution-strategy%2fcma-es%2f&hashtags=machine-learning%2cevolution-strategy%2cneuroevolution"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share CMA Evolution Strategy on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2ftrunghng.github.io%2fposts%2fevolution-strategy%2fcma-es%2f&title=CMA%20Evolution%20Strategy&summary=CMA%20Evolution%20Strategy&source=https%3a%2f%2ftrunghng.github.io%2fposts%2fevolution-strategy%2fcma-es%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share CMA Evolution Strategy on reddit" href="https://reddit.com/submit?url=https%3a%2f%2ftrunghng.github.io%2fposts%2fevolution-strategy%2fcma-es%2f&title=CMA%20Evolution%20Strategy"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share CMA Evolution Strategy on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2ftrunghng.github.io%2fposts%2fevolution-strategy%2fcma-es%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share CMA Evolution Strategy on whatsapp" href="https://api.whatsapp.com/send?text=CMA%20Evolution%20Strategy%20-%20https%3a%2f%2ftrunghng.github.io%2fposts%2fevolution-strategy%2fcma-es%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share CMA Evolution Strategy on telegram" href="https://telegram.me/share/url?text=CMA%20Evolution%20Strategy&url=https%3a%2f%2ftrunghng.github.io%2fposts%2fevolution-strategy%2fcma-es%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2022 <a href=https://trunghng.github.io>Trung's Place</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>