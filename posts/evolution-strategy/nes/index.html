<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Natural Evolution Strategies | Littleroot</title>
<script type=text/x-mathjax-config>
  MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": {availableFonts: []}
  });
</script><script type=text/x-mathjax-config>
    MathJax.Hub.Config({
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
      "HTML-CSS": {availableFonts: []},
      TeX: {
        equationNumbers: { autoNumber: "AMS" },
      },
    });
  </script><script type=text/javascript src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><meta name=keywords content="machine-learning,evolution-strategy,neuroevolution"><meta name=description content="
Natural Evolution Strategies, or NES, are referred to a family of evolution strategies that throughout its generations update a search distribution repeatedly using an estimated gradient of its distribution parameters.
"><meta name=author content="Trung H. Nguyen"><link rel=canonical href=https://trunghng.github.io/posts/evolution-strategy/nes/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.5cfc680b1eeaeef9efbced92d46c2a9e876b72ee14fba85846afc4cff9e6e6f8.css integrity="sha256-XPxoCx7q7vnvvO2S1Gwqnodrcu4U+6hYRq/Ez/nm5vg=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://trunghng.github.io/images/favicon/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://trunghng.github.io/images/favicon/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://trunghng.github.io/images/favicon/favicon-32x32.png><link rel=apple-touch-icon href=https://trunghng.github.io/images/favicon/apple-touch-icon.png><link rel=mask-icon href=https://trunghng.github.io/images/favicon/android-chrome-512x512.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=text/x-mathjax-config>
  MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": {availableFonts: []}
  });
</script><script type=text/x-mathjax-config>
    MathJax.Hub.Config({
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
      "HTML-CSS": {availableFonts: []},
      TeX: {
        equationNumbers: { autoNumber: "AMS" },
      },
    });
  </script><script type=text/javascript src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><style>.post-content{text-align:justify;font-size:15px;font-family:"goudy bookletter 1911",sans-serif}.post-content h1,h2,h3,h4,h5,h6{text-align:left}.post-content a,.post-content a:link,.post-content a:visited,.post-content a:hover,.post-content a:active{box-shadow:none;font-weight:700;color:#4682b4}.post-content ol,.post-content ul{margin-left:10px}.post-content li>ol,.post-content li>ul{margin-left:30px}#roman-list,#number-list,#alpha-list{counter-reset:section;margin-bottom:10px}#roman-list>li{list-style:none;position:relative}#number-list>li{list-style:none;position:relative}#alpha-list>li{list-style:none;position:relative}#roman-list>li:before{counter-increment:section;content:"(" counter(section,lower-roman)") ";position:absolute;left:-2em}#number-list>li:before{counter-increment:section;content:"(" counter(section,decimal)") ";position:absolute;left:-2em}#alpha-list>li:before{counter-increment:section;content:"(" counter(section,lower-alpha)") ";position:absolute;left:-2em}.toc{font-size:15px}.post-footer{font-size:15px}.post-content figure>img{display:block;margin-left:auto;margin-right:auto}.post-content figure>figcaption{all:revert;text-align:justify;font-size:12px;font-style:italic;width:70%;margin-left:15%}.post-content figure>figcaption>p{all:revert}.post-content h3{font-size:28px}.post-content h4{font-size:24px}.post-content h5{font-size:20px}.post-content h6{font-size:16px}</style><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="Natural Evolution Strategies"><meta property="og:description" content="
Natural Evolution Strategies, or NES, are referred to a family of evolution strategies that throughout its generations update a search distribution repeatedly using an estimated gradient of its distribution parameters.
"><meta property="og:type" content="article"><meta property="og:url" content="https://trunghng.github.io/posts/evolution-strategy/nes/"><meta property="og:image" content="https://trunghng.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-10-07T13:00:00+07:00"><meta property="article:modified_time" content="2022-10-07T13:00:00+07:00"><meta property="og:site_name" content="Littleroot"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://trunghng.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Natural Evolution Strategies"><meta name=twitter:description content="
Natural Evolution Strategies, or NES, are referred to a family of evolution strategies that throughout its generations update a search distribution repeatedly using an estimated gradient of its distribution parameters.
"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://trunghng.github.io/posts/"},{"@type":"ListItem","position":3,"name":"Natural Evolution Strategies","item":"https://trunghng.github.io/posts/evolution-strategy/nes/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Natural Evolution Strategies","name":"Natural Evolution Strategies","description":" Natural Evolution Strategies, or NES, are referred to a family of evolution strategies that throughout its generations update a search distribution repeatedly using an estimated gradient of its distribution parameters.\n","keywords":["machine-learning","evolution-strategy","neuroevolution"],"articleBody":" Natural Evolution Strategies, or NES, are referred to a family of evolution strategies that throughout its generations update a search distribution repeatedly using an estimated gradient of its distribution parameters.\nSearch gradients Usually when working on Evolution Strategy methods, we select some candidate solutions, which generate better fitness values than the other ones, to be parents of the next generation. This means, majority of solution samples have been wasted since they may contain some useful information.\nTo utilize the use all fitness samples, the NES uses search gradients in updating the parameters for the search distribution.\nLet $\\mathbf{z}\\in\\mathbb{R}^n$ denote the solution sampled from the distribution $\\pi(\\mathbf{z},\\theta)$ and let $f:\\mathbb{R}^n\\to\\mathbb{R}$ be the fitness (or objective) function. The expected fitness value is then given by \\begin{equation} J(\\theta)=\\mathbb{E}_\\theta[f(\\mathbf{z})]=\\int f(\\mathbf{z})\\pi(\\mathbf{z}\\vert\\theta)\\hspace{0.1cm}d\\mathbf{z}\\label{eq:sg.1} \\end{equation} Taking the gradient of the above function w.r.t $\\theta$ using the log-likelihood trick as in REINFORCE gives us \\begin{align} \\nabla_\\theta J(\\theta)\u0026=\\nabla_\\theta\\int f(\\mathbf{z})\\pi(\\mathbf{z}\\vert\\theta)\\hspace{0.1cm}d\\mathbf{z} \\\\ \u0026=\\int f(\\mathbf{z})\\nabla_\\theta\\pi(\\mathbf{z}\\vert\\theta)\\hspace{0.1cm}d\\mathbf{z} \\\\ \u0026=\\int f(\\mathbf{z})\\nabla_\\theta\\pi(\\mathbf{z}\\vert\\theta)\\frac{\\pi(\\mathbf{z}\\vert\\theta)}{\\pi(\\mathbf{z}\\vert\\theta)}\\hspace{0.1cm}d\\mathbf{z} \\\\ \u0026=\\int\\left[f(\\mathbf{z})\\nabla_\\theta\\log\\pi(\\mathbf{z}\\vert\\theta)\\right]\\pi(\\mathbf{z}\\vert\\theta)\\hspace{0.1cm}d\\mathbf{z} \\\\ \u0026=\\mathbb{E}_\\theta\\left[f(\\mathbf{z})\\nabla_\\theta\\log\\pi(\\mathbf{z}\\vert\\theta)\\right] \\end{align} Using Monte Carlo method, given samples $\\mathbf{z}_1,\\ldots,\\mathbf{z}_\\lambda$ from the population of size $\\lambda$, the search gradient is then can be approximated by \\begin{equation} \\nabla_\\theta J(\\theta)\\approx\\frac{1}{\\lambda}\\sum_{k=1}^{\\lambda}f(\\mathbf{z}_k)\\nabla_\\theta\\log\\pi(\\mathbf{z}_k\\vert\\theta)\\label{eq:sg.2} \\end{equation} Given this gradient w.r.t $\\theta$, we then can use a gradient-based method to repeatedly update the parameter $\\theta$ in order to give us a more desired search distribution. In particular, we can use such as SGD method \\begin{equation} \\theta\\leftarrow\\theta+\\alpha\\nabla_\\theta J(\\theta),\\label{eq:sg.3} \\end{equation} where $\\alpha$ is the learning rate.\nSearch gradients for MVN Consider the case that our search distribution $\\pi(\\mathbf{z}\\vert\\theta)$ is in form of a Multivariate Normal distribution, $\\mathbf{z}\\sim\\mathcal{N}(\\boldsymbol{\\mu},\\boldsymbol{\\Sigma})$, where $\\boldsymbol{\\mu}\\in\\mathbb{R}^n$ and $\\boldsymbol{\\Sigma}\\in\\mathbb{R}^{n\\times n}$.\nIn this case $\\theta=(\\boldsymbol{\\mu},\\boldsymbol{\\Sigma})$ denotes a tuple of parameters for the search distribution, which is given by \\begin{equation} \\pi(\\mathbf{z}\\vert\\theta)=\\frac{1}{(2\\pi)^{n/1}\\left\\vert\\boldsymbol{\\Sigma}\\right\\vert^{1/2}}\\exp\\left[-\\frac{1}{2}\\left(\\mathbf{z}-\\boldsymbol{\\mu}\\right)^\\text{T}\\boldsymbol{\\Sigma}^{-1}\\left(\\mathbf{z}-\\boldsymbol{\\mu}\\right)\\right] \\end{equation} Taking natural logarithm of both sides then gives us \\begin{align} \\log\\pi(\\mathbf{z}\\vert\\theta)\u0026=\\log\\left(\\frac{1}{(2\\pi)^{n/1}\\left\\vert\\boldsymbol{\\Sigma}\\right\\vert^{1/2}}\\exp\\left[-\\frac{1}{2}\\left(\\mathbf{z}-\\boldsymbol{\\mu}\\right)^\\text{T}\\boldsymbol{\\Sigma}^{-1}\\left(\\mathbf{z}-\\boldsymbol{\\mu}\\right)\\right]\\right) \\\\ \u0026=-\\frac{n}{2}\\log(2\\pi)-\\frac{1}{2}\\log\\vert\\boldsymbol{\\Sigma}\\vert-\\frac{1}{2}\\left(\\mathbf{z}-\\boldsymbol{\\mu}\\right)^\\text{T}\\boldsymbol{\\Sigma}^{-1}\\left(\\mathbf{z}-\\boldsymbol{\\mu}\\right) \\end{align} We continue by differentiating the above log-likelihood w.r.t $\\boldsymbol{\\mu}$ and $\\boldsymbol{\\Sigma}$. Starting with $\\boldsymbol{\\mu}$, the gradient is given by \\begin{align} \\nabla_\\boldsymbol{\\mu}\\log\\pi(\\mathbf{z}\\vert\\theta)\u0026=\\nabla_\\boldsymbol{\\mu}\\left(-\\frac{n}{2}\\log(2\\pi)-\\frac{1}{2}\\log\\vert\\boldsymbol{\\Sigma}\\vert-\\frac{1}{2}\\left(\\mathbf{z}-\\boldsymbol{\\mu}\\right)^\\text{T}\\boldsymbol{\\Sigma}^{-1}\\left(\\mathbf{z}-\\boldsymbol{\\mu}\\right)\\right) \\\\ \u0026=-\\frac{1}{2}\\nabla_\\boldsymbol{\\mu}\\left(\\mathbf{z}-\\boldsymbol{\\mu}\\right)^\\text{T}\\boldsymbol{\\Sigma}^{-1}\\left(\\mathbf{z}-\\boldsymbol{\\mu}\\right) \\\\ \u0026=\\boldsymbol{\\Sigma}^{-1}(\\mathbf{z}-\\boldsymbol{\\mu}) \\end{align} And the gradient w.r.t $\\boldsymbol{\\Sigma}$ is computed as \\begin{align} \\nabla_\\boldsymbol{\\Sigma}\\pi(\\mathbf{z}\\vert\\theta)\u0026=\\nabla_\\boldsymbol{\\Sigma}\\left(-\\frac{n}{2}\\log(2\\pi)-\\frac{1}{2}\\log\\vert\\boldsymbol{\\Sigma}\\vert-\\frac{1}{2}\\left(\\mathbf{z}-\\boldsymbol{\\mu}\\right)^\\text{T}\\boldsymbol{\\Sigma}^{-1}\\left(\\mathbf{z}-\\boldsymbol{\\mu}\\right)\\right) \\\\ \u0026=-\\frac{1}{2}\\nabla_\\boldsymbol{\\Sigma}\\left(\\mathbf{z}-\\boldsymbol{\\mu}\\right)^\\text{T}\\boldsymbol{\\Sigma}^{-1}\\left(\\mathbf{z}-\\boldsymbol{\\mu}\\right) \\\\ \u0026=\\frac{1}{2}\\boldsymbol{\\Sigma}^{-1}\\left(\\mathbf{z}-\\boldsymbol{\\mu}\\right)\\left(\\mathbf{z}-\\boldsymbol{\\mu}\\right)^\\text{T}\\boldsymbol{\\Sigma}^{-1}-\\frac{1}{2}\\boldsymbol{\\Sigma}^{-1} \\end{align} The SGD update \\eqref{eq:sg.3} now is applied for each of $\\boldsymbol{\\mu}$ and $\\boldsymbol{\\Sigma}$ as \\begin{align} \\boldsymbol{\\mu}\u0026\\leftarrow\\boldsymbol{\\mu}+\\alpha\\nabla_\\boldsymbol{\\mu}J(\\theta) \\\\ \u0026\\leftarrow\\boldsymbol{\\mu}+\\alpha\\frac{1}{\\lambda}\\sum_{k=1}^{\\lambda}\\boldsymbol{\\Sigma}^{-1}\\left(\\mathbf{z}_k-\\boldsymbol{\\mu}\\right)f(\\mathbf{z}_k) \\end{align} and \\begin{align} \\boldsymbol{\\Sigma}\u0026\\leftarrow\\boldsymbol{\\Sigma}+\\alpha\\nabla_\\boldsymbol{\\Sigma}J(\\theta) \\\\ \u0026\\leftarrow\\boldsymbol{\\Sigma}+\\alpha\\frac{1}{\\lambda}\\sum_{k=1}^{\\lambda}\\left[\\frac{1}{2}\\boldsymbol{\\Sigma}^{-1}\\left(\\mathbf{z}_k-\\boldsymbol{\\mu}\\right)\\left(\\mathbf{z}_k-\\boldsymbol{\\mu}\\right)^\\text{T}\\boldsymbol{\\Sigma}^{-1}-\\frac{1}{2}\\boldsymbol{\\Sigma}^{-1}\\right]f(\\mathbf{z}_k) \\end{align}\nNatural gradient The natural gradient searches for the direction based on the distance between distributions $\\pi(\\mathbf{z}\\vert\\theta)$ and $\\pi(\\mathbf{z}\\vert\\theta’)$. One natural measure of distance between probability distributions is the Kullback-Leibler divergence, or KL divergence.\nIn other words, our work is to look for the direction of updating gradient, denoted as $\\delta\\theta$, such that \\begin{align} \\max_{\\delta\\theta}\u0026\\hspace{0.1cm}J(\\theta+\\delta\\theta)\\approx J(\\theta)+\\delta\\theta^\\text{T}\\nabla_\\theta J \\\\ \\text{s.t.}\u0026\\hspace{0.1cm}D_\\text{KL}(\\theta\\Vert\\theta+\\delta\\theta)=\\varepsilon, \\end{align} where $J(\\theta)$ is given as in \\eqref{eq:sg.1}; $\\varepsilon$ is a small increment size; and where $D_\\text{KL}(\\theta\\Vert\\theta+\\delta\\theta)$ is the KL divergence of $\\pi(\\mathbf{z}\\vert\\theta)$ from $\\pi(\\mathbf{z}\\vert\\theta+\\delta\\theta)$, defined as \\begin{align} D_\\text{KL}(\\theta\\Vert\\theta+\\delta\\theta)\u0026=\\int\\pi(\\mathbf{z}\\vert\\theta)\\log\\frac{\\pi(\\mathbf{z}\\vert\\theta)}{\\pi(\\mathbf{z}\\vert\\theta+\\delta\\theta)}\\hspace{0.1cm}d\\mathbf{z} \\\\ \u0026=\\mathbb{E}_{\\theta}\\big[\\log\\pi(\\mathbf{z}\\vert\\theta)-\\log\\pi(\\mathbf{z}\\vert\\theta+\\delta)\\big]\\label{eq:ng.1} \\end{align} As $\\delta\\theta\\to 0$, or in other words, consider the Taylor expansion of \\eqref{eq:ng.1} about $\\delta\\theta=0$, we have \\begin{align} \u0026D_\\text{KL}(\\theta\\Vert\\theta+\\delta\\theta)\\nonumber \\\\ \u0026=\\mathbb{E}_{\\theta}\\big[\\log\\pi(\\mathbf{z}\\vert\\theta)-\\log\\pi(\\mathbf{z}\\vert\\theta+\\delta\\theta)\\big] \\\\ \u0026\\approx\\mathbb{E}_\\theta\\left[\\log\\pi(\\mathbf{z}\\vert\\theta)-\\left(\\log\\pi(\\mathbf{z}\\vert\\theta)+\\delta\\theta^\\text{T}\\frac{\\nabla_\\theta\\pi(\\mathbf{z}\\vert\\theta)}{\\pi(\\mathbf{z}\\vert\\theta)}+\\frac{1}{2}\\delta\\theta^\\text{T}\\frac{\\nabla_\\theta^2\\pi(\\mathbf{z}\\vert\\theta)}{\\pi(\\mathbf{z}\\vert\\theta)}\\delta\\theta\\right)\\right] \\\\ \u0026=-\\mathbb{E}_\\theta\\left[\\delta\\theta^\\text{T}\\nabla_\\theta\\log\\pi(\\mathbf{z}\\vert\\theta)+\\frac{1}{2}\\delta\\theta^\\text{T}\\nabla_\\theta^2\\log\\pi(\\mathbf{z}\\vert\\theta)\\delta\\theta\\right] \\\\ \u0026=-\\mathbb{E}_\\theta\\Big[\\delta\\theta^\\text{T}\\nabla_\\theta\\log\\pi(\\mathbf{z}\\vert\\theta)\\Big]-\\mathbb{E}_\\theta\\left[\\frac{1}{2}\\delta\\theta^\\text{T}\\nabla_\\theta^2\\log\\pi(\\mathbf{z}\\vert\\theta)\\delta\\theta\\right] \\\\ \u0026\\overset{\\text{(i)}}{=}-\\frac{1}{2}\\delta\\theta^\\text{T}\\mathbb{E}_\\theta\\Big[\\nabla_\\theta^2\\log\\pi(\\mathbf{z}\\vert\\theta)\\Big]\\delta\\theta \\\\ \u0026\\overset{\\text{(ii)}}{=}\\frac{1}{2}\\delta\\theta^\\text{T}\\mathbb{E}_\\theta\\Big[\\nabla_\\theta\\log\\pi(\\mathbf{z}\\vert\\theta)\\nabla_\\theta\\log\\pi(\\mathbf{z}\\vert\\theta)^\\text{T}\\Big]\\delta\\theta \\\\ \u0026\\overset{\\text{(iii)}}{=}\\frac{1}{2}\\delta\\theta^\\text{T}\\mathbf{F}\\delta\\theta\\label{eq:ng.2} \\end{align} where\nIn this step, we have used \\begin{align} \\mathbb{E}_\\theta\\Big[\\delta\\theta^\\text{T}\\nabla_\\theta\\log\\pi(\\mathbf{z}\\vert\\theta)\\Big]\u0026=\\delta\\theta^\\text{T}\\int\\pi(\\mathbf{z}\\vert\\theta)\\nabla_\\theta\\log\\pi(\\mathbf{z}\\vert\\theta)\\hspace{0.1cm}d\\mathbf{z} \\\\ \u0026=\\delta\\theta^\\text{T}\\int\\pi(\\mathbf{z}\\vert\\theta)\\frac{1}{\\pi(\\mathbf{z}\\vert\\theta)}\\nabla_\\theta\\pi(\\mathbf{z}\\vert\\theta)\\hspace{0.1cm}d\\mathbf{z} \\\\ \u0026=\\delta\\theta^\\text{T}\\nabla_\\theta\\int\\pi(\\mathbf{z}\\vert\\theta)\\hspace{0.1cm}d\\mathbf{z} \\\\ \u0026=\\delta\\theta^\\text{T}\\nabla_\\theta 1=0 \\end{align} In this step, let $\\theta_j,\\theta_k$ denote the $j$-th and $k$-th element of $\\theta$ respectively. The $(j,k)$ element of the Hessian $\\nabla_\\theta^2\\log\\pi(\\mathbf{z}\\vert\\theta)$ thus, by chain rule, can be computed as \\begin{align} \\hspace{-1.7cm}\\frac{\\partial^2}{\\partial\\theta_j\\partial\\theta_k}\\log\\pi(\\mathbf{z}\\vert\\theta)\u0026=\\frac{\\partial}{\\partial\\theta_j}\\left(\\frac{\\partial\\log\\pi(\\mathbf{z}\\vert\\theta)}{\\partial\\theta_k}\\right) \\\\ \u0026=\\frac{\\partial}{\\partial\\theta_j}\\left(\\frac{1}{\\pi(\\mathbf{z}\\vert\\theta)}\\cdot\\frac{\\partial\\pi(\\mathbf{z}\\vert\\theta)}{\\partial\\theta_k}\\right) \\\\ \u0026=\\frac{\\partial}{\\partial\\theta_j}\\left(\\frac{1}{\\pi(\\mathbf{z} \\vert\\theta)}\\right)\\cdot\\frac{\\partial\\pi(\\mathbf{z}\\vert\\theta)}{\\partial\\theta_k}+\\frac{1}{\\pi(\\mathbf{z}\\vert\\theta)}\\cdot\\frac{\\partial^2\\pi(\\mathbf{z}\\vert\\theta)}{\\partial\\theta_j\\partial\\theta_k} \\\\ \u0026=\\left(\\frac{\\partial\\frac{1}{\\pi(\\mathbf{z}\\vert\\theta)}}{\\partial\\pi(\\mathbf{z}\\vert\\theta)}\\cdot\\frac{\\partial\\pi(\\mathbf{z}\\vert\\theta)}{\\partial\\theta_j}\\right)\\cdot\\frac{\\partial\\pi(\\mathbf{z}\\vert\\theta)}{\\partial\\theta_k}+\\frac{1}{\\pi(\\mathbf{z}\\vert\\theta)}\\cdot\\frac{\\partial^2\\pi(\\mathbf{z}\\vert\\theta)}{\\partial\\theta_j\\partial\\theta_k} \\\\ \u0026=-\\frac{1}{\\pi(\\mathbf{z}\\vert\\theta)^2}\\cdot\\frac{\\partial\\pi(\\mathbf{z}\\vert\\theta)}{\\partial\\theta_j}\\cdot\\frac{\\partial\\pi(\\mathbf{z}\\vert\\theta)}{\\partial\\theta_k}+\\frac{1}{\\pi(\\mathbf{z}\\vert\\theta)}\\cdot\\frac{\\partial^2\\pi(\\mathbf{z}\\vert\\theta)}{\\partial\\theta_j\\partial\\theta_k} \\\\ \u0026=-\\frac{\\partial\\log\\pi(\\mathbf{z}\\vert\\theta)}{\\partial\\theta_j}\\cdot\\frac{\\partial\\log\\pi(\\mathbf{z}\\vert\\theta)}{\\partial\\theta_k}+\\frac{1}{\\pi(\\mathbf{z}\\vert\\theta)}\\cdot\\frac{\\partial^2\\pi(\\mathbf{z}\\vert\\theta)}{\\partial\\theta_j\\partial\\theta_k}, \\end{align} which implies that \\begin{equation} \\nabla_\\theta^2\\log\\pi(\\mathbf{z}\\vert\\theta)=-\\nabla_\\theta\\log\\pi(\\mathbf{z}\\vert\\theta)\\nabla_\\theta\\log\\pi(\\mathbf{z}\\vert\\theta)^\\text{T}+\\frac{1}{\\pi(\\mathbf{z}\\vert\\theta)}\\nabla_\\theta^2\\pi(\\mathbf{z}\\vert\\theta) \\end{equation} Taking expectation on both sides gives us \\begin{align} \\hspace{-1cm}\\mathbb{E}_\\theta\\Big[\\nabla_\\theta^2\\log\\pi(\\mathbf{z}\\vert\\theta)\\Big]\u0026=-\\mathbb{E}_\\theta\\Big[\\nabla_\\theta\\log\\pi(\\mathbf{z}\\vert\\theta)\\nabla_\\theta\\log\\pi(\\mathbf{z}\\vert\\theta)^\\text{T}\\Big]+\\mathbb{E}_\\theta\\left[\\frac{1}{\\pi(\\mathbf{z}\\vert\\theta)}\\nabla_\\theta^2\\pi(\\mathbf{z}\\vert\\theta)\\right]\\label{eq:ng.5} \\\\ \u0026=-\\mathbb{E}_\\theta\\Big[\\nabla_\\theta\\log\\pi(\\mathbf{z}\\vert\\theta)\\nabla_\\theta\\log\\pi(\\mathbf{z}\\vert\\theta)^\\text{T}\\Big], \\end{align} where the latter expectation in \\eqref{eq:ng.5} has been absorbed due to \\begin{align} \\mathbb{E}_\\theta\\left[\\frac{1}{\\pi(\\mathbf{z}\\vert\\theta)}\\nabla_\\theta^2\\pi(\\mathbf{z}\\vert\\theta)\\right]\u0026=\\int\\nabla_\\theta^2\\pi(\\mathbf{z}\\vert\\theta)\\,d\\mathbf{z} \\\\ \u0026=\\nabla_\\theta^2\\int\\pi(\\mathbf{z}\\vert\\theta)\\,d\\mathbf{z} \\\\ \u0026=\\nabla_\\theta^2 1=\\mathbf{0} \\end{align} The matrix $\\mathbf{F}$ is referred as the Fisher information matrix of the given parametric family of search distributions, defined as \\begin{align} \\mathbf{F}\u0026=\\mathbb{E}_\\theta\\Big[\\nabla_\\theta\\log\\pi(\\mathbf{z}\\vert\\theta)\\nabla_\\theta\\log\\pi(\\mathbf{z}\\vert\\theta)^\\text{T}\\Big] \\\\ \u0026=\\int\\pi(\\mathbf{z}\\vert\\theta)\\nabla_\\theta\\log\\pi(\\mathbf{z}\\vert\\theta)\\nabla_\\theta\\log\\pi(\\mathbf{z}\\vert\\theta)^\\text{T}\\hspace{0.1cm}d\\mathbf{z} \\end{align} Hence, we have the Lagrangian of our constrained optimization problem is \\begin{align} \\mathcal{L}(\\theta,\\delta\\theta,\\lambda)\u0026=J(\\theta)+\\delta\\theta^\\text{T}\\nabla_\\theta J(\\theta)+\\lambda\\big(\\varepsilon-D_\\text{KL}(\\theta\\Vert\\theta+\\delta\\theta)\\big) \\\\ \u0026=J(\\theta)+\\delta\\theta^\\text{T}\\nabla_\\theta J(\\theta)+\\lambda\\left(\\varepsilon-\\frac{1}{2}\\delta\\theta^\\text{T}\\mathbf{F}\\delta\\theta\\right), \\end{align} where $\\lambda\u003e0$ is the Lagrange multiplier.\nIt is easily seen that $\\mathbf{F}$ is symmetric, thus taking the gradient of the Lagrangian w.r.t $\\delta\\theta$ and setting it to zero gives us \\begin{equation} \\lambda\\mathbf{F}\\delta\\theta=\\nabla_\\theta J(\\theta) \\end{equation} If the Fisher information matrix $\\mathbf{F}$ is invertible, the solution for $\\delta\\theta$ that maximizes $\\mathcal{L}$ then can be computed as \\begin{equation} \\delta\\theta=\\frac{1}{\\lambda}\\mathbf{F}^{-1}\\nabla_\\theta J(\\theta),\\label{eq:ng.3} \\end{equation} which defines the direction of the natural gradient $\\tilde{\\nabla}_\\theta J(\\theta)$. Since $\\lambda\u003e0$ we therefore obtain \\begin{equation} \\tilde{\\nabla}_\\theta J(\\theta)=\\mathbf{F}^{-1}\\nabla_\\theta J(\\theta) \\end{equation} Continue with the value of $\\delta\\theta$ given in \\eqref{eq:ng.3}, the dual function of our optimization is given as \\begin{align} g(\\lambda)\u0026=J(\\theta)+\\frac{1}{\\lambda}\\nabla_\\theta J(\\theta)^\\text{T}\\mathbf{F}^{-1}\\nabla_\\theta J(\\theta)-\\frac{1}{2}\\frac{\\lambda}{\\lambda^2}\\nabla_\\theta J(\\theta)^\\text{T}\\mathbf{F}^{-1}\\mathbf{F}\\mathbf{F}^{-1}\\nabla_\\theta J(\\theta)+\\lambda\\varepsilon \\\\ \u0026=J(\\theta)+\\frac{1}{2}\\lambda^{-1}\\nabla_\\theta J(\\theta)^\\text{T}\\mathbf{F}^{-1}\\nabla_\\theta J(\\theta)+\\lambda\\varepsilon \\end{align} Taking the gradient of $g$ w.r.t $\\lambda$ and setting it to zero and since $\\varepsilon\u003e0$ small gives us the solution for $\\lambda$, which is \\begin{equation} \\lambda=\\sqrt{\\frac{\\nabla_\\theta J(\\theta)^\\text{T}\\mathbf{F}^{-1}\\nabla_\\theta J(\\theta)}{\\varepsilon}}, \\end{equation} Hence, the SGD update for the parameter $\\theta$ using natural gradient is \\begin{equation} \\theta\\leftarrow\\theta+\\eta\\tilde{\\nabla}_\\theta J(\\theta)=\\theta+\\eta\\mathbf{F}^{-1}\\nabla_\\theta J(\\theta),\\label{eq:ng.4} \\end{equation} where $\\eta$ is the learning rate, given as \\begin{equation} \\eta=\\lambda^{-1}=\\sqrt{\\frac{\\varepsilon}{\\nabla_\\theta J(\\theta)^\\text{T}\\mathbf{F}^{-1}\\nabla_\\theta J(\\theta)}} \\end{equation} This learning rate can also be replaced by a more desirable one without changing the direction of our update. With this update rule for natural gradient, we obtain the general formulation of NES, as described in the following pseudocode.\nRobustness techniques Fitness shaping NES uses the so-called fitness shaping technique, which helps to avoid early convergence due to the possible affection of outliers fitness value in \\eqref{eq:sg.2}, e.g. there may exist an outlier whose fitness value, says $f(\\mathbf{z}_i)$, is much greater than other solutions’ ones, $\\{f(\\mathbf{z}_k)\\}_{k\\neq i}$.\nRather than using fitness values $f(\\mathbf{z}_k)$ in approximating the gradient in \\eqref{eq:sg.2}, fitness shaping instead applies a rank-based transformation of $f(\\mathbf{z}_k)$.\nIn particular, let $\\mathbf{z}_{k:\\lambda}$ denote the $k$-th best sample out of the population of size $\\lambda$, $\\mathbf{z}_1,\\ldots,\\mathbf{z}_\\lambda$, i.e. $f(\\mathbf{z}_{1:\\lambda})\\geq\\ldots\\geq f(\\mathbf{z}_{\\lambda:\\lambda})$, the gradient estimate \\eqref{eq:sg.2} now is rewritten as \\begin{equation} \\nabla_\\theta J(\\theta)=\\sum_{k=1}^{\\lambda}u_k\\nabla_\\theta\\log\\pi(\\mathbf{z}_{k:\\lambda}\\vert\\theta),\\label{eq:fs.1} \\end{equation} where $u_1\\geq\\ldots\\geq u_\\lambda$ are referred as utility values, which are preserved-order transformations of $f(\\mathbf{z}_{1:\\lambda}),\\ldots,f(\\mathbf{z}_{\\lambda:\\lambda})$.\nThe choice for utility function $u$ is a free parameter of the algorithm. In the original paper, the author proposed \\begin{equation} u_k=\\frac{\\max\\left(0,\\log\\left(\\frac{\\lambda}{2}+1\\right)-\\log k\\right)}{\\sum_{j=1}^{\\lambda}\\max\\left(0,\\log\\left(\\frac{\\lambda}{2}+1\\right)-\\log j\\right)}-\\frac{1}{\\lambda} \\end{equation}\nAdaption sampling Beside fitness shaping, NES also applies another heuristic, called adaption sampling, to make the performance more robustly. This technique lets the algorithm determine the appropriate hyperparameters (in this case, NES chooses the learning rate $\\eta$ be the one to adapt) more quickly.\nIn particular, for a successive parameter $\\theta’$ of $\\theta$, the corresponding learning rate $\\eta$ used in its update \\eqref{eq:ng.4} will be determined by comparing samples $\\mathbf{z}’$ sampled from $\\pi_\\theta’$ with samples $\\mathbf{z}$ sampled from $\\pi_\\theta$ according to a Mann-Whitney U-test.\nRotationally-symmetric distributions The rotationally-symmetric distributions, or radial distributions refer to class of distributions $p(\\mathbf{x})$ such that \\begin{equation} p(\\mathbf{x})=p(\\mathbf{U}\\mathbf{x}),\\label{eq:rsd.1} \\end{equation} for all $\\mathbf{x}\\in\\mathbb{R}^n$ and for all orthogonal matrices $\\mathbf{U}\\in\\mathbb{R}^{n\\times n}$.\nLet $Q_\\boldsymbol{\\tau}(\\mathbf{z})$ be a family of rotationally-symmetric distributions in $\\mathbb{R}^n$ parameterized by $\\boldsymbol{\\tau}$. The property \\eqref{eq:rsd.1} allows us to represent $Q_\\boldsymbol{\\tau}(\\mathbf{z})$ as \\begin{equation} Q_\\boldsymbol{\\tau}(\\mathbf{z})=q_\\boldsymbol{\\tau}(\\Vert\\mathbf{z}\\Vert^2), \\end{equation} for some family of functions $q_\\boldsymbol{\\tau}:\\mathbb{R}_+\\to\\mathbb{R}_+$.\nConsider the classes of search distributions in a form of \\begin{align} \\pi(\\mathbf{z}\\vert\\boldsymbol{\\mu},\\boldsymbol{\\Sigma},\\boldsymbol{\\tau})\u0026=\\frac{1}{\\vert\\mathbf{A}\\vert}q_\\boldsymbol{\\tau}\\left(\\left\\Vert(\\mathbf{A}^{-1})^\\text{T}(\\mathbf{z}-\\boldsymbol{\\mu})\\right\\Vert^2\\right) \\\\ \u0026=\\frac{1}{\\left\\vert\\mathbf{A}^\\text{T}\\mathbf{A}\\right\\vert^{1/2}}q_\\boldsymbol{\\tau}\\left((\\mathbf{z}-\\boldsymbol{\\mu})^\\text{T}(\\mathbf{A}^\\text{T}\\mathbf{A})^{-1}(\\mathbf{z}-\\boldsymbol{\\mu})\\right),\\label{eq:rsd.2} \\end{align} with additional transformation parameters $\\boldsymbol{\\mu}\\in\\mathbb{R}^n$ and invertible matrices $\\mathbf{A}\\in\\mathbb{R}^{n\\times n}$.\nIt can be seen that Gaussian and its multivariate form, MVN, can be written in form of $\\eqref{eq:rsd.2}$, and thus are members of these classes of distributions.\nExponential parameterization By \\eqref{eq:ng.4}, the natural gradient update for a multivariate Gaussian search distribution, denoted $\\mathcal{N}(\\boldsymbol{\\mu},\\boldsymbol{\\Sigma})$, is \\begin{align} \\boldsymbol{\\mu}\u0026\\leftarrow\\boldsymbol{\\mu}+\\eta\\mathbf{F}^{-1}\\nabla_\\boldsymbol{\\mu} J(\\boldsymbol{\\mu},\\boldsymbol{\\Sigma}), \\\\ \\boldsymbol{\\Sigma}\u0026\\leftarrow\\boldsymbol{\\Sigma}+\\eta\\mathbf{F}^{-1}\\nabla_\\boldsymbol{\\Sigma} J(\\boldsymbol{\\mu},\\boldsymbol{\\Sigma}) \\end{align} Thus, in updating the covariance matrix $\\boldsymbol{\\Sigma}$ as above, we have to ensure that $\\boldsymbol{\\Sigma}+\\eta\\mathbf{F}^{-1}\\nabla_\\boldsymbol{\\Sigma} J(\\boldsymbol{\\mu},\\boldsymbol{\\Sigma})$ is symmetric positive definite.\nTo accomplish this, we may represent the covariance matrix using the exponential parameterization for symmetric matrices. In particular, let \\begin{equation} \\mathcal{S}_n\\doteq\\{\\mathbf{M}\\in\\mathbb{R}^{n\\times n}:\\mathbf{M}=\\mathbf{M}^\\text{T}\\} \\end{equation} denote the set of symmetric matrices of $\\mathbb{R}^{n\\times n}$ and let \\begin{equation} \\mathcal{P}_n\\doteq\\{\\mathbf{M}\\in\\mathcal{S}_n:\\mathbf{M}\\succ 0\\} \\end{equation} represent the cone of symmetric positive definite matrices of $\\mathbb{R}^{n\\times n}$.\nUsing Taylor expansion for the exponential function, we then have the exponential map $\\exp:\\mathcal{S}_n\\to\\mathcal{P}_n$ can be written as \\begin{equation} \\exp(\\mathbf{M})=\\sum_{i=0}^{\\infty}\\frac{\\mathbf{M}^i}{i!},\\label{eq:ep.1} \\end{equation} which is diffeomorphism, i.e. the map is bijective, plus the map and its inverse map, $\\log:\\mathcal{P}_n\\to\\mathcal{S}_n$, both are differentiable.\nTherefore, we can represent the covariance matrix $\\boldsymbol{\\Sigma}\\in\\mathcal{P}_n$ as \\begin{equation} \\boldsymbol{\\Sigma}=\\exp(\\mathbf{M}),\\hspace{2cm}\\mathbf{M}\\in\\mathcal{S}_n \\end{equation} This representation lets the gradient update always end up as a valid covariance matrix. However, the computation for the Fisher information matrix $\\mathbf{F}$ is consequently more complicated due to require partial derivatives of matrix exponential \\eqref{eq:ep.1}.\nExponential local coordinates It is noticeable from \\eqref{eq:rsd.2} that the dependency of the distribution on $\\mathbf{A}$ is only in terms of $\\mathbf{A}^\\text{T}\\mathbf{A}$, which is a symmetric positive semi-definite matrix since for all non-zero vector $\\mathbf{x}\\in\\mathbb{R}^n$ we have \\begin{equation} \\mathbf{x}^\\text{T}\\mathbf{A}^\\text{T}\\mathbf{A}\\mathbf{x}=\\Vert\\mathbf{A}\\mathbf{x}\\Vert^2\\geq 0 \\end{equation} In the case of MVN, this matrix corresponds to the covariance matrix.\nTherefore, rather than using exponential mapping in updating the positive definite matrices $\\mathbf{A}^\\text{T}\\mathbf{A}$, we repeatedly linear transform the coordinate system in each iteration to a coordinate system in which the calculation for $\\mathbf{F}$ is trivial.\nSpecifically, let the current search distribution be given by $(\\boldsymbol{\\mu},\\mathbf{A})$, we use exponential local coordinates \\begin{equation} (\\boldsymbol{\\delta},\\mathbf{M})\\mapsto(\\boldsymbol{\\mu}_\\text{new},\\mathbf{A}_\\text{new})=\\left(\\boldsymbol{\\mu}+\\mathbf{A}^\\text{T}\\boldsymbol{\\delta},\\mathbf{A}\\exp\\left(\\frac{1}{2}\\mathbf{M}\\right)\\right) \\end{equation} This coordinate system is local in the sense that the coordinates $(\\boldsymbol{\\delta},\\mathbf{M})=(\\mathbf{0},\\mathbf{0})$ is mapped to $(\\boldsymbol{\\mu},\\mathbf{A})$.\nFor the case that $\\tau\\in\\mathbb{R}^{n’}$, $\\boldsymbol{\\delta}\\in\\mathbb{R}^n$ and $\\mathbf{M}\\in\\mathbb{R}^{n(n+1)/2}$, the Fisher information matrix $\\mathbf{F}$ in this coordinate system is an $m\\times m$ matrix, where \\begin{equation} m=n+\\frac{n(n+1)}{2}+n’=\\frac{n(n+3)}{2}+n’, \\end{equation} and is given as \\begin{equation} \\mathbf{F}=\\left[\\begin{matrix}\\mathbf{I}\u0026\\mathbf{V} \\\\ \\mathbf{V}^\\text{T}\u0026\\mathbf{C}\\end{matrix}\\right],\\label{eq:ec.1} \\end{equation} where \\begin{equation} \\mathbf{V}=\\frac{\\partial^2\\log\\pi(\\mathbf{z})}{\\partial(\\boldsymbol{\\delta},\\mathbf{M})\\partial\\boldsymbol{\\tau}}\\in\\mathbb{R}^{(m-n’)\\times n’},\\hspace{1cm}\\mathbf{C}=\\frac{\\partial^2\\log\\pi(\\mathbf{z})}{\\partial\\boldsymbol{\\tau}^2}\\in\\mathbb{R}^{n’\\times n’} \\end{equation} Using the Woodbury identity for $\\mathbf{F}$ gives us its inverse \\begin{equation} \\mathbf{F}^{-1}=\\left[\\begin{matrix}\\mathbf{I}\u0026\\mathbf{V} \\\\ \\mathbf{V}^\\text{T}\u0026\\mathbf{C}\\end{matrix}\\right]^{-1}=\\left[\\begin{matrix}\\mathbf{I}+\\mathbf{H}\\mathbf{V}\\mathbf{V}^\\text{T}\u0026-\\mathbf{H}\\mathbf{v} \\\\ -\\mathbf{H}\\mathbf{V}^\\text{T}\u0026\\mathbf{H}\\end{matrix}\\right], \\end{equation} where $\\mathbf{H}=(\\mathbf{C}-\\mathbf{V}^\\text{T}\\mathbf{V})^{-1}$, and thus $\\mathbf{H}$ is symmetric.\nOn the other hands, the gradient w.r.t each parameter of $\\log\\pi(\\mathbf{z})$ are given as \\begin{equation} \\nabla_{\\boldsymbol{\\delta},\\mathbf{M},\\boldsymbol{\\tau}}\\log\\pi(\\mathbf{z}\\vert\\boldsymbol{\\mu},\\mathbf{A},\\boldsymbol{\\tau},\\boldsymbol{\\delta},\\mathbf{M})\\big\\vert_{\\hspace{0.1cm}\\boldsymbol{\\delta}=\\mathbf{0},\\mathbf{M}=\\mathbf{0}}=\\mathbf{g}=\\left[\\begin{matrix}\\mathbf{g}_\\boldsymbol{\\delta} \\\\ \\mathbf{g}_\\mathbf{M} \\\\ \\mathbf{g}_\\boldsymbol{\\tau}\\end{matrix}\\right], \\end{equation} where \\begin{align} \\mathbf{g}_\\boldsymbol{\\delta}\u0026=-2\\frac{q_\\boldsymbol{\\tau}’(\\Vert\\mathbf{s}\\Vert^2)}{q_\\boldsymbol{\\tau}(\\Vert\\mathbf{s}\\Vert^2)}\\mathbf{s},\\label{eq:ec.2} \\\\ \\mathbf{g}_\\mathbf{M}\u0026=-\\frac{1}{2}\\mathbf{I}-\\frac{q_\\boldsymbol{\\tau}’(\\Vert\\mathbf{s}\\Vert^2)}{q_\\boldsymbol{\\tau}(\\Vert\\mathbf{s}\\Vert^2)}\\mathbf{s}\\mathbf{s}^\\text{T},\\label{eq:ec.3} \\\\ \\mathbf{g}_\\boldsymbol{\\tau}\u0026=\\frac{1}{q_\\boldsymbol{\\tau}(\\Vert\\mathbf{s}\\Vert^2)}\\nabla_\\boldsymbol{\\tau}q_\\boldsymbol{\\tau}(\\Vert\\mathbf{s}\\Vert^2), \\end{align} where \\begin{equation} q_\\boldsymbol{\\tau}’=\\frac{\\partial}{\\partial(r^2)}q_\\boldsymbol{\\tau} \\end{equation} denotes the derivative of $q_\\boldsymbol{\\tau}$ w.r.t $r^2$, while $\\nabla_\\boldsymbol{\\tau}q_\\boldsymbol{\\tau}$ represents the gradient w.r.t $\\boldsymbol{\\tau}$.\nThe natural gradient for a sample $\\mathbf{s}$ is then can be computed as \\begin{equation} \\tilde{\\nabla}J=\\mathbf{F}^{-1}\\mathbf{g}=\\mathbf{F}^{-1}\\left[\\begin{matrix}\\mathbf{g}_\\boldsymbol{\\delta} \\\\ \\mathbf{g}_\\mathbf{M} \\\\ \\mathbf{g}_\\boldsymbol{\\tau}\\end{matrix}\\right]=\\left[\\begin{matrix}\\left(\\mathbf{g}_\\boldsymbol{\\delta},\\mathbf{g}_\\mathbf{M}\\right)-\\mathbf{H}\\mathbf{V}\\left(\\mathbf{V}^\\text{T}\\left(\\mathbf{g}_\\boldsymbol{\\delta},\\mathbf{g}_\\mathbf{M}\\right)-\\mathbf{g}_\\boldsymbol{\\tau}\\right) \\\\ \\mathbf{H}\\left(\\mathbf{V}^\\text{T}\\left(\\mathbf{g}_\\boldsymbol{\\delta},\\mathbf{g}_\\mathbf{M}\\right)-\\mathbf{g}_\\boldsymbol{\\tau}\\right)\\end{matrix}\\right], \\end{equation} where \\begin{equation} \\left(\\mathbf{g}_\\boldsymbol{\\delta},\\mathbf{g}_\\mathbf{M}\\right)=\\left[\\begin{matrix}\\mathbf{g}_\\boldsymbol{\\delta} \\\\ \\mathbf{g}_\\mathbf{M}\\end{matrix}\\right] \\end{equation}\nSampling from rotationally symmetric distributions To sample from this class of distributions, we first draw a sample $\\mathbf{s}$ according to the standard density \\begin{equation} \\mathbf{s}\\sim\\pi(\\mathbf{s}\\vert\\boldsymbol{\\mu}=\\mathbf{0},\\mathbf{A}=\\mathbf{I},\\boldsymbol{\\tau}), \\end{equation} We continue to transform this sample into \\begin{equation} \\mathbf{z}=\\boldsymbol{\\mu}+\\mathbf{A}^\\text{T}\\mathbf{s}\\sim\\pi(\\mathbf{z}\\vert\\boldsymbol{\\mu},\\mathbf{A},\\boldsymbol{\\tau}) \\end{equation} In general, sampling $\\mathbf{s}$ can be decomposed into sampling $r^2$ according to \\begin{equation} r^2\\sim\\tilde{q}_\\boldsymbol{\\tau}(r^2)=\\int_{\\Vert\\mathbf{z}\\Vert^2=r^2}Q_\\boldsymbol{\\tau}\\hspace{0.1cm}d\\mathbf{z}=\\frac{2\\pi^{n/2}}{\\Gamma(n/2)}(r^2)^{(d-1)/2}q_\\boldsymbol{\\tau}(r^2) \\end{equation} and a unit vector $\\mathbf{u}\\in\\mathbb{R}^n$.\nExponential Natural Evolution Strategies Recall that the Multivariate Gaussian can be expressed in form of a radial distribution \\eqref{eq:ep.1}. In this case, we have that \\begin{equation} q_\\boldsymbol{\\tau}(r^2)=\\frac{1}{(2\\pi)^{n/2}}\\exp\\left(-\\frac{1}{2}r^2\\right),\\label{eq:xnes.1} \\end{equation} which does not depend on $\\boldsymbol{\\tau}$. This lets the Fisher information matrix in \\eqref{eq:ec.1} be simplified to the most trivial form, which is the identity matrix $\\mathbf{I}$.\nDifferentiating \\eqref{eq:xnes.1} w.r.t $r^2$ then gives us \\begin{equation} q_\\boldsymbol{\\tau}’(r^2)=\\frac{\\partial}{\\partial(r^2)}\\frac{1}{(2\\pi)^{n/2}}\\exp\\left(-\\frac{1}{2}r^2\\right)=-\\frac{1}{2}\\frac{1}{(2\\pi)^{n/2}}\\exp\\left(-\\frac{1}{2}r^2\\right)=-\\frac{1}{2}q_\\boldsymbol{\\tau}(r^2), \\end{equation} which by \\eqref{eq:ec.2} and \\eqref{eq:ec.3} implies that \\begin{equation} \\mathbf{g}_\\boldsymbol{\\delta}=-2\\frac{q_\\boldsymbol{\\tau}’(\\Vert\\mathbf{s}\\Vert^2)}{q_\\boldsymbol{\\tau}(\\Vert\\mathbf{s}\\Vert^2)}\\mathbf{s}=\\mathbf{s} \\end{equation} and \\begin{equation} \\mathbf{g}_\\mathbf{M}=-\\frac{1}{2}\\mathbf{I}-\\frac{q_\\boldsymbol{\\tau}’(\\Vert\\mathbf{s}\\Vert^2)}{q_\\boldsymbol{\\tau}(\\Vert\\mathbf{s}\\Vert^2)}\\mathbf{s}\\mathbf{s}^\\text{T}=\\frac{1}{2}(\\mathbf{s}\\mathbf{s}^\\text{T}-\\mathbf{I}) \\end{equation} Hence, the natural gradient is then given as \\begin{align} \\nabla_\\boldsymbol{\\delta}J\u0026=\\sum_{k=1}^{\\lambda}f(\\mathbf{z}_k)\\mathbf{s}_k \\\\ \\nabla_\\mathbf{M}J\u0026=\\sum_{k=1}^{\\lambda}f(\\mathbf{z}_k)(\\mathbf{s}_k\\mathbf{s}_k^\\text{T}-\\mathbf{I}), \\end{align} which can be improved with fitness shaping using the update formula \\eqref{eq:fs.1} as \\begin{align} \\nabla_\\boldsymbol{\\delta}J\u0026=\\sum_{k=1}^{\\lambda}u_k\\mathbf{s}_{k:\\lambda}, \\\\ \\nabla_\\mathbf{M}J\u0026=\\sum_{k=1}^{\\lambda}u_k(\\mathbf{s}_{k:\\lambda}\\mathbf{s}_{k:\\lambda}^\\text{T}-\\mathbf{I}), \\end{align} where $\\mathbf{s}_{k:\\lambda}$ denotes the $k$-th best sample in local coordinates. The resulting algorithm is thus known as Exponential Natural Evolution Strategies, or xNES, with the corresponding pseudocode shown below.\nTesting on Rastrigin function Analogy to CMA-ES, let us test NES on the Rastrigin function, which is, recall that, given by the formula \\begin{equation} f(\\mathbf{x})=10 n+\\sum_{i=1}^{n}x_i^2-10\\cos\\left(2\\pi x_i\\right) \\end{equation} $f(\\mathbf{x})$ reaches its global minimum $0$ at $\\mathbf{x}=\\mathbf{0}$. The experimental setup we are going to use are provided in Wierstra et al. 2014. Similar to our test with CMA-ES, each function evaluation is counted as success when it reaches $f_\\text{stop}=10^{-10}$.\nThe result after running our experiment is illustrated in the figure below.\nFigure 1: Success rate to reach $f_\\text{stop}=10^{-10}$ versus population size for Rastrigin function. The code can be found here References [1] Daan Wierstra, Tom Schaul, Jan Peters, Jürgen Schmidhuber. Natural Evolution Strategies. IEEE World Congress on Computational Intelligence, 2008.\n[2] Daan Wierstra, Tom Schaul, Tobias Glasmachers, Yi Sun, Jürgen Schmidhuber. Natural Evolution Strategies. arXiv:1106.4487, 2011.\n[3] Daan Wierstra, Tom Schaul, Tobias Glasmachers, Yi Sun, Jan Peters, Jürgen Schmidhuber. Natural Evolution Strategies. Journal of Machine Learning Research 15, 2014.\n[4] Jan Reinhard Peters. Machine Learning of Motor Skills for Robotics. PhD thesis, 2007.\n[5] Stephen Boyd \u0026 Lieven Vandenberghe. Convex Optimization. Cambridge UP, 2004.\n[6] Ha, David. A Visual Guide to Evolution Strategies. blog.otoro.net, 2017.\nFootnotes","wordCount":"1997","inLanguage":"en","datePublished":"2022-10-07T13:00:00+07:00","dateModified":"2022-10-07T13:00:00+07:00","author":{"@type":"Person","name":"Trung H. Nguyen"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://trunghng.github.io/posts/evolution-strategy/nes/"},"publisher":{"@type":"Organization","name":"Littleroot","logo":{"@type":"ImageObject","url":"https://trunghng.github.io/images/favicon/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://trunghng.github.io accesskey=h title="Littleroot (Alt + H)"><img src=https://trunghng.github.io/images/others/pokeball.png alt aria-label=logo height=27>Littleroot</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://trunghng.github.io/ title=Posts><span>Posts</span></a></li><li><a href=https://trunghng.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://trunghng.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://trunghng.github.io/about/ title=About><span>About</span></a></li><li><a href=https://trunghng.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Natural Evolution Strategies</h1><div class=post-meta><span title='2022-10-07 13:00:00 +0700 +0700'>October 7, 2022</span>&nbsp;·&nbsp;10 min&nbsp;·&nbsp;Trung H. Nguyen</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#search-grad>Search gradients</a><ul><li><a href=#search-grad-gauss>Search gradients for MVN</a></li><li><a href=#ntr-grad>Natural gradient</a></li></ul></li><li><a href=#rbn-tchnq>Robustness techniques</a><ul><li><a href=#fn-shp>Fitness shaping</a></li><li><a href=#adp-sampl>Adaption sampling</a></li></ul></li><li><a href=#rot-sym-dist>Rotationally-symmetric distributions</a><ul><li><a href=#exp-param>Exponential parameterization</a></li><li><a href=#exp-coords>Exponential local coordinates</a></li><li><a href=#samp-rot-sym-dist>Sampling from rotationally symmetric distributions</a></li><li><a href=#xnes>Exponential Natural Evolution Strategies</a></li></ul></li><li><a href=#test-on-rast>Testing on Rastrigin function</a></li><li><a href=#references>References</a></li><li><a href=#footnotes>Footnotes</a></li></ul></nav></div></details></div><div class=post-content><blockquote><p><strong>Natural Evolution Strategies</strong>, or <strong>NES</strong>, are referred to a family of evolution strategies that throughout its generations update a search distribution repeatedly using an estimated gradient of its distribution parameters.</p></blockquote><h2 id=search-grad>Search gradients<a hidden class=anchor aria-hidden=true href=#search-grad>#</a></h2><p>Usually when working on <strong>Evolution Strategy</strong> methods, we select some candidate solutions, which generate better fitness values than the other ones, to be parents of the next generation. This means, majority of solution samples have been wasted since they may contain some useful information.</p><p>To utilize the use all fitness samples, the <strong>NES</strong> uses <strong>search gradients</strong> in updating the parameters for the search distribution.</p><p>Let $\mathbf{z}\in\mathbb{R}^n$ denote the solution sampled from the distribution $\pi(\mathbf{z},\theta)$ and let $f:\mathbb{R}^n\to\mathbb{R}$ be the fitness (or objective) function. The expected fitness value is then given by
\begin{equation}
J(\theta)=\mathbb{E}_\theta[f(\mathbf{z})]=\int f(\mathbf{z})\pi(\mathbf{z}\vert\theta)\hspace{0.1cm}d\mathbf{z}\label{eq:sg.1}
\end{equation}
Taking the gradient of the above function w.r.t $\theta$ using the <strong>log-likelihood trick</strong> as in <a href=https://trunghng.github.io/posts/reinforcement-learning/policy-gradient-theorem/#reinforce>REINFORCE</a> gives us
\begin{align}
\nabla_\theta J(\theta)&=\nabla_\theta\int f(\mathbf{z})\pi(\mathbf{z}\vert\theta)\hspace{0.1cm}d\mathbf{z} \\ &=\int f(\mathbf{z})\nabla_\theta\pi(\mathbf{z}\vert\theta)\hspace{0.1cm}d\mathbf{z} \\ &=\int f(\mathbf{z})\nabla_\theta\pi(\mathbf{z}\vert\theta)\frac{\pi(\mathbf{z}\vert\theta)}{\pi(\mathbf{z}\vert\theta)}\hspace{0.1cm}d\mathbf{z} \\ &=\int\left[f(\mathbf{z})\nabla_\theta\log\pi(\mathbf{z}\vert\theta)\right]\pi(\mathbf{z}\vert\theta)\hspace{0.1cm}d\mathbf{z} \\ &=\mathbb{E}_\theta\left[f(\mathbf{z})\nabla_\theta\log\pi(\mathbf{z}\vert\theta)\right]
\end{align}
Using Monte Carlo method, given samples $\mathbf{z}_1,\ldots,\mathbf{z}_\lambda$ from the population of size $\lambda$, the search gradient is then can be approximated by
\begin{equation}
\nabla_\theta J(\theta)\approx\frac{1}{\lambda}\sum_{k=1}^{\lambda}f(\mathbf{z}_k)\nabla_\theta\log\pi(\mathbf{z}_k\vert\theta)\label{eq:sg.2}
\end{equation}
Given this gradient w.r.t $\theta$, we then can use a gradient-based method to repeatedly update the parameter $\theta$ in order to give us a more desired search distribution. In particular, we can use such as SGD method
\begin{equation}
\theta\leftarrow\theta+\alpha\nabla_\theta J(\theta),\label{eq:sg.3}
\end{equation}
where $\alpha$ is the learning rate.</p><h3 id=search-grad-gauss>Search gradients for MVN<a hidden class=anchor aria-hidden=true href=#search-grad-gauss>#</a></h3><p>Consider the case that our search distribution $\pi(\mathbf{z}\vert\theta)$ is in form of a Multivariate Normal distribution, $\mathbf{z}\sim\mathcal{N}(\boldsymbol{\mu},\boldsymbol{\Sigma})$, where $\boldsymbol{\mu}\in\mathbb{R}^n$ and $\boldsymbol{\Sigma}\in\mathbb{R}^{n\times n}$.</p><p>In this case $\theta=(\boldsymbol{\mu},\boldsymbol{\Sigma})$ denotes a tuple of parameters for the search distribution, which is given by
\begin{equation}
\pi(\mathbf{z}\vert\theta)=\frac{1}{(2\pi)^{n/1}\left\vert\boldsymbol{\Sigma}\right\vert^{1/2}}\exp\left[-\frac{1}{2}\left(\mathbf{z}-\boldsymbol{\mu}\right)^\text{T}\boldsymbol{\Sigma}^{-1}\left(\mathbf{z}-\boldsymbol{\mu}\right)\right]
\end{equation}
Taking natural logarithm of both sides then gives us
\begin{align}
\log\pi(\mathbf{z}\vert\theta)&=\log\left(\frac{1}{(2\pi)^{n/1}\left\vert\boldsymbol{\Sigma}\right\vert^{1/2}}\exp\left[-\frac{1}{2}\left(\mathbf{z}-\boldsymbol{\mu}\right)^\text{T}\boldsymbol{\Sigma}^{-1}\left(\mathbf{z}-\boldsymbol{\mu}\right)\right]\right) \\ &=-\frac{n}{2}\log(2\pi)-\frac{1}{2}\log\vert\boldsymbol{\Sigma}\vert-\frac{1}{2}\left(\mathbf{z}-\boldsymbol{\mu}\right)^\text{T}\boldsymbol{\Sigma}^{-1}\left(\mathbf{z}-\boldsymbol{\mu}\right)
\end{align}
We continue by differentiating the above log-likelihood w.r.t $\boldsymbol{\mu}$ and $\boldsymbol{\Sigma}$. Starting with $\boldsymbol{\mu}$, the gradient is given by
\begin{align}
\nabla_\boldsymbol{\mu}\log\pi(\mathbf{z}\vert\theta)&=\nabla_\boldsymbol{\mu}\left(-\frac{n}{2}\log(2\pi)-\frac{1}{2}\log\vert\boldsymbol{\Sigma}\vert-\frac{1}{2}\left(\mathbf{z}-\boldsymbol{\mu}\right)^\text{T}\boldsymbol{\Sigma}^{-1}\left(\mathbf{z}-\boldsymbol{\mu}\right)\right) \\ &=-\frac{1}{2}\nabla_\boldsymbol{\mu}\left(\mathbf{z}-\boldsymbol{\mu}\right)^\text{T}\boldsymbol{\Sigma}^{-1}\left(\mathbf{z}-\boldsymbol{\mu}\right) \\ &=\boldsymbol{\Sigma}^{-1}(\mathbf{z}-\boldsymbol{\mu})
\end{align}
And the gradient w.r.t $\boldsymbol{\Sigma}$ is computed as
\begin{align}
\nabla_\boldsymbol{\Sigma}\pi(\mathbf{z}\vert\theta)&=\nabla_\boldsymbol{\Sigma}\left(-\frac{n}{2}\log(2\pi)-\frac{1}{2}\log\vert\boldsymbol{\Sigma}\vert-\frac{1}{2}\left(\mathbf{z}-\boldsymbol{\mu}\right)^\text{T}\boldsymbol{\Sigma}^{-1}\left(\mathbf{z}-\boldsymbol{\mu}\right)\right) \\ &=-\frac{1}{2}\nabla_\boldsymbol{\Sigma}\left(\mathbf{z}-\boldsymbol{\mu}\right)^\text{T}\boldsymbol{\Sigma}^{-1}\left(\mathbf{z}-\boldsymbol{\mu}\right) \\ &=\frac{1}{2}\boldsymbol{\Sigma}^{-1}\left(\mathbf{z}-\boldsymbol{\mu}\right)\left(\mathbf{z}-\boldsymbol{\mu}\right)^\text{T}\boldsymbol{\Sigma}^{-1}-\frac{1}{2}\boldsymbol{\Sigma}^{-1}
\end{align}
The SGD update \eqref{eq:sg.3} now is applied for each of $\boldsymbol{\mu}$ and $\boldsymbol{\Sigma}$ as
\begin{align}
\boldsymbol{\mu}&\leftarrow\boldsymbol{\mu}+\alpha\nabla_\boldsymbol{\mu}J(\theta) \\ &\leftarrow\boldsymbol{\mu}+\alpha\frac{1}{\lambda}\sum_{k=1}^{\lambda}\boldsymbol{\Sigma}^{-1}\left(\mathbf{z}_k-\boldsymbol{\mu}\right)f(\mathbf{z}_k)
\end{align}
and
\begin{align}
\boldsymbol{\Sigma}&\leftarrow\boldsymbol{\Sigma}+\alpha\nabla_\boldsymbol{\Sigma}J(\theta) \\ &\leftarrow\boldsymbol{\Sigma}+\alpha\frac{1}{\lambda}\sum_{k=1}^{\lambda}\left[\frac{1}{2}\boldsymbol{\Sigma}^{-1}\left(\mathbf{z}_k-\boldsymbol{\mu}\right)\left(\mathbf{z}_k-\boldsymbol{\mu}\right)^\text{T}\boldsymbol{\Sigma}^{-1}-\frac{1}{2}\boldsymbol{\Sigma}^{-1}\right]f(\mathbf{z}_k)
\end{align}</p><h3 id=ntr-grad>Natural gradient<a hidden class=anchor aria-hidden=true href=#ntr-grad>#</a></h3><p>The <strong>natural gradient</strong> searches for the direction based on the distance between distributions $\pi(\mathbf{z}\vert\theta)$ and $\pi(\mathbf{z}\vert\theta&rsquo;)$. One natural measure of distance between probability distributions is the <strong>Kullback-Leibler divergence</strong>, or <strong>KL divergence</strong>.</p><p>In other words, our work is to look for the direction of updating gradient, denoted as $\delta\theta$, such that
\begin{align}
\max_{\delta\theta}&\hspace{0.1cm}J(\theta+\delta\theta)\approx J(\theta)+\delta\theta^\text{T}\nabla_\theta J \\ \text{s.t.}&\hspace{0.1cm}D_\text{KL}(\theta\Vert\theta+\delta\theta)=\varepsilon,
\end{align}
where $J(\theta)$ is given as in \eqref{eq:sg.1}; $\varepsilon$ is a small increment size; and where $D_\text{KL}(\theta\Vert\theta+\delta\theta)$ is the KL divergence of $\pi(\mathbf{z}\vert\theta)$ from $\pi(\mathbf{z}\vert\theta+\delta\theta)$, defined as
\begin{align}
D_\text{KL}(\theta\Vert\theta+\delta\theta)&=\int\pi(\mathbf{z}\vert\theta)\log\frac{\pi(\mathbf{z}\vert\theta)}{\pi(\mathbf{z}\vert\theta+\delta\theta)}\hspace{0.1cm}d\mathbf{z} \\ &=\mathbb{E}_{\theta}\big[\log\pi(\mathbf{z}\vert\theta)-\log\pi(\mathbf{z}\vert\theta+\delta)\big]\label{eq:ng.1}
\end{align}
As $\delta\theta\to 0$, or in other words, consider the Taylor expansion of \eqref{eq:ng.1} about $\delta\theta=0$, we have
\begin{align}
&amp;D_\text{KL}(\theta\Vert\theta+\delta\theta)\nonumber \\ &=\mathbb{E}_{\theta}\big[\log\pi(\mathbf{z}\vert\theta)-\log\pi(\mathbf{z}\vert\theta+\delta\theta)\big] \\ &\approx\mathbb{E}_\theta\left[\log\pi(\mathbf{z}\vert\theta)-\left(\log\pi(\mathbf{z}\vert\theta)+\delta\theta^\text{T}\frac{\nabla_\theta\pi(\mathbf{z}\vert\theta)}{\pi(\mathbf{z}\vert\theta)}+\frac{1}{2}\delta\theta^\text{T}\frac{\nabla_\theta^2\pi(\mathbf{z}\vert\theta)}{\pi(\mathbf{z}\vert\theta)}\delta\theta\right)\right] \\ &=-\mathbb{E}_\theta\left[\delta\theta^\text{T}\nabla_\theta\log\pi(\mathbf{z}\vert\theta)+\frac{1}{2}\delta\theta^\text{T}\nabla_\theta^2\log\pi(\mathbf{z}\vert\theta)\delta\theta\right] \\ &=-\mathbb{E}_\theta\Big[\delta\theta^\text{T}\nabla_\theta\log\pi(\mathbf{z}\vert\theta)\Big]-\mathbb{E}_\theta\left[\frac{1}{2}\delta\theta^\text{T}\nabla_\theta^2\log\pi(\mathbf{z}\vert\theta)\delta\theta\right] \\ &\overset{\text{(i)}}{=}-\frac{1}{2}\delta\theta^\text{T}\mathbb{E}_\theta\Big[\nabla_\theta^2\log\pi(\mathbf{z}\vert\theta)\Big]\delta\theta \\ &\overset{\text{(ii)}}{=}\frac{1}{2}\delta\theta^\text{T}\mathbb{E}_\theta\Big[\nabla_\theta\log\pi(\mathbf{z}\vert\theta)\nabla_\theta\log\pi(\mathbf{z}\vert\theta)^\text{T}\Big]\delta\theta \\ &\overset{\text{(iii)}}{=}\frac{1}{2}\delta\theta^\text{T}\mathbf{F}\delta\theta\label{eq:ng.2}
\end{align}
where</p><ul id=roman-list><li>In this step, we have used
\begin{align}
\mathbb{E}_\theta\Big[\delta\theta^\text{T}\nabla_\theta\log\pi(\mathbf{z}\vert\theta)\Big]&=\delta\theta^\text{T}\int\pi(\mathbf{z}\vert\theta)\nabla_\theta\log\pi(\mathbf{z}\vert\theta)\hspace{0.1cm}d\mathbf{z} \\ &=\delta\theta^\text{T}\int\pi(\mathbf{z}\vert\theta)\frac{1}{\pi(\mathbf{z}\vert\theta)}\nabla_\theta\pi(\mathbf{z}\vert\theta)\hspace{0.1cm}d\mathbf{z} \\ &=\delta\theta^\text{T}\nabla_\theta\int\pi(\mathbf{z}\vert\theta)\hspace{0.1cm}d\mathbf{z} \\ &=\delta\theta^\text{T}\nabla_\theta 1=0
\end{align}</li><li><span id=derivation-ii>In this step, let $\theta_j,\theta_k$ denote the $j$-th and $k$-th element of $\theta$ respectively. The $(j,k)$ element of the Hessian $\nabla_\theta^2\log\pi(\mathbf{z}\vert\theta)$ thus, by chain rule, can be computed as</span>
\begin{align}
\hspace{-1.7cm}\frac{\partial^2}{\partial\theta_j\partial\theta_k}\log\pi(\mathbf{z}\vert\theta)&=\frac{\partial}{\partial\theta_j}\left(\frac{\partial\log\pi(\mathbf{z}\vert\theta)}{\partial\theta_k}\right) \\ &=\frac{\partial}{\partial\theta_j}\left(\frac{1}{\pi(\mathbf{z}\vert\theta)}\cdot\frac{\partial\pi(\mathbf{z}\vert\theta)}{\partial\theta_k}\right) \\ &=\frac{\partial}{\partial\theta_j}\left(\frac{1}{\pi(\mathbf{z}
\vert\theta)}\right)\cdot\frac{\partial\pi(\mathbf{z}\vert\theta)}{\partial\theta_k}+\frac{1}{\pi(\mathbf{z}\vert\theta)}\cdot\frac{\partial^2\pi(\mathbf{z}\vert\theta)}{\partial\theta_j\partial\theta_k} \\ &=\left(\frac{\partial\frac{1}{\pi(\mathbf{z}\vert\theta)}}{\partial\pi(\mathbf{z}\vert\theta)}\cdot\frac{\partial\pi(\mathbf{z}\vert\theta)}{\partial\theta_j}\right)\cdot\frac{\partial\pi(\mathbf{z}\vert\theta)}{\partial\theta_k}+\frac{1}{\pi(\mathbf{z}\vert\theta)}\cdot\frac{\partial^2\pi(\mathbf{z}\vert\theta)}{\partial\theta_j\partial\theta_k} \\ &=-\frac{1}{\pi(\mathbf{z}\vert\theta)^2}\cdot\frac{\partial\pi(\mathbf{z}\vert\theta)}{\partial\theta_j}\cdot\frac{\partial\pi(\mathbf{z}\vert\theta)}{\partial\theta_k}+\frac{1}{\pi(\mathbf{z}\vert\theta)}\cdot\frac{\partial^2\pi(\mathbf{z}\vert\theta)}{\partial\theta_j\partial\theta_k} \\ &=-\frac{\partial\log\pi(\mathbf{z}\vert\theta)}{\partial\theta_j}\cdot\frac{\partial\log\pi(\mathbf{z}\vert\theta)}{\partial\theta_k}+\frac{1}{\pi(\mathbf{z}\vert\theta)}\cdot\frac{\partial^2\pi(\mathbf{z}\vert\theta)}{\partial\theta_j\partial\theta_k},
\end{align}
which implies that
\begin{equation}
\nabla_\theta^2\log\pi(\mathbf{z}\vert\theta)=-\nabla_\theta\log\pi(\mathbf{z}\vert\theta)\nabla_\theta\log\pi(\mathbf{z}\vert\theta)^\text{T}+\frac{1}{\pi(\mathbf{z}\vert\theta)}\nabla_\theta^2\pi(\mathbf{z}\vert\theta)
\end{equation}
Taking expectation on both sides gives us
\begin{align}
\hspace{-1cm}\mathbb{E}_\theta\Big[\nabla_\theta^2\log\pi(\mathbf{z}\vert\theta)\Big]&=-\mathbb{E}_\theta\Big[\nabla_\theta\log\pi(\mathbf{z}\vert\theta)\nabla_\theta\log\pi(\mathbf{z}\vert\theta)^\text{T}\Big]+\mathbb{E}_\theta\left[\frac{1}{\pi(\mathbf{z}\vert\theta)}\nabla_\theta^2\pi(\mathbf{z}\vert\theta)\right]\label{eq:ng.5} \\ &=-\mathbb{E}_\theta\Big[\nabla_\theta\log\pi(\mathbf{z}\vert\theta)\nabla_\theta\log\pi(\mathbf{z}\vert\theta)^\text{T}\Big],
\end{align}
where the latter expectation in \eqref{eq:ng.5} has been absorbed due to
\begin{align}
\mathbb{E}_\theta\left[\frac{1}{\pi(\mathbf{z}\vert\theta)}\nabla_\theta^2\pi(\mathbf{z}\vert\theta)\right]&=\int\nabla_\theta^2\pi(\mathbf{z}\vert\theta)\,d\mathbf{z} \\ &=\nabla_\theta^2\int\pi(\mathbf{z}\vert\theta)\,d\mathbf{z} \\ &=\nabla_\theta^2 1=\mathbf{0}
		\end{align}</li><li>The matrix $\mathbf{F}$ is referred as the <b>Fisher information matrix</b> of the given parametric family of search distributions, defined as
\begin{align}
\mathbf{F}&=\mathbb{E}_\theta\Big[\nabla_\theta\log\pi(\mathbf{z}\vert\theta)\nabla_\theta\log\pi(\mathbf{z}\vert\theta)^\text{T}\Big] \\ &=\int\pi(\mathbf{z}\vert\theta)\nabla_\theta\log\pi(\mathbf{z}\vert\theta)\nabla_\theta\log\pi(\mathbf{z}\vert\theta)^\text{T}\hspace{0.1cm}d\mathbf{z}
\end{align}</li></ul><p>Hence, we have the <span id=lagrangian>Lagrangian</span> of our constrained optimization problem is
\begin{align}
\mathcal{L}(\theta,\delta\theta,\lambda)&=J(\theta)+\delta\theta^\text{T}\nabla_\theta J(\theta)+\lambda\big(\varepsilon-D_\text{KL}(\theta\Vert\theta+\delta\theta)\big) \\ &=J(\theta)+\delta\theta^\text{T}\nabla_\theta J(\theta)+\lambda\left(\varepsilon-\frac{1}{2}\delta\theta^\text{T}\mathbf{F}\delta\theta\right),
\end{align}
where $\lambda>0$ is the <strong>Lagrange multiplier</strong>.</p><p>It is easily seen that $\mathbf{F}$ is symmetric, thus taking the gradient of the Lagrangian w.r.t $\delta\theta$ and setting it to zero gives us
\begin{equation}
\lambda\mathbf{F}\delta\theta=\nabla_\theta J(\theta)
\end{equation}
If the Fisher information matrix $\mathbf{F}$ is invertible, the solution for $\delta\theta$ that maximizes $\mathcal{L}$ then can be computed as
\begin{equation}
\delta\theta=\frac{1}{\lambda}\mathbf{F}^{-1}\nabla_\theta J(\theta),\label{eq:ng.3}
\end{equation}
which defines the direction of the natural gradient $\tilde{\nabla}_\theta J(\theta)$. Since $\lambda>0$ we therefore obtain
\begin{equation}
\tilde{\nabla}_\theta J(\theta)=\mathbf{F}^{-1}\nabla_\theta J(\theta)
\end{equation}
Continue with the value of $\delta\theta$ given in \eqref{eq:ng.3}, the dual function of our optimization is given as
\begin{align}
g(\lambda)&=J(\theta)+\frac{1}{\lambda}\nabla_\theta J(\theta)^\text{T}\mathbf{F}^{-1}\nabla_\theta J(\theta)-\frac{1}{2}\frac{\lambda}{\lambda^2}\nabla_\theta J(\theta)^\text{T}\mathbf{F}^{-1}\mathbf{F}\mathbf{F}^{-1}\nabla_\theta J(\theta)+\lambda\varepsilon \\ &=J(\theta)+\frac{1}{2}\lambda^{-1}\nabla_\theta J(\theta)^\text{T}\mathbf{F}^{-1}\nabla_\theta J(\theta)+\lambda\varepsilon
\end{align}
Taking the gradient of $g$ w.r.t $\lambda$ and setting it to zero and since $\varepsilon>0$ small gives us the solution for $\lambda$, which is
\begin{equation}
\lambda=\sqrt{\frac{\nabla_\theta J(\theta)^\text{T}\mathbf{F}^{-1}\nabla_\theta J(\theta)}{\varepsilon}},
\end{equation}
Hence, the SGD update for the parameter $\theta$ using natural gradient is
\begin{equation}
\theta\leftarrow\theta+\eta\tilde{\nabla}_\theta J(\theta)=\theta+\eta\mathbf{F}^{-1}\nabla_\theta J(\theta),\label{eq:ng.4}
\end{equation}
where $\eta$ is the learning rate, given as
\begin{equation}
\eta=\lambda^{-1}=\sqrt{\frac{\varepsilon}{\nabla_\theta J(\theta)^\text{T}\mathbf{F}^{-1}\nabla_\theta J(\theta)}}
\end{equation}
This learning rate can also be replaced by a more desirable one without changing the direction of our update. With this update rule for natural gradient, we obtain the general formulation of NES, as described in the following pseudocode.</p><figure><img src=/images/nes/nes.png alt=NES></figure><h2 id=rbn-tchnq>Robustness techniques<a hidden class=anchor aria-hidden=true href=#rbn-tchnq>#</a></h2><h3 id=fn-shp>Fitness shaping<a hidden class=anchor aria-hidden=true href=#fn-shp>#</a></h3><p>NES uses the so-called <strong>fitness shaping</strong> technique, which helps to avoid early convergence due to the possible affection of outliers fitness value in \eqref{eq:sg.2}, e.g. there may exist an outlier whose fitness value, says $f(\mathbf{z}_i)$, is much greater than other solutions&rsquo; ones, $\{f(\mathbf{z}_k)\}_{k\neq i}$.</p><p>Rather than using fitness values $f(\mathbf{z}_k)$ in approximating the gradient in \eqref{eq:sg.2}, fitness shaping instead applies a rank-based transformation of $f(\mathbf{z}_k)$.</p><p>In particular, let $\mathbf{z}_{k:\lambda}$ denote the $k$-th best sample out of the population of size $\lambda$, $\mathbf{z}_1,\ldots,\mathbf{z}_\lambda$, i.e. $f(\mathbf{z}_{1:\lambda})\geq\ldots\geq f(\mathbf{z}_{\lambda:\lambda})$, the gradient estimate \eqref{eq:sg.2} now is rewritten as
\begin{equation}
\nabla_\theta J(\theta)=\sum_{k=1}^{\lambda}u_k\nabla_\theta\log\pi(\mathbf{z}_{k:\lambda}\vert\theta),\label{eq:fs.1}
\end{equation}
where $u_1\geq\ldots\geq u_\lambda$ are referred as <strong>utility values</strong>, which are preserved-order transformations of $f(\mathbf{z}_{1:\lambda}),\ldots,f(\mathbf{z}_{\lambda:\lambda})$.</p><p>The choice for utility function $u$ is a free parameter of the algorithm. In the original paper, the author proposed
\begin{equation}
u_k=\frac{\max\left(0,\log\left(\frac{\lambda}{2}+1\right)-\log k\right)}{\sum_{j=1}^{\lambda}\max\left(0,\log\left(\frac{\lambda}{2}+1\right)-\log j\right)}-\frac{1}{\lambda}
\end{equation}</p><h3 id=adp-sampl>Adaption sampling<a hidden class=anchor aria-hidden=true href=#adp-sampl>#</a></h3><p>Beside fitness shaping, NES also applies another heuristic, called <strong>adaption sampling</strong>, to make the performance more robustly. This technique lets the algorithm determine the appropriate hyperparameters (in this case, NES chooses the learning rate $\eta$ be the one to adapt) more quickly.</p><p>In particular, for a successive parameter $\theta&rsquo;$ of $\theta$, the corresponding learning rate $\eta$ used in its update \eqref{eq:ng.4} will be determined by comparing samples $\mathbf{z}&rsquo;$ sampled from $\pi_\theta&rsquo;$ with samples $\mathbf{z}$ sampled from $\pi_\theta$ according to a <strong>Mann-Whitney U-test</strong>.</p><h2 id=rot-sym-dist>Rotationally-symmetric distributions<a hidden class=anchor aria-hidden=true href=#rot-sym-dist>#</a></h2><p>The <strong>rotationally-symmetric distributions</strong>, or <strong>radial distributions</strong> refer to class of distributions $p(\mathbf{x})$ such that
\begin{equation}
p(\mathbf{x})=p(\mathbf{U}\mathbf{x}),\label{eq:rsd.1}
\end{equation}
for all $\mathbf{x}\in\mathbb{R}^n$ and for all orthogonal matrices $\mathbf{U}\in\mathbb{R}^{n\times n}$.</p><p>Let $Q_\boldsymbol{\tau}(\mathbf{z})$ be a family of rotationally-symmetric distributions in $\mathbb{R}^n$ parameterized by $\boldsymbol{\tau}$. The property \eqref{eq:rsd.1} allows us to represent $Q_\boldsymbol{\tau}(\mathbf{z})$ as
\begin{equation}
Q_\boldsymbol{\tau}(\mathbf{z})=q_\boldsymbol{\tau}(\Vert\mathbf{z}\Vert^2),
\end{equation}
for some family of functions $q_\boldsymbol{\tau}:\mathbb{R}_+\to\mathbb{R}_+$.</p><p>Consider the classes of search distributions in a form of
\begin{align}
\pi(\mathbf{z}\vert\boldsymbol{\mu},\boldsymbol{\Sigma},\boldsymbol{\tau})&=\frac{1}{\vert\mathbf{A}\vert}q_\boldsymbol{\tau}\left(\left\Vert(\mathbf{A}^{-1})^\text{T}(\mathbf{z}-\boldsymbol{\mu})\right\Vert^2\right) \\ &=\frac{1}{\left\vert\mathbf{A}^\text{T}\mathbf{A}\right\vert^{1/2}}q_\boldsymbol{\tau}\left((\mathbf{z}-\boldsymbol{\mu})^\text{T}(\mathbf{A}^\text{T}\mathbf{A})^{-1}(\mathbf{z}-\boldsymbol{\mu})\right),\label{eq:rsd.2}
\end{align}
with additional transformation parameters $\boldsymbol{\mu}\in\mathbb{R}^n$ and invertible matrices $\mathbf{A}\in\mathbb{R}^{n\times n}$.</p><p>It can be seen that Gaussian and its multivariate form, MVN, can be written in form of $\eqref{eq:rsd.2}$, and thus are members of these classes of distributions.</p><h3 id=exp-param>Exponential parameterization<a hidden class=anchor aria-hidden=true href=#exp-param>#</a></h3><p>By \eqref{eq:ng.4}, the natural gradient update for a multivariate Gaussian search distribution, denoted $\mathcal{N}(\boldsymbol{\mu},\boldsymbol{\Sigma})$, is
\begin{align}
\boldsymbol{\mu}&\leftarrow\boldsymbol{\mu}+\eta\mathbf{F}^{-1}\nabla_\boldsymbol{\mu} J(\boldsymbol{\mu},\boldsymbol{\Sigma}), \\ \boldsymbol{\Sigma}&\leftarrow\boldsymbol{\Sigma}+\eta\mathbf{F}^{-1}\nabla_\boldsymbol{\Sigma} J(\boldsymbol{\mu},\boldsymbol{\Sigma})
\end{align}
Thus, in updating the covariance matrix $\boldsymbol{\Sigma}$ as above, we have to ensure that $\boldsymbol{\Sigma}+\eta\mathbf{F}^{-1}\nabla_\boldsymbol{\Sigma} J(\boldsymbol{\mu},\boldsymbol{\Sigma})$ is symmetric positive definite.</p><p>To accomplish this, we may represent the covariance matrix using the <strong>exponential parameterization</strong> for symmetric matrices. In particular, let
\begin{equation}
\mathcal{S}_n\doteq\{\mathbf{M}\in\mathbb{R}^{n\times n}:\mathbf{M}=\mathbf{M}^\text{T}\}
\end{equation}
denote the set of symmetric matrices of $\mathbb{R}^{n\times n}$ and let
\begin{equation}
\mathcal{P}_n\doteq\{\mathbf{M}\in\mathcal{S}_n:\mathbf{M}\succ 0\}
\end{equation}
represent the cone of symmetric positive definite matrices of $\mathbb{R}^{n\times n}$.</p><p>Using Taylor expansion for the exponential function, we then have the exponential map $\exp:\mathcal{S}_n\to\mathcal{P}_n$ can be written as
\begin{equation}
\exp(\mathbf{M})=\sum_{i=0}^{\infty}\frac{\mathbf{M}^i}{i!},\label{eq:ep.1}
\end{equation}
which is <strong>diffeomorphism</strong>, i.e. the map is bijective, plus the map and its inverse map, $\log:\mathcal{P}_n\to\mathcal{S}_n$, both are differentiable.</p><p>Therefore, we can represent the covariance matrix $\boldsymbol{\Sigma}\in\mathcal{P}_n$ as
\begin{equation}
\boldsymbol{\Sigma}=\exp(\mathbf{M}),\hspace{2cm}\mathbf{M}\in\mathcal{S}_n
\end{equation}
This representation lets the gradient update always end up as a valid covariance matrix. However, the computation for the Fisher information matrix $\mathbf{F}$ is consequently more complicated due to require partial derivatives of matrix exponential \eqref{eq:ep.1}.</p><h3 id=exp-coords>Exponential local coordinates<a hidden class=anchor aria-hidden=true href=#exp-coords>#</a></h3><p>It is noticeable from \eqref{eq:rsd.2} that the dependency of the distribution on $\mathbf{A}$ is only in terms of $\mathbf{A}^\text{T}\mathbf{A}$, which is a symmetric positive semi-definite matrix since for all non-zero vector $\mathbf{x}\in\mathbb{R}^n$ we have
\begin{equation}
\mathbf{x}^\text{T}\mathbf{A}^\text{T}\mathbf{A}\mathbf{x}=\Vert\mathbf{A}\mathbf{x}\Vert^2\geq 0
\end{equation}
In the case of MVN, this matrix corresponds to the covariance matrix.</p><p>Therefore, rather than using exponential mapping in updating the positive definite matrices $\mathbf{A}^\text{T}\mathbf{A}$, we repeatedly linear transform the coordinate system in each iteration to a coordinate system in which the calculation for $\mathbf{F}$ is trivial.</p><p>Specifically, let the current search distribution be given by $(\boldsymbol{\mu},\mathbf{A})$, we use <strong>exponential local coordinates</strong>
\begin{equation}
(\boldsymbol{\delta},\mathbf{M})\mapsto(\boldsymbol{\mu}_\text{new},\mathbf{A}_\text{new})=\left(\boldsymbol{\mu}+\mathbf{A}^\text{T}\boldsymbol{\delta},\mathbf{A}\exp\left(\frac{1}{2}\mathbf{M}\right)\right)
\end{equation}
This coordinate system is local in the sense that the coordinates $(\boldsymbol{\delta},\mathbf{M})=(\mathbf{0},\mathbf{0})$ is mapped to $(\boldsymbol{\mu},\mathbf{A})$.</p><p>For the case that $\tau\in\mathbb{R}^{n&rsquo;}$, $\boldsymbol{\delta}\in\mathbb{R}^n$ and $\mathbf{M}\in\mathbb{R}^{n(n+1)/2}$, the Fisher information matrix $\mathbf{F}$ in this coordinate system is an $m\times m$ matrix, where
\begin{equation}
m=n+\frac{n(n+1)}{2}+n&rsquo;=\frac{n(n+3)}{2}+n&rsquo;,
\end{equation}
and is given as
\begin{equation}
\mathbf{F}=\left[\begin{matrix}\mathbf{I}&\mathbf{V} \\ \mathbf{V}^\text{T}&\mathbf{C}\end{matrix}\right],\label{eq:ec.1}
\end{equation}
where
\begin{equation}
\mathbf{V}=\frac{\partial^2\log\pi(\mathbf{z})}{\partial(\boldsymbol{\delta},\mathbf{M})\partial\boldsymbol{\tau}}\in\mathbb{R}^{(m-n&rsquo;)\times n&rsquo;},\hspace{1cm}\mathbf{C}=\frac{\partial^2\log\pi(\mathbf{z})}{\partial\boldsymbol{\tau}^2}\in\mathbb{R}^{n&rsquo;\times n&rsquo;}
\end{equation}
Using the <strong>Woodbury identity</strong> for $\mathbf{F}$ gives us its inverse
\begin{equation}
\mathbf{F}^{-1}=\left[\begin{matrix}\mathbf{I}&\mathbf{V} \\ \mathbf{V}^\text{T}&\mathbf{C}\end{matrix}\right]^{-1}=\left[\begin{matrix}\mathbf{I}+\mathbf{H}\mathbf{V}\mathbf{V}^\text{T}&-\mathbf{H}\mathbf{v} \\ -\mathbf{H}\mathbf{V}^\text{T}&\mathbf{H}\end{matrix}\right],
\end{equation}
where $\mathbf{H}=(\mathbf{C}-\mathbf{V}^\text{T}\mathbf{V})^{-1}$, and thus $\mathbf{H}$ is symmetric.</p><p>On the other hands, the gradient w.r.t each parameter of $\log\pi(\mathbf{z})$ are given as
\begin{equation}
\nabla_{\boldsymbol{\delta},\mathbf{M},\boldsymbol{\tau}}\log\pi(\mathbf{z}\vert\boldsymbol{\mu},\mathbf{A},\boldsymbol{\tau},\boldsymbol{\delta},\mathbf{M})\big\vert_{\hspace{0.1cm}\boldsymbol{\delta}=\mathbf{0},\mathbf{M}=\mathbf{0}}=\mathbf{g}=\left[\begin{matrix}\mathbf{g}_\boldsymbol{\delta} \\ \mathbf{g}_\mathbf{M} \\ \mathbf{g}_\boldsymbol{\tau}\end{matrix}\right],
\end{equation}
where
\begin{align}
\mathbf{g}_\boldsymbol{\delta}&=-2\frac{q_\boldsymbol{\tau}&rsquo;(\Vert\mathbf{s}\Vert^2)}{q_\boldsymbol{\tau}(\Vert\mathbf{s}\Vert^2)}\mathbf{s},\label{eq:ec.2} \\ \mathbf{g}_\mathbf{M}&=-\frac{1}{2}\mathbf{I}-\frac{q_\boldsymbol{\tau}&rsquo;(\Vert\mathbf{s}\Vert^2)}{q_\boldsymbol{\tau}(\Vert\mathbf{s}\Vert^2)}\mathbf{s}\mathbf{s}^\text{T},\label{eq:ec.3} \\ \mathbf{g}_\boldsymbol{\tau}&=\frac{1}{q_\boldsymbol{\tau}(\Vert\mathbf{s}\Vert^2)}\nabla_\boldsymbol{\tau}q_\boldsymbol{\tau}(\Vert\mathbf{s}\Vert^2),
\end{align}
where
\begin{equation}
q_\boldsymbol{\tau}&rsquo;=\frac{\partial}{\partial(r^2)}q_\boldsymbol{\tau}
\end{equation}
denotes the derivative of $q_\boldsymbol{\tau}$ w.r.t $r^2$, while $\nabla_\boldsymbol{\tau}q_\boldsymbol{\tau}$ represents the gradient w.r.t $\boldsymbol{\tau}$.</p><p>The natural gradient for a sample $\mathbf{s}$ is then can be computed as
\begin{equation}
\tilde{\nabla}J=\mathbf{F}^{-1}\mathbf{g}=\mathbf{F}^{-1}\left[\begin{matrix}\mathbf{g}_\boldsymbol{\delta} \\ \mathbf{g}_\mathbf{M} \\ \mathbf{g}_\boldsymbol{\tau}\end{matrix}\right]=\left[\begin{matrix}\left(\mathbf{g}_\boldsymbol{\delta},\mathbf{g}_\mathbf{M}\right)-\mathbf{H}\mathbf{V}\left(\mathbf{V}^\text{T}\left(\mathbf{g}_\boldsymbol{\delta},\mathbf{g}_\mathbf{M}\right)-\mathbf{g}_\boldsymbol{\tau}\right) \\ \mathbf{H}\left(\mathbf{V}^\text{T}\left(\mathbf{g}_\boldsymbol{\delta},\mathbf{g}_\mathbf{M}\right)-\mathbf{g}_\boldsymbol{\tau}\right)\end{matrix}\right],
\end{equation}
where
\begin{equation}
\left(\mathbf{g}_\boldsymbol{\delta},\mathbf{g}_\mathbf{M}\right)=\left[\begin{matrix}\mathbf{g}_\boldsymbol{\delta} \\ \mathbf{g}_\mathbf{M}\end{matrix}\right]
\end{equation}</p><h3 id=samp-rot-sym-dist>Sampling from rotationally symmetric distributions<a hidden class=anchor aria-hidden=true href=#samp-rot-sym-dist>#</a></h3><p>To sample from this class of distributions, we first draw a sample $\mathbf{s}$ according to the standard density
\begin{equation}
\mathbf{s}\sim\pi(\mathbf{s}\vert\boldsymbol{\mu}=\mathbf{0},\mathbf{A}=\mathbf{I},\boldsymbol{\tau}),
\end{equation}
We continue to transform this sample into
\begin{equation}
\mathbf{z}=\boldsymbol{\mu}+\mathbf{A}^\text{T}\mathbf{s}\sim\pi(\mathbf{z}\vert\boldsymbol{\mu},\mathbf{A},\boldsymbol{\tau})
\end{equation}
In general, sampling $\mathbf{s}$ can be decomposed into sampling $r^2$ according to
\begin{equation}
r^2\sim\tilde{q}_\boldsymbol{\tau}(r^2)=\int_{\Vert\mathbf{z}\Vert^2=r^2}Q_\boldsymbol{\tau}\hspace{0.1cm}d\mathbf{z}=\frac{2\pi^{n/2}}{\Gamma(n/2)}(r^2)^{(d-1)/2}q_\boldsymbol{\tau}(r^2)
\end{equation}
and a unit vector $\mathbf{u}\in\mathbb{R}^n$.</p><h3 id=xnes>Exponential Natural Evolution Strategies<a hidden class=anchor aria-hidden=true href=#xnes>#</a></h3><p>Recall that the Multivariate Gaussian can be expressed in form of a radial distribution \eqref{eq:ep.1}. In this case, we have that
\begin{equation}
q_\boldsymbol{\tau}(r^2)=\frac{1}{(2\pi)^{n/2}}\exp\left(-\frac{1}{2}r^2\right),\label{eq:xnes.1}
\end{equation}
which does not depend on $\boldsymbol{\tau}$. This lets the Fisher information matrix in \eqref{eq:ec.1} be simplified to the most trivial form, which is the identity matrix $\mathbf{I}$.</p><p>Differentiating \eqref{eq:xnes.1} w.r.t $r^2$ then gives us
\begin{equation}
q_\boldsymbol{\tau}&rsquo;(r^2)=\frac{\partial}{\partial(r^2)}\frac{1}{(2\pi)^{n/2}}\exp\left(-\frac{1}{2}r^2\right)=-\frac{1}{2}\frac{1}{(2\pi)^{n/2}}\exp\left(-\frac{1}{2}r^2\right)=-\frac{1}{2}q_\boldsymbol{\tau}(r^2),
\end{equation}
which by \eqref{eq:ec.2} and \eqref{eq:ec.3} implies that
\begin{equation}
\mathbf{g}_\boldsymbol{\delta}=-2\frac{q_\boldsymbol{\tau}&rsquo;(\Vert\mathbf{s}\Vert^2)}{q_\boldsymbol{\tau}(\Vert\mathbf{s}\Vert^2)}\mathbf{s}=\mathbf{s}
\end{equation}
and
\begin{equation}
\mathbf{g}_\mathbf{M}=-\frac{1}{2}\mathbf{I}-\frac{q_\boldsymbol{\tau}&rsquo;(\Vert\mathbf{s}\Vert^2)}{q_\boldsymbol{\tau}(\Vert\mathbf{s}\Vert^2)}\mathbf{s}\mathbf{s}^\text{T}=\frac{1}{2}(\mathbf{s}\mathbf{s}^\text{T}-\mathbf{I})
\end{equation}
Hence, the natural gradient is then given as
\begin{align}
\nabla_\boldsymbol{\delta}J&=\sum_{k=1}^{\lambda}f(\mathbf{z}_k)\mathbf{s}_k \\ \nabla_\mathbf{M}J&=\sum_{k=1}^{\lambda}f(\mathbf{z}_k)(\mathbf{s}_k\mathbf{s}_k^\text{T}-\mathbf{I}),
\end{align}
which can be improved with fitness shaping using the update formula \eqref{eq:fs.1} as
\begin{align}
\nabla_\boldsymbol{\delta}J&=\sum_{k=1}^{\lambda}u_k\mathbf{s}_{k:\lambda}, \\ \nabla_\mathbf{M}J&=\sum_{k=1}^{\lambda}u_k(\mathbf{s}_{k:\lambda}\mathbf{s}_{k:\lambda}^\text{T}-\mathbf{I}),
\end{align}
where $\mathbf{s}_{k:\lambda}$ denotes the $k$-th best sample in local coordinates. The resulting algorithm is thus known as <strong>Exponential Natural Evolution Strategies</strong>, or <strong>xNES</strong>, with the corresponding pseudocode shown below.</p><figure><img src=/images/nes/xnes.png alt=xNES></figure><h2 id=test-on-rast>Testing on Rastrigin function<a hidden class=anchor aria-hidden=true href=#test-on-rast>#</a></h2><p>Analogy to <a href=https://trunghng.github.io/posts/evolution-strategy/cma-es/#test-on-rast>CMA-ES</a>, let us test NES on the Rastrigin function, which is, recall that, given by the formula
\begin{equation}
f(\mathbf{x})=10 n+\sum_{i=1}^{n}x_i^2-10\cos\left(2\pi x_i\right)
\end{equation}
$f(\mathbf{x})$ reaches its global minimum $0$ at $\mathbf{x}=\mathbf{0}$. The experimental setup we are going to use are provided in <a href=#nes-paper>Wierstra et al. 2014</a>. Similar to our test with CMA-ES, each function evaluation is counted as success when it reaches $f_\text{stop}=10^{-10}$.</p><p>The result after running our experiment is illustrated in the figure below.</p><figure><img src=/images/nes/nes-rastrigin.png alt="NES on rastrigin" width=70% height=70%><figcaption><b>Figure 1</b>: <b>Success rate to reach $f_\text{stop}=10^{-10}$ versus population size for Rastrigin function</b>. The code can be found <a href=https://github.com/trunghng/evolution-strategies/blob/main/testing_ground.py target=_blank>here</a></figcaption></figure><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2><p>[1] Daan Wierstra, Tom Schaul, Jan Peters, Jürgen Schmidhuber. <a href=https://people.idsia.ch/~juergen/nes2008.pdf>Natural Evolution Strategies</a>. IEEE World Congress on Computational Intelligence, 2008.</p><p>[2] Daan Wierstra, Tom Schaul, Tobias Glasmachers, Yi Sun, Jürgen Schmidhuber. <a href=https://arxiv.org/abs/1106.4487>Natural Evolution Strategies</a>. arXiv:1106.4487, 2011.</p><p>[3] <span id=nes-paper>Daan Wierstra, Tom Schaul, Tobias Glasmachers, Yi Sun, Jan Peters, Jürgen Schmidhuber. <a href=https://www.jmlr.org/papers/volume15/wierstra14a/wierstra14a.pdf>Natural Evolution Strategies</a>. Journal of Machine Learning Research 15, 2014.</span></p><p>[4] Jan Reinhard Peters. <a href=https://www.ias.informatik.tu-darmstadt.de/uploads/Research/Thesis/thesis_1.pdf>Machine Learning of Motor Skills for Robotics</a>. PhD thesis, 2007.</p><p>[5] Stephen Boyd & Lieven Vandenberghe. <a href=http://www.stanford.edu/%E2%88%BCboyd/cvxbook/>Convex Optimization</a>. Cambridge UP, 2004.</p><p>[6] Ha, David. <a href=https://blog.otoro.net/2017/10/29/visual-evolution-strategies/>A Visual Guide to Evolution Strategies</a>. blog.otoro.net, 2017.</p><h2 id=footnotes>Footnotes<a hidden class=anchor aria-hidden=true href=#footnotes>#</a></h2></div><footer class=post-footer><ul class=post-tags><li><a href=https://trunghng.github.io/tags/machine-learning/>machine-learning</a></li><li><a href=https://trunghng.github.io/tags/evolution-strategy/>evolution-strategy</a></li><li><a href=https://trunghng.github.io/tags/neuroevolution/>neuroevolution</a></li></ul><nav class=paginav><a class=prev href=https://trunghng.github.io/posts/reinforcement-learning/deep-q-learning/><span class=title>« Prev</span><br><span>Deep Q-learning</span>
</a><a class=next href=https://trunghng.github.io/posts/reinforcement-learning/policy-gradient/><span class=title>Next »</span><br><span>Policy Gradient</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Natural Evolution Strategies on x" href="https://x.com/intent/tweet/?text=Natural%20Evolution%20Strategies&amp;url=https%3a%2f%2ftrunghng.github.io%2fposts%2fevolution-strategy%2fnes%2f&amp;hashtags=machine-learning%2cevolution-strategy%2cneuroevolution"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Natural Evolution Strategies on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2ftrunghng.github.io%2fposts%2fevolution-strategy%2fnes%2f&amp;title=Natural%20Evolution%20Strategies&amp;summary=Natural%20Evolution%20Strategies&amp;source=https%3a%2f%2ftrunghng.github.io%2fposts%2fevolution-strategy%2fnes%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Natural Evolution Strategies on reddit" href="https://reddit.com/submit?url=https%3a%2f%2ftrunghng.github.io%2fposts%2fevolution-strategy%2fnes%2f&title=Natural%20Evolution%20Strategies"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Natural Evolution Strategies on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2ftrunghng.github.io%2fposts%2fevolution-strategy%2fnes%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Natural Evolution Strategies on whatsapp" href="https://api.whatsapp.com/send?text=Natural%20Evolution%20Strategies%20-%20https%3a%2f%2ftrunghng.github.io%2fposts%2fevolution-strategy%2fnes%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Natural Evolution Strategies on telegram" href="https://telegram.me/share/url?text=Natural%20Evolution%20Strategies&amp;url=https%3a%2f%2ftrunghng.github.io%2fposts%2fevolution-strategy%2fnes%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Natural Evolution Strategies on ycombinator" href="https://news.ycombinator.com/submitlink?t=Natural%20Evolution%20Strategies&u=https%3a%2f%2ftrunghng.github.io%2fposts%2fevolution-strategy%2fnes%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></div></footer><script src=https://utteranc.es/client.js repo=trunghng/trunghng.github.io issue-term=pathname theme=github-light crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2023 <a href=https://trunghng.github.io>Littleroot</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>