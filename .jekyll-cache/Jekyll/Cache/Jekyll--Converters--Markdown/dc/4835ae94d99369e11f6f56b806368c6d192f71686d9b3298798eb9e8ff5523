I"V
<p>Since I don’t know how to begin with this post, why not just dive straight into details :P<br />
Markov chain is a stochastic process in which the random variables follow a special property called Markov</p>

<h3 id="markov-property">Markov property</h3>
<p>A sequence of random variables $X_0, X_1, X_2, \dots$ taking values in the <em>state space</em> $S=${$1, 2,\dots, M$}. For all $n\geq0$,
\begin{equation}
P(X_{n+1}=j|X_n=i)=P(X_{n+1}|X_n=i,X_{n-1}=i_{n-1},X_{n-2}=i_{n-2},\dots,X_0=i_0)
\end{equation}
In other words, knowledge of the preceding state is all we need to determine the probability distribution of the current state.</p>

<h3 id="transition-matrix">Transition matrix</h3>
<p>The quantity $P(X_{n+1}=j|X_n=i)$ is <em>transition probability</em> from state $i$ to $j$.<br />
If we denote that $q_{ij}=P(X_{n+1}=j|X_n=i)$ and let $Q=(q_{ij})$, which is a $M\times M$ matrix, there we have the <em>transition matrix</em> $Q$ of the chain.<br />
Therefore, each row of $Q$ is a conditional probability mass function (PMF) of $X_{n+1}$ given $X_n$. And hence, sum of its entries is 1.</p>

<h4 id="n-step-transition-probability">n-step transition probability</h4>
<p>The n-step transition probability from $i$ to $j$ is the probability of being at $i$ and $n$ steps later being at $j$, and be denoted as $q_{ij}^{(n)}$,
\begin{equation}
q_{ij}^{(n)}=P(X_n=j|X_0=i)
\end{equation}
We have that
\begin{equation}
q_{ij}^{(2)}=\sum_{k}^{}q_{ik}q_{kj}
\end{equation}
since it has to go through an intermediary step $k$ to reach $j$ in 2 steps from $i$. It’s easily seen that the right hand side is $Q_{ij}^2$. And by induction, we have that:
\begin{equation}
q_{ij}^{(n)}=Q_{ij}^{n}
\end{equation}
$Q^n$ is also called the <em>n-step transition matrix</em>.</p>

<h4 id="marginal-distribution-of-x_n">Marginal distribution of $X_n$</h4>
<p>Let $t=(t_1,\dots,t_M)^T$, where $t_i=P(X_0=i)$. By the law of total probability (LOTP), we have that:
\begin{align}
P(X_n=j)&amp;=\sum_{i=1}^{M}P(X_0=i)P(X_n=j|X_0=i) \\&amp;=\sum_{i=1}^{M}t_iq_{ij}^{(n)}
\end{align}
or the marginal distribution of $X_n$ is given by $tQ^n$.</p>

<h3 id="properties">Properties</h3>
<ul>
  <li>State $i$ of a Markov chain is defined as <em>recurrent</em> or <em>transient</em> depending upon whether or not the Markov chain will eventually return to it. Starting with <em>recurrent</em> state i, the chain will return to it with the probability of 1. Otherwise, it is <em>transient</em>.
    <ul>
      <li>Proposition: Number of returns to transient state is Geom($p$), with $p$ is the probability of never returning to $i$.</li>
    </ul>
  </li>
</ul>

:ET