I"‚<blockquote>
  <p>So far in this <a href="/tag/my-rl">series</a>, we have gone through ideas of <a href="/artificial-intelligent/reinforcement-learning/2021/07/25/dp-in-mdp.html"><strong>dynamic programming</strong> (DP)</a> and <a href="/artificial-intelligent/reinforcement-learning/2021/08/21/monte-carlo-in-rl.html"><strong>Monte Carlo</strong></a>. What will happen if we combine these ideas together? <strong>Temporal-deffirence (TD) learning</strong> is our answer.</p>
</blockquote>

<!-- excerpt-end -->

<ul>
  <li><a href="#references">References</a></li>
  <li><a href="#footnotes">Footnotes</a></li>
</ul>

<h2 id="references">References</h2>
<p>[1] Richard S. Sutton &amp; Andrew G. Barto. <a href="https://mitpress.mit.edu/books/reinforcement-learning-second-edition">Reinforcement Learning: An Introduction</a></p>

<p>[2] David Silver. <a href="https://www.davidsilver.uk/teaching/">UCL course on RL</a></p>

<p>[3] Mnih, V., Kavukcuoglu, K., Silver, D. et al. <a href="https://doi.org/10.1038/nature14236">Human-level control through deep reinforcement learning</a>. Nature 518, 529â€“533 (2015).</p>

<h2 id="footnotes">Footnotes</h2>
:ET