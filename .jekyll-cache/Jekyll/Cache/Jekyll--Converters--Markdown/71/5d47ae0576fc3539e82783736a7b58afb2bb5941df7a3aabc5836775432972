I"X<blockquote>

  <!-- excerpt-end -->
  <ul>
    <li><a href="#fnn">Feedforward neural networks</a>
      <ul>
        <li><a href="#xor">The XOR function</a></li>
      </ul>
    </li>
    <li><a href="#references">References</a></li>
    <li><a href="#footnotes">Footnotes</a></li>
  </ul>
</blockquote>

<h2 id="fnn">Feedforward neural networks</h2>

<h3 id="xor">The XOR function</h3>
<p>The <strong>XOR function</strong> (or <strong>exclusive or function</strong>), denoted as $f:\{0,1\}\times\{0,1\}\to\{0,1\}$, is defined as:
\begin{align}
f(0,0)&amp;=0, \\ f(0,1)&amp;=1, \\ f(1,0)&amp;=1, \\ f(1,1)&amp;=0,
\end{align}
or by words, $f(x_1,x_2)=1$ only if exactly one of the two binary inputs having the value of $1$, otherwise it returns the value of $0$.</p>

<p>Suppose given a set of four points $\mathbb{X}=\left\{(0,0),(0,1),(1,0),(1,1)\right\}$ and their projected value of them on $f$ space, $\hat{f}(\mathbf{x}),\mathbf{x}\in\mathbb{X}$, we are trying to learn the XOR by a feedforward network</p>

<p>\begin{equation}
f(\mathbf{x};mathbf{w},b)=\mathbf{x}^\intercal\mathbf{w}+b
\end{equation}
The MSE</p>

<h2 id="references">References</h2>
<p>[1] joelgrus <a href="https://github.com/joelgrus/joelnet">JoelNet</a>.</p>

<p>[2] Ian Goodfellow &amp; Yoshua Bengio &amp; Aaron Courville. <a href="https://www.deeplearningbook.org">Deep Learning</a>. MIT Press (2016).</p>

<p>[3] Adrew Ng. <a href="https://coursera.com">Deep Learning Specialization</a>. Coursera.</p>

<p>[4] Pytorch Documentation <a href="https://pytorch.org/docs/stable/index.html">Pytorch Docs</a>.</p>

<h2 id="footnotes">Footnotes</h2>
:ET