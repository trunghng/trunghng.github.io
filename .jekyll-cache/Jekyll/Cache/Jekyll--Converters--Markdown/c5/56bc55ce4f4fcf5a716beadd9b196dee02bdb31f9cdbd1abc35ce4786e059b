I"<blockquote>

  <!-- excerpt-end -->
</blockquote>

<ul>
  <li><a href="#references">References</a></li>
  <li><a href="#footnotes">Footnotes</a></li>
</ul>

<h2 id="references">References</h2>
<p>[1] Richard S. Sutton &amp; Andrew G. Barto. <a href="https://mitpress.mit.edu/books/reinforcement-learning-second-edition">Reinforcement Learning: An Introduction</a>.</p>

<p>[2] C. B. Browne et al. <a href="https://ieeexplore.ieee.org/document/6145622">A Survey of Monte Carlo Tree Search Methods</a>, in IEEE Transactions on Computational Intelligence and AI in Games, vol. 4, no. 1, pp. 1-43, March 2012.</p>

<p>[3] Kocsis, L. &amp; Szepesvári, C. (2006). <a href="https://doi.org/10.1007/11871842_29">Bandit Based Monte-Carlo Planning</a>. In: Fürnkranz, J., Scheffer, T., Spiliopoulou, M. (eds) Machine Learning: ECML 2006. ECML 2006. Lecture Notes in Computer Science, vol 4212. Springer, Berlin, Heidelberg.</p>

<p>[4] David Silver &amp; Julian Schrittwieser &amp; Karen Simonyan et al. <a href="https://doi.org/10.1038/nature24270">Mastering the game of Go without human knowledge</a>. Nature 550, 354–359 (2017).</p>

<p>[5] David Silver &amp; Thomas Hubert &amp; Julian Schrittwieser et al. <a href="https://arxiv.org/abs/1712.01815">Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm</a>. arXiv.</p>

<p>[6] Shangtong Zhang. <a href="https://github.com/ShangtongZhang/reinforcement-learning-an-introduction">Reinforcement Learning: An Introduction implementation</a>.</p>

<h2 id="footnotes">Footnotes</h2>
:ET