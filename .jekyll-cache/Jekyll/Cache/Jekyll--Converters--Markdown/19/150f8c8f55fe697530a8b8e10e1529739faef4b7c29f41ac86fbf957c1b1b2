I"´<blockquote>
  <p>Recall that when using <a href="/2021/07/25/dp-in-mdp.html"><strong>Dynamic Programming</strong></a> algorithms to solve RL problems, we made an assumption about the complete knowledge of the environment. With <strong>Monte Carlo</strong> methods, we only require <strong>experience</strong> - sample sequences of states, actions, and rewards from simulated or real interaction with an environment.</p>
</blockquote>

:ET