I"|<p>Since I don’t know how to begin with this post, why not just dive straight into details :P<br />
Markov chain is a stochastic process in which the random variables follow a special property called Markov</p>

<h3 id="markov-property">Markov property</h3>
<p>A sequence of random variables $X_0, X_1, X_2, \dots$ taking values in the <em>state space</em> $S$. For all $n\geq0$,
\begin{equation}
P(X_{n+1}=j|X_n=i)=P(X_{n+1}|X_n=i,X_{n-1}=i_{n-1},X_{n-2}=i_{n-2},\dots,X_0=i_0)
\end{equation}
In other words, knowledge of the preceding state is all we need to determine the probability distribution of the current state.</p>

<h3 id="transition-matrix">Transition matrix</h3>
<p>The quantity $P(X_{n+1}=j|X_n=i)$ is <em>transition probability</em> from state $i$ to $j$.<br />
If we denote that $q_{ij}=P(X_{n+1}=j|X_n=i)$ and let $Q=(q_{ij})$, which is a $|S|\times|S|$ matrix, there we have the <em>transition matrix</em> $Q$ of the chain.<br />
Therefore, each row of $Q$ is a probability vector. And hence, sum of its entries is 1.</p>

<h4 id="n-step-transition-probability">n-step transition probability</h4>
<p>The n-step transition probability from $i$ to $j$ is the probability of being at $i$ and $n$ steps later being at $j$, and be denoted as $q_{ij}^{(n)}$,
\begin{equation}
q_{ij}^{(n)}=P(X_n=j|X_0=i)
\end{equation}
We have that
\begin{equation}
q_{ij}^{(2)}=\sum_{k}^{}q_{ik}q_{kj}
\end{equation}
since it has to go through an intermediary step $k$ to reach $j$ in 2 steps from $i$. It’s easily seen that the right hand side is $Q^2<em>{ij}$. And by induction, we have that:
\begin{equation}
q</em>{ij}^{(n)}=Q_{ij}^{n}
\end{equation}</p>
:ET