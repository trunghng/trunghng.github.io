I"'<p>In the previous post about <a href="/artificial-intelligent/reinforcement-learning/2021/06/27/mdp-bellman-eqn.html"><strong>Markov Descision Process (MDP) and Bellman equations</strong></a>, we mentioned that there exists a policy $\pi_*$ that is better than or equal to all other policies. And now, we are here prove it.<br />
<!-- excerpt-end --></p>

<p>Before catching the pokémon, we need to prepare ourselves some pokéball.</p>

<h3 id="norms-contractions-and-banachs-fixed-point-theorem">Norms, Contractions and Banach’s Fixed-point Theorem</h3>
<p><strong>Definition</strong> (<em>Norm</em>)<br />
Given a vector space $\mathcal{V}\subseteq\mathbb{R}^d$, a function $f:\mathcal{V}\to\mathbb{R}^+_0$ is a <em>norm</em> if and only if</p>
<ol>
  <li>If $f(v)=0$ for some $v\in\mathcal{V}$, then $v=0$</li>
  <li>For any $\lambda\in\mathbb{R},v\in\mathcal{V},f(\lambda v)=|\lambda|v$</li>
  <li>For any $u,v\in\mathbb{R}, f(u+v)\leq f(u)+f(v)$</li>
</ol>

<p><strong>Examples</strong> (<em>Norm</em>)</p>
<ol>
  <li>$\ell^p$ norms: for $p\geq 1$,
\begin{equation}
\Vert v\Vert_p=\left(\sum_{i=1}^{d}|v_i|^p\right)^{1/p}
\end{equation}</li>
  <li>$\ell^\infty$ norms:
\begin{equation}
\Vert v\Vert_\infty=\max_{1\leq i\leq d}|v_i|
\end{equation}</li>
  <li>$\ell^{\mu,p}$: the weighted variants of these norm are defined as
\begin{equation}
\Vert v\Vert_p=\begin{cases}\left(\sum_{i=1}^{d}\frac{|v_i|^p}{w_i}\right)^{1/p}&amp;\text{if }1\leq p&lt;\infty\\ \max_{1\leq i\leq d}\frac{|v_i|}{w_i}&amp;\text{if }p=\infty\end{cases}
\end{equation}</li>
  <li>$\ell^{2,P}$: the matrix-weighted 2-norm is defined as
\begin{equation}
\Vert v\Vert^2_P=v^TPv
\end{equation}</li>
</ol>

<p><strong>Definition</strong> (<em>Convergence in norm</em>)<br />
Let $\mathcal{V}=(\mathcal{V},\Vert\cdot\Vert)$ be a <em>normed vector space</em><sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>. Let $v_n\in\mathcal{V}$ is a sequence of vectors ($n\in\mathbb{N}$). The sequence ($v_n,n\geq0$) is said to <em>converge to</em> $v\in\mathcal{V}$ in the norm $\Vert\cdot\Vert$, denoted as $v_n\to_{\Vert\cdot\Vert}v$ if
\begin{equation}
\lim_{n\to\infty}\Vert v_n-v\Vert=0,
\end{equation}
<br /></p>

<p><strong>Definition</strong> (<em>Cauchy sequence</em><sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup>)<br />
Let ($v_n;n\geq0$) be a sequence of vectors of a normed vector space $\mathcal{V}=(\mathcal{V},\Vert\cdot\Vert)$. Then $v_n$ is called a <em>Cauchy sequence</em> if
\begin{equation}
\lim_{n\to\infty}\sup_{m\geq n}\Vert v_n-v_m\Vert=0
\end{equation}
Normed vector spaces where all Cauchy sequences are convergent are special: we can find examples of normed vector spaces such that some of the Cauchy sequences in the vector space do not have a limit.<br />
<br /></p>

<p><strong>Definition</strong> (<em>Completeness</em>)<br />
A normed vector space $\mathcal{V}=(\mathcal{V},\Vert\cdot\Vert)$ is called <em>complete</em> if every Cauchy sequence in $\mathcal{V}$ is convergent in the norm of the vector space.<br />
<br /></p>

<p><strong>Definition</strong> (<em>Banach space</em>)<br />
A complete, normed vector space is called a <em>Banach space</em>.<br />
<br /></p>

<p><strong>Definition</strong> (<em>Lipschitzian</em>) <br />
Let $\mathcal{V}=(\mathcal{V},\Vert\cdot\Vert)$ be a normed vector space. A mapping $\mathcal{T}:\mathcal{V}\to\mathcal{V}$ is called <em>L-Lipschitz</em> if for any $u,v\in\mathcal{V}$,
\begin{equation}
\Vert\mathcal{T}u-\mathcal{T}v\Vert\leq L\Vert u-v\Vert
\end{equation}
A mapping $\mathcal{T}$ is called a <em>non-expansion</em> if it is <em>Lipschitzian</em> with $L\leq1$. It is called a <em>contraction</em> if it is <em>Lipschitzian</em> with $L&lt;1$. In this case, $L$ is called the <em>contraction factor of</em> $\mathcal{T}$ and $\mathcal{T}$ is called an <em>L-contraction</em>.<br />
<ins>Note</ins>: If $\mathcal{T}$ is <em>Lipschitz</em>, it is also continuous in the sense that if $v_n\to_{\Vert\cdot\Vert}v$, then also $\mathcal{T}v_n\to_{\Vert\cdot\Vert}\mathcal{T}v$. This is because $\Vert\mathcal{T}v_n-\mathcal{T}v\Vert\leq L\Vert v_n-v\Vert\to0$ as $n\to\infty$.<br />
<br /></p>

<p><strong>Defintion</strong> (<em>Fixed point</em>)<br />
Let $\mathcal{T}:\mathcal{V}\to\mathcal{V}$ be some mapping. The vector $v\in\mathcal{V}$ is called a <em>fixed point of</em> $\mathcal{T}$ if $\mathcal{T}v=v$.<br />
<br /></p>

<p><strong>Theorem</strong> (<em>Banach’s fixed-point</em><sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">3</a></sup>)<br />
Let $\mathcal{V}$ be a Banach space and $\mathcal{T}:\mathcal{V}\to\mathcal{V}$ be a $\gamma$-contraction mapping. Then</p>
<ol>
  <li>$\mathcal{T}$ admits a <em>unique fixed point</em> $v$.</li>
  <li>For any $v_0\in\mathcal{V}$, if $v_{n+1}=\mathcal{T}v_n$, then $v_n\to_{\Vert\cdot\Vert}v$ with a <em>geometric convergence rate</em><sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote" rel="footnote">4</a></sup>:
\begin{equation}
\Vert v_n-v\Vert\leq\gamma^n\Vert v_0-v\Vert
\end{equation}</li>
</ol>

<h3 id="bellman-operator">Bellman Operator</h3>
<p>Previously, we defined Bellman equation for state-value function $v_\pi(s)$ as:
\begin{align}
v_\pi(s)&amp;=\sum_{a\in\mathcal{A}}\pi(a|s)\sum_{s’\in\mathcal{S},r}p(s’,r|s,a)\left[r+\gamma v_\pi(s’)\right]\tag{1}\label{1} \\\text{or}\quad v_\pi(s)&amp;=\sum_{a\in\mathcal{A}}\pi(a|s)\left(\mathcal{R}^a_s+\gamma\sum_{s’\in\mathcal{S}}\mathcal{P}^a_{ss’}v_\pi(s’)\right)\tag{2}\label{2}
\end{align}
If we let
\begin{align}
\mathcal{P}^\pi_{ss’}&amp;=\sum_{a\in\mathcal{A}}\pi(a|s)\mathcal{P}^a_{ss’};\tag{3}\label{3} \\\mathcal{R}^\pi_s&amp;=\sum_{a\in\mathcal{A}}\pi(a|s)\mathcal{R}^a_s\tag{4}\label{4}
\end{align}
then we can rewrite \eqref{2} in another form as
\begin{equation}
v_\pi(s)=\mathcal{R}^\pi_s+\gamma\sum_{s’\in\mathcal{S}}\mathcal{P}^\pi_{ss’}v_\pi(s’)\tag{5}\label{5}
\end{equation}
<br />
<strong>Definition</strong> (<em>Bellman operator</em>)<br />
We define the <em>Bellman operator</em> underlying $\pi,\mathcal{T}:\mathbb{R}^\mathcal{S}\to\mathbb{R}^\mathcal{S}$, by:
\begin{equation}
(\mathcal{T}^\pi v)(s)=\mathcal{R}^\pi_s+\gamma\sum_{s’\in\mathcal{S}}\mathcal{P}^\pi_{ss’}v(s’) \tag{6}\label{6}
\end{equation}
<br />
With the help of $\mathcal{T}^\pi$, equation \eqref{5} can be rewrite as:
\begin{equation}
\mathcal{T}^\pi v_\pi=v_\pi\tag{7}\label{7}
\end{equation}
Similarly, we can rewrite the <em>Bellman optimality equation for</em> $v_*$
\begin{align}
v_*(s)&amp;=\max_{a\in\mathcal{A}}\sum_{s’\in\mathcal{S},r}p(s’,r|s,a)\left[r+\gamma v_*(s’)\right]\tag{8}\label{8} \\ &amp;=\max_{a\in\mathcal{A}}\left(\mathcal{R}^a_s+\gamma\sum_{s’\in\mathcal{S}}\mathcal{P}^a_{ss’}v_*(s’)\right)\tag{9}\label{9}
\end{align}
and thus, we can define the <em>Bellman optimality operator</em> $\mathcal{T}^*:\mathcal{R}^\mathcal{S}\to\mathcal{R}^\mathcal{S}$, by:
\begin{equation}
(\mathcal{T}^* v)(s)=\max_{a\in\mathcal{A}}\left(\mathcal{R}^a_s+\gamma\sum_{s’\in\mathcal{S}}\mathcal{P}^a_{ss’}v(s’)\right)\tag{10}\label{10}
\end{equation}
And thus, with the help of $\mathcal{T}^*$, we can rewrite the equation \eqref{9} as:
\begin{equation}
\mathcal{T}^*v_*=v_*\tag{11}\label{11}
\end{equation}
<br />
Now everything is all set, we can move on to the next step.</p>
<ul>
  <li>Let $B(\mathcal{S})$ be the space of <em>uniformly bounded functions</em><sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote" rel="footnote">5</a></sup> with domain $\mathcal{S}$:
\begin{equation}
B(\mathcal{S})=\{v:\mathcal{S}\to\mathbb{R}:\Vert v\Vert_\infty&lt;+\infty\}
\end{equation}</li>
  <li>
    <p>We will view $B(\mathcal{S})$ as a normed vector space with the norm $\Vert\cdot\Vert_\infty$. It is easily seen that $(B(\mathcal{S}),\Vert\cdot\Vert_\infty)$ is complete: If ($v_n;n\geq0$) is a Cauchy sequence in it then for any $s\mathcal{S}$, ($v_n(s);n\geq0$) is also a Cauchy sequence over the reals. Denoting by $v(s)$ the limit of ($v_n(s)$), we can show that $\Vert v_n-v\Vert_\infty\to0$. Vaguely speaking, this holds because ($v_n;n\geq0$) is a Cauchy sequence in the norm $\Vert\cdot\Vert_\infty$  so the rate of convergence of $v_n(s)$ to $v(s)$ is independent of $s$.</p>
  </li>
  <li>Pick any stationary policy $\pi$.</li>
  <li>We have that $\mathcal{T}^\pi$ is <em>well-defined</em><sup id="fnref:6" role="doc-noteref"><a href="#fn:6" class="footnote" rel="footnote">6</a></sup> since: if $u\in B(\mathcal{S})$, then also $\mathcal{T}^\pi u\in B(S)$.</li>
  <li>From equation \eqref{7}, we have that $v_\pi$ is a fixed point to $\mathcal{T}^\pi$.<br />
We also have that $\mathcal{T}^\pi$ is a contraction in $\Vert\cdot\Vert_\infty$ since for any $u, v\in B(\mathcal{S})$,
\begin{align}
\Vert\mathcal{T}^\pi u-\mathcal{T}^\pi v\Vert_\infty&amp;=\gamma\max_{s\in\mathcal{S}}\left|\sum_{s’\in\mathcal{S}}\mathcal{P}^\pi_{ss’}\left(u(s’)-v(s’)\right)\right|
\end{align}</li>
</ul>

<h4 id="footnotes">Footnotes</h4>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">

      <p><a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">

      <p><a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">

      <p><a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:4" role="doc-endnote">

      <p><a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">

      <p><a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:6" role="doc-endnote">

      <p><a href="#fnref:6" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
:ET