I"ÕY<blockquote>
  <p>A note on convex sets, convex functions</p>
</blockquote>

<!-- excerpt-end -->

<ul>
  <li><a href="#cvx-sets">Convex sets</a>
    <ul>
      <li><a href="#aff-cvx-sets">Affine &amp; convex sets</a>
        <ul>
          <li><a href="#aff-sets">Affine sets</a></li>
          <li><a href="#aff-dim-rel-int">Affine dimension, relative interior</a></li>
          <li><a href="#cvx-sets-def">Convex sets</a></li>
          <li><a href="#cones">Cones</a></li>
        </ul>
      </li>
      <li><a href="#cvx-sets-eg">Examples</a>
        <ul>
          <li><a href="#hyperplane-halfspaces">Hyperplanes, halfspaces</a></li>
          <li><a href="#balls-ellips-cones">Balls, ellipsoids, norm cones</a>
            <ul>
              <li><a href="#balls">Balls</a></li>
              <li><a href="#ellips">Ellipsoids</a></li>
              <li><a href="#norm-cones">Norm cones</a></li>
            </ul>
          </li>
          <li><a href="#polyhedra">Polyhedra</a>
            <ul>
              <li><a href="#non-neg-orthant">Nonnegative orthant</a></li>
              <li><a href="#simplex">Simplex</a></li>
            </ul>
          </li>
          <li><a href="#psd-cone">Positive semi-definite cone</a></li>
        </ul>
      </li>
      <li><a href="#operations-sets">Operations that preserve convexity</a>
        <ul>
          <li><a href="#intersect">Intersection</a></li>
          <li><a href="#aff-funcs">Affine functions</a></li>
          <li><a href="#lin-frac-persp-funcs">Linear-fractional, perspective functions</a>
            <ul>
              <li><a href="#persp-funcs">Perspective functions</a></li>
              <li><a href="#lin-frac-funcs">Linear-fractional functions</a></li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#cvx-funcs">Convex functions</a>
    <ul>
      <li><a href="#props">Properties</a>
        <ul>
          <li><a href="#st-order-conds">First-order conditions</a></li>
          <li><a href="#nd-order-conds">Second-order conditions</a></li>
        </ul>
      </li>
      <li><a href="#cvx-funcs-eg">Examples</a></li>
      <li><a href="#sub-lvl-sets">Sub-level sets</a></li>
      <li><a href="#inequalities">Inequalities</a>
        <ul>
          <li><a href="#jensens-inequality">Jensenâ€™s inequality</a></li>
        </ul>
      </li>
      <li><a href="#operations-funcs">Operations that preserve convexity</a></li>
      <li><a href="#conjugate-func">The conjugate function</a></li>
      <li><a href="#quasi-cvx-funcs">Quasiconvex functions</a></li>
    </ul>
  </li>
  <li><a href="#references">References</a></li>
  <li><a href="#footnotes">Footnotes</a></li>
</ul>

<h2 id="cvx-sets">Convex sets</h2>

<h3 id="aff-cvx-sets">Affine &amp; convex sets</h3>

<h4 id="aff-sets">Affine sets</h4>
<p>A set $C\subset\mathbb{R}^n$ is <strong>affine</strong> if the line through any two distinct points in $C$ lies in $C$, i.e. for any $x_1,x_2\in C$ and for any $\theta\in\mathbb{R}$ we have
\begin{equation}
\theta x_1+(1-\theta)x_2\in C
\end{equation}
A point of the form $\theta_1 x_1+\ldots+\theta_k x_k$, where $\theta_1+\ldots+\theta_k=1$ is known as an <strong>affine combination</strong> of the points $x_1,\ldots,x_k$.</p>

<p>Hence, if $C$ is an affine set, and $x_1,\ldots,x_k\in C$, and $\theta_1+\ldots+\theta_k=1$, then the point
\begin{equation}
\theta_1 x_1+\ldots+\theta_k x_k\in C,
\end{equation}
or in other words, an affine set contains every affine combination of its points.</p>

<p>If $C$ is an affine set and $x_0\in C$, then the set
\begin{equation}
V=C-x_0\{x-x_0:x\in C\}
\end{equation}
is a subspace.</p>

<p>The set of all affine combinations of points in some set $C\subset\mathbb{R}^n$ is referred as <strong>affine hull</strong> of $C$, denoted as $\text{aff}\,C$:
\begin{equation}
\text{aff}\,C=\{\theta_1 x_1+\ldots+\theta_k x_k:x_1,\ldots,x_k\in C;\theta_1+\ldots+\theta_k=1\}
\end{equation}
The affine hull is the <em>smallest</em> affine set containing $C$.</p>

<h4 id="aff-dim-rel-int">Affine dimension, relative interior</h4>
<p>The <strong>affine dimension</strong> of a set $C$ is defined as the dimension of $\text{aff}\,C$.</p>

<p>If the affine dimension of $C\subset\mathbb{R}^n$ is less than $n$, then the set lies in $\text{aff}\,C\neq\mathbb{R}^n$. The <strong>relative interior</strong> of the set $C$, denoted as $\text{relint}\,C$, is defined as its interior relative to $\text{aff}\,C$:
\begin{equation}
\text{relint}\,C=\{x\in C:B(x,r)\cap\text{aff}\,C\in C\text{ for some }r&gt;0\},
\end{equation}
where $B(x,r)$ is the ball centered at $x$ with radius $r$ in the norm $\Vert\cdot\Vert$ (here $\Vert\cdot\Vert$ could be any norm; all norms define the same relative interior).</p>

<p>The <strong>relative boundary</strong> of $C$ is defined as $\overline{C}\backslash\text{relint}\,C$, where $\overline{C}$ is the closure of $C$.</p>

<h4 id="cvx-sets-def">Convex sets</h4>
<p>A set $C$ is <strong>convex</strong> if the line segment between any points in $C$ also lies in $C$, i.e. for any $x_1,x_2\in C$ and for any $0\leq\theta\leq 1$, we have
\begin{equation}
\theta x_1+(1-\theta)x_2\in C
\end{equation}
It is then easily seen that every affine sets is also convex.</p>

<p>Analogy to affine sets, we also refer a point of the form $\theta_1 x_1+\ldots+\theta_k x_k$, where $\theta_1+\ldots+\theta_k=1$ and $\theta_i\geq 0,\forall i=1,\ldots,k$, a <strong>convex combination</strong> of the points $x_1,\ldots,x_k$. And a set is convex iff it contains every convex combination of its points.</p>

<p>The <strong>convex hull</strong> of $C$, denoted by $\text{conv}\,C$, is defined as the set of all convex combinations of points in $C$:
\begin{equation}
\text{conv}\,C=\{\theta_1 x_1+\ldots+\theta_k x_k:x_1,\ldots,x_k\in C;\theta_1+\ldots+\theta_k=1;\theta_1,\ldots,\theta_k\geq 0\}
\end{equation}
Thus, $\text{conv}\,C$ is convex and is the smallest convex set containing $C$.</p>

<p>We can generalize the definition of convex combination into: let $x_1,x_2\ldots\in C$ where $C\subset\mathbb{R}^n$ and let $\{\theta_n\}_{n=1,2,\ldots}$ be a countable sequence such that
\begin{equation}
\sum_{i=1}^{\infty}\theta_i=1;\hspace{2cm}\theta_i\geq 0,\hspace{0.5cm}\forall i=1,2,\ldots
\end{equation}
Then the series
\begin{equation}
\sum_{i=1}^{\infty}\theta_i x_i\in C,
\end{equation}
if it converges.</p>

<p>More generally, suppose $p:\mathbb{R}^n\to\mathbb{R}$ satisfies $p(x)\geq 0$ forall $x\in C$ and $\int_C p(x)\,dx=1$, where $C\subset\mathbb{R}^n$ is a convex set. Then the integral
\begin{equation}
\int_C p(x)x\,dx\in C
\end{equation}
if it exists.</p>

<p>In the most general form, suppose $C\subset\mathbb{R}^n$ is convex and $x$ is a random vector with $x\in C$ with probability one. Then we also have that
\begin{equation}
\mathbb{E}x\in C
\end{equation}</p>

<h4 id="cones">Cones</h4>
<p>A set $C$ is called a <strong>cone</strong>, or <strong>nonnegative homogeneous</strong>, if for every $x\in C$ and for any $\theta\geq 0$, we also have $\theta x\in C$.</p>

<p>A <strong>convex cone</strong> $C$ is both convex and a cone, i.e. for any $x_1,x_2\in C$ and for any $\theta_1,\theta_2\geq 0$, we have
\begin{equation}
\theta_1 x_1+\theta_2 x_2\in C
\end{equation}
since by definition of a cone, we can add a normalization factor $\alpha$ into the point above
\begin{equation}
\alpha\theta_1 x_1+\alpha\theta_2 x_2
\end{equation}
such that $\alpha\theta_1+\alpha\theta_2=1$ (in this particular case, $\alpha=1/(\theta_1+\theta_2)$).</p>

<p>A point of the form $\theta_1 x_1+\ldots+\theta_k x_k$ with $\theta_1,\ldots,\theta_k\geq 0$ is called a <strong>conic combination</strong>. It is easily seen that a set $C$ is a convex cone iff it contains all conic combinations of its points.
Like convex and affine combinations, we can generalize the definition of conic combination into infinite series and integrals.</p>

<p>We define the <strong>conic hull</strong> of a set $C$ as the set of all conic combinations of elements in $C$
\begin{equation}
\{\theta_1 x_1+\ldots+\theta_k x_k:x_i\in C;\theta_i\geq 0,\forall i=1,\ldots,k\}
\end{equation}
Also, the conic hull of $C$ is the smallest convex cone containing $C$.</p>

<h3 id="cvx-sets-eg">Examples</h3>

<h4 id="hyperplane-halfspaces">Hyperplanes, halfspaces</h4>
<p>A <strong>hyperplane</strong> $P$ is a set of form
\begin{equation}
P=\{x\in\mathbb{R}^n:a^\text{T}x=b\},
\end{equation}
where $a\in\mathbb{R}^n$, $a\neq 0$ and $b\in\mathbb{R}$. We have that $P$ is convex.</p>

<p>To prove this, for $x_1,x_2\in P$, and for any $0\leq\theta\leq 1$, we have
\begin{equation}
a^\text{T}\big(\theta x_1+(1-\theta)x_2\big)=\theta a^\text{T}x_1+(1-\theta)a^\text{T}x_2=\theta b+(1-\theta)b=b
\end{equation}</p>

<p>A hyperplane separates $\mathbb{R}^n$ into two <strong>halfspaces</strong>. A (closed) halfspace is a set of of the form
\begin{equation}
\{x\in\mathbb{R}^n:a^\text{T}x\leq b\},
\end{equation}
where $a\in\mathbb{R}^n$, $a\neq 0$ and $b\in\mathbb{R}$. It is also easily seen that halfspaces are also convex.</p>

<h4 id="balls-ellips-cones">Balls, ellipsoids, norm cones</h4>

<h5 id="balls">Balls</h5>
<p>A (closed) <strong>ball</strong> in $\mathbb{R}^n$ centered at $x_c$ and with radius $r$ and with $\Vert\cdot\Vert$ is any norm in $\mathbb{R}^n$
\begin{equation}
B(x_c,r)=\{x\in\mathbb{R}^n:\Vert x-x_c\Vert\leq r\}
\end{equation}
is a convex set.</p>

<p>To see this, for any $x_1,x_2\in B(x_c,r)$ and for any $0\leq\theta\leq 1$, by triangle inequality of norm, we have
\begin{align}
\Vert\theta x_1+(1-\theta)x_2-x_c\Vert&amp;=\Vert\theta(x_1-x_c)+(1-\theta)(x_2-x_c)\Vert \\ &amp;\leq\theta\Vert x_1-x_c\Vert+(1-\theta)\Vert x_2-x_c\Vert \\ &amp;\leq\theta r+(1-\theta)r \\ &amp;=r
\end{align}</p>

<h5 id="ellips">Ellipsoids</h5>
<p>An <strong>ellipsoid</strong> $\mathcal{E}$ in $\mathbb{R}^n$ centered at $x_c\in\mathbb{R}^n$ is defined as
\begin{equation}
\mathcal{E}=\{x:(x-x_c)^\text{T}P^{-1}(x-x_c)\leq 1\},
\end{equation}
where $P\in\mathbb{R}^{n\times n}$ is symmetric and positive definite. The matrix $P$ determines how far $\mathcal{E}$ extends in every direction from $x_c$; the lengths of the semi-axes of $\mathcal{E}$ are $\sqrt{\lambda_i}$, where $\lambda_i$ for $i=1,\ldots,n$ are the eigenvalues of $P$. A ball of radius $r$ is an ellipsoid with
\begin{equation}
P=r^2 I
\end{equation}
We then have $\mathcal{E}$ is convex.</p>

<p>To prove this claim, as usual, for $x_1,x_2\in\mathcal{E}$ and for $0\leq\theta\leq 1$, we have
\begin{align}
&amp;\hspace{0.7cm}\big(\theta x_1+(1-\theta)x_2-x_c\big)^\text{T}P^{-1}\big(\theta x_1+(1-\theta)x_2-x_c\big) \\ &amp;=\big(\theta x_1-\theta x_c+(1-\theta)x_2-(1-\theta)x_c\big)^\text{T}P^{-1}\big(\theta x_1-\theta x_c+(1-\theta)x_2-(1-\theta)x_c\big) \\ &amp;=(a+b)^\text{T}P^{-1}(a+b) \\ &amp;=a^\text{T}P^{-1}a+b^\text{T}P^{-1}b+2a^\text{T}P^{-1}b \\ &amp;\leq\theta^2+(1-\theta)^2+2\theta(1-\theta) \\ &amp;=1
\end{align}
where in the second step, we have let
\begin{equation}
a=\theta x_1-\theta x_c,\hspace{2cm}b=(1-\theta)x_2-(1-\theta)x_c,
\end{equation}
which implies that
\begin{equation}
a^\text{T}P^{-1}a\leq 1,\hspace{2cm}b^\text{T}P^{-1}b\leq 1
\end{equation}
and thus
\begin{equation}
a^\text{T}P^{-1/2}\leq 1,\hspace{2cm}b^\text{T}P^{-1/2}\leq 1
\end{equation}</p>

<h5 id="norm-cones">Norm cones</h5>
<p>A <strong>norm cone</strong> $C$ associated with the norm $\Vert\cdot\Vert$ is defined as
\begin{equation}
C=\{(x,t):\Vert x\Vert\leq t\}\subset\mathbb{R}^{n+1}
\end{equation}
is also convex</p>

<h4 id="polyhedra">Polyhedra</h4>
<p>A <strong>polyhedron</strong> $\mathcal{P}$ is defined as
\begin{equation}
\mathcal{P}=\{x:a_i^\text{T}\leq b_i,i=1,\ldots,m;c_j^\text{T}=d_j,j=1,\ldots,p\}
\end{equation}
Then $\mathcal{P}$ can be seen as the intersection of a finite number of halfspaces and hyperplanes. Another representation of $\mathcal{P}$ is
\begin{equation}
\mathcal{P}=\{x:Ax\preceq b,Cx=d\},
\end{equation}
where
\begin{equation}
A=\left[\begin{matrix}a_1^\text{T} \\ \vdots \\ a_m^\text{T}\end{matrix}\right],\hspace{2cm}C=\left[\begin{matrix}c_1^\text{T} \\ \vdots \\ c_p^\text{T}\end{matrix}\right]
\end{equation}
And thus, we also have that $\mathcal{P}$ is convex, which can be proved easily since $Ax$ and $Cx$ are both linear functions.</p>

<h5 id="non-neg-orthant">Nonnegative orthant</h5>
<p>The <strong>nonnegative orthant</strong> in $\mathbb{R}^n$, denoted $\mathbb{R}_+^{n}$, is the set of points with nonnegative components, i.e.
\begin{equation}
\mathbb{R}_+^n=\{x\in\mathbb{R}^n:x\succeq 0\}
\end{equation}
We have that $\mathbb{R}_+^n$ is both a polyhedron and a cone, or a <strong>polyhedral cone</strong>, and hence is also convex.</p>

<h5 id="simplex">Simplex</h5>
<p>Suppose the $v_0,\ldots,v_k\in\mathbb{R}^n$ are <strong>affinely independent</strong>, i.e. $v_1-v_0,\ldots,v_k-v_0$ are linearly independent. The <strong>simplex</strong> determined by them is given as
\begin{equation}
C=\text{conv}\{v_0,\ldots,v_k\}=\{\theta_0 v_0+\ldots+\theta_k v_k:\theta\succeq 0,\mathbf{1}^\text{T}\theta=1\}
\end{equation}
As an instance of polyhedra, $C$ is thus convex.</p>

<h4 id="psd-cone">Positive semi-definite cone</h4>
<p>Let $\mathbb{S}^n$ denote the set of symmetric $n\times n$ matrices
\begin{equation}
\mathbb{S}^n=\{X\in\mathbb{R}^{n\times n}:X=X^\text{T}\},
\end{equation}
and let $\mathbb{S}_+^n$ represent the set of symmetric positive semi-definite matrices
\begin{equation}
\mathbb{S}_+^n=\{X\in\mathbb{S}^n:X\succeq 0\},
\end{equation}
and finally, let us assign the set of symmetric positive definite matrices to $\mathbb{S}_{++}^n$
\begin{equation}
\mathbb{S}_{++}^n=\{X\in\mathbb{S}^n:X\succ 0\}
\end{equation}
We have that $\mathbb{S}_+^n$ is a convex cone, since for any matrices $A_1,A_2\in\mathbb{S}_+^n$, for any $\theta_1,\theta_2\geq 0$ and for any $x\in\mathbb{R}^n$, we have
\begin{equation}
x^\text{T}(\theta_1 A_1+\theta_2 A_2)x=\theta_1 x^\text{T}A_1 x+\theta_2 x^\text{T}A_2 x\geq 0
\end{equation}
The same argument can be applied to prove that $\mathbb{S}_{++}^n$ or even the set of symmetric negative definite matrices and the set of symmetric negative semi-definite matrices are convex.</p>

<h3 id="operations-sets">Operations that preserve convexity</h3>

<h4 id="intersect">Intersection</h4>
<p>Let $S_1,S_2$ be convex sets and let $x_1,x_2$ are two points containing in both sets, thus $x_1,x_2\in S_1\cap S_2$.</p>

<p>Since $x_1,x_2\in S_1$ which is convex, for $0\leq\theta\leq 1$, we have the point
\begin{equation}
\theta x_1+(1-\theta)x_2\in S_1
\end{equation}
Analogously, we also have
\begin{equation}
\theta x_1+(1-\theta)x_2\in S_2,
\end{equation}
which implies that
\begin{equation}
\theta x_1+(1-\theta)x_2\in S_1\cap S_2
\end{equation}
Or in other words, $S_1\cap S_2$ is also convex.</p>

<p>By induction, we can extend this property to: if $S_\alpha$ is convex for every $\alpha\in\mathcal{A}$, then their intersection
\begin{equation}
\bigcap_{\alpha\in\mathcal{A}}S_\alpha
\end{equation}
is also convex.</p>

<h4 id="aff-funcs">Affine functions</h4>
<p>A function $f:\mathbb{R}^n\to\mathbb{R}^m$ is <strong>affine</strong> if it is a sum of linear function and a constant, i.e. it can be written as
\begin{equation}
f(x)=Ax+b,
\end{equation}
where $A\in\mathbb{R}^{m\times n}$ and $b\in\mathbb{R}^m$.</p>

<p>Let $S\subset\mathbb{R}^n$ be a convex set and let $f:\mathbb{R}^n\to\mathbb{R}^m$ be an affine function. Then the image of $S$ under $f$
\begin{equation}
f(S)=\{f(x):x\in S\}
\end{equation}
is convex.</p>

<p>Analogously, the inverse image of $S$ under an affine function $g:\mathbb{R}^k\to\mathbb{R}^n$
\begin{equation}
g^{-1}(S)=\{x:g(x)\in S\}
\end{equation}
is convex.</p>

<p>The <strong>projection</strong> of a convex set $S\subset\mathbb{R}^m\times\mathbb{R}^n$ onto some of its coordinates
\begin{equation}
T=\{x_1\in\mathbb{R}^m:(x_1,x_2)\in S,\text{ for some }x_2\in\mathbb{R}^n\}
\end{equation}
is convex.</p>

<p>If $S_1,S_2$ are convex then so is their sum
\begin{equation}
S_1+S_2=\{x_1+x_2:x_1\in S_1,x_2\in S_2\}
\end{equation}
This is due to its reverse image under the linear function $f(x_1,x_2)=x_1+x_2$, which is the <strong>Cartesian product</strong>
\begin{equation}
S_1\times S_2=\{(x_1,x_2):x_1\in S_1,x_2\in S_2\}
\end{equation}
is convex.</p>

<h4 id="lin-frac-persp-funcs">Linear-fractional, perspective functions</h4>

<h5 id="persp-funcs">Perspective functions</h5>
<p>The <strong>perspective function</strong> $P:\mathbb{R}^{n+1}\to\mathbb{R}^n$, with domain $\text{dom}\,P=\mathbb{R}^n\times\mathbb{R}_{++}$ is defined as
\begin{equation}
P(z,t)=\frac{z}{t}
\end{equation}
Suppose that $x=(\tilde{x},x_{n+1}),y=(\tilde{y},y_{n+1})\in\mathbb{R}^{n+1}$ with $x_{n+1},y_{n+1}\gt 0$. Then for $0\leq\theta\leq 1$, we have
\begin{equation}
P(\theta x+(1-\theta)y)=\frac{\theta\tilde{x}+(1-\theta)\tilde{y}}{\theta x_{1+1}+(1-\theta)y_{n+1}}=\mu P(x)+(1-\mu)P(y),
\end{equation}
where
\begin{equation}
\mu=\frac{\theta x_{n+1}}{\theta x_{n+1}+(1-\theta)y_{n+1}}\in[0,1],
\end{equation}
which implies that
\begin{equation}
P([x,y])=[P(x),P(y)]\label{eq:pf.1}
\end{equation}
Let $C$ be convex with $C\subset\text{dom}\,P$, and let $x,y\in C$. By \eqref{eq:pf.1}, we have that the line segment $[P(x),P(y)]$ is the image of the line segment $[x,y]$ under $P$, $P([x,y])$, and so lies in $P(C)$, which also claims the convexity of $P(C)$.</p>

<p>The inverse image of a convex set under the perspective function is also convex: if $C\subset\mathbb{R}^n$ is convex, then
\begin{equation}
P^{-1}(C)=\{(x,t)\in\mathbb{R}^{n+1}:x/t\in C,t&gt;0\}
\end{equation}
is convex.</p>

<p>To prove this, for any $(x_1,t_1),(x_2,t_2)\in P^{-1}(C)$ and for any $0\leq t\leq 1$, by the result \eqref{eq:pf.1}, we have
\begin{equation}
P^{-1}\big(\theta(x_1,t_1)+(1-\theta)(x_2,t_2)\big)=\frac{\theta x_1+(1-\theta x_2)}{\theta t_1+(1-\theta)t_2}=\mu\frac{x_1}{t_1}+(1-\mu)\frac{x_2}{t_2},
\end{equation}
where
\begin{equation}
\mu=\frac{\theta t_1}{\theta t_1+(1-\theta)t_2}\in[0,1]
\end{equation}</p>

<h5 id="lin-frac-funcs">Linear-fractional functions</h5>
<p>We define the <strong>linear-fractional function</strong> to be the composite function of a perspective function with an affine function. Specifically, let $g:\mathbb{R}^n\to\mathbb{R}^{m+1}$ be affine
\begin{equation}
g(x)=\left[\begin{matrix}A \\ c^\text{T}\end{matrix}\right]x+\left[\begin{matrix}b \\ d\end{matrix}\right],
\end{equation}
where $A\in\mathbb{R}^{m\times n},b\in\mathbb{R}^m,c\in\mathbb{R}^n$ and $d\in\mathbb{R}$. The function $f:\mathbb{R}^n\to\mathbb{R}^m$ given by
\begin{equation}
f(x)=(P\circ g)(x)=\frac{Ax+b}{c^\text{T}x+d},
\end{equation}
for $\text{dom}\,f\{x:c^\text{T}x+d&gt;0\}$, is called a <strong>linear-fractional function</strong>.</p>

<p>It is convenient to represent a linear-fractional function as a matrix
\begin{equation}
Q=\left[\begin{matrix}A&amp;b \\ c^\text{T}&amp;d\end{matrix}\right]\in\mathbb{R}^{(m+1)\times(n+1)},
\end{equation}
which lets
\begin{equation}
Q\left[\begin{matrix}x \\ 1\end{matrix}\right]=\left[\begin{matrix}A&amp;b \\ c^\text{T}&amp;d\end{matrix}\right]\left[\begin{matrix}x \\ 1\end{matrix}\right]=\left[\begin{matrix}Ax+b \\ c^\text{T}x+d\end{matrix}\right]
\end{equation}</p>

<h2 id="cvx-funcs">Convex functions</h2>
<p>A function $f:\mathbb{R}^n\to\mathbb{R}$ is called <strong>convex</strong> if $\text{dom}\,f$ is a convex set and if for all $x,y\in\text{dom}\,f$ and for any $0\leq\theta\leq 1$, we have
\begin{equation}
f\big(\theta x+(1-\theta)y\big)\leq\theta f(x)+(1-\theta)f(y)\label{eq:cf.1}
\end{equation}
Intuitively, we can think of the above inequality as the line segment between $(x,f(x))$ and $(y,f(y))$ lies above the graph of $f$.</p>

<p>We call $f$ a <strong>strictly convex</strong> function if strict inequality hold in \eqref{eq:cf.1} for every $x\neq y$ and $0\lt\theta\lt 1$. And $f$ is referred as <strong>concave</strong> if $-f$ is convex, or is known as <strong>strictly concave</strong> if $-f$ is strictly convex.</p>

<p>A function is convex iff it is convex when restricted to any line that intersects its domain. In other words, $f$ is convex iff for all $x\in\text{dom}\,f$ and for all $v$, the function
\begin{equation}
g(t)=f(x+tv)
\end{equation}
is convex on its domain, $\text{dom}\,g=\{t:x+tv\in\text{dom}\,f\}$.</p>

<h3 id="props">Properties</h3>

<h4 id="st-order-conds">First-order conditions</h4>

<p>Let $f$ be differentible, i.e. $\nabla f$ exists at each point in $\text{dom}\,f$, which is open. Then $f$ is convex iff $\text{dom}\,f$ is convex and
\begin{equation}
f(y)\geq f(x)+\nabla f(x)^\text{T}(y-x)
\end{equation}
holds for all $x,y\in\text{dom}\,f$.</p>

<p>Similarly, we can also have that $f$ is strictly convex iff $\text{dom}\,f$ is convex and for $x,y\in\text{dom}\,f$ such that $x\neq y$, we have
\begin{equation}
f(y)&gt;f(x)+\nabla f(x)^\text{T}(y-x)
\end{equation}
And hence, $f$ is concave iff $\text{dom}\,f$ is convex and for all $x,y\in\text{dom}\,f$, we have
\begin{equation}
f(y)\leq f(x)+\nabla f(x)^\text{T}(y-x)
\end{equation}</p>

<p><strong>Proof</strong><br />
We first consider the case that $n=1$, i.e. $f:\mathbb{R}\to\mathbb{R}$ is convex iff for all $x,y\in$, we have
\begin{equation}
f(y)\geq f(x)+fâ€™(x)(y-x)\label{eq:soc.1}
\end{equation}
Suppose that $f$ is convex, thus $\text{dom}\,f$ is convex.</p>

<p>Let $x,y$ be two points in $\text{dom}\,f$. We therefore have that for any $0\lt\theta\leq 1$, $(1-\theta)x+\theta y\in\text{dom}\,f$ and
\begin{equation}
f\big((1-\theta)x+\theta y\big)\leq(1-\theta)f(x)+\theta f(y),
\end{equation}
which give us
\begin{equation}
f(y)\geq f(x)+\frac{f\big(x+\theta(y-x)\big)-f(x)}{\theta}
\end{equation}
Let $t\to 0$, we obtain
\begin{equation}
f(y)\geq f(x)+fâ€™(x)(y-x)
\end{equation}
Given $f$ such that \eqref{eq:soc.1} satisfies for all $x,y$ in $\text{\dom}\,f$ and $\text{dom}\,f$ is convex.</p>

<p>Choose any $x\neq y$ and let $z=\theta x+(1-\theta)y$, for some $0\leq\theta\leq 1$, we then have $z\in\text{dom}\,f$, which implies that
\begin{equation}
f(x)\geq f(z)+fâ€™(z)(x-z)
\end{equation}
and
\begin{equation}
f(y)\geq f(z)+fâ€™(z)(y-z)
\end{equation}
Since $0\leq\theta\leq 1$, these two results above give us
\begin{equation}
\theta f(x)+(1-\theta)f(y)\geq f(z)=\theta x+(1-\theta)y,
\end{equation}
which proves our claim.</p>

<h4 id="nd-order-conds">Second-order conditions</h4>

<h3 id="cvx-funcs-eg">Examples</h3>

<h3 id="sub-lvl-sets">Sub-level sets</h3>

<h3 id="inequalities">Inequalities</h3>

<h4 id="jensens-inequality">Jensenâ€™s inequality</h4>

<h3 id="operations-funcs">Operations that preserve convexity</h3>

<h3 id="conjugate-func">The conjugate function</h3>

<h3 id="quasi-cvx-funcs">Quasiconvex functions</h3>

<h2 id="references">References</h2>
<p>[1] Stephen Boyd &amp; Lieven Vandenberghe. <a href="http://www.stanford.edu/âˆ¼boyd/cvxbook/">Convex Optimization</a>. Cambridge UP, 2004.</p>

<h2 id="footnotes">Footnotes</h2>
:ET