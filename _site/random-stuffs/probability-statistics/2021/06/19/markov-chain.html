<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Markov Chain | Trung’s blog</title>
<meta name="generator" content="Jekyll v4.2.0" />
<meta property="og:title" content="Markov Chain" />
<meta name="author" content="trunghng" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Since I have no idea how to begin with this post, why not just dive straight into details :P" />
<meta property="og:description" content="Since I have no idea how to begin with this post, why not just dive straight into details :P" />
<meta property="og:site_name" content="Trung’s blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-06-19T22:27:00+07:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Markov Chain" />
<script type="application/ld+json">
{"description":"Since I have no idea how to begin with this post, why not just dive straight into details :P","mainEntityOfPage":{"@type":"WebPage","@id":"/random-stuffs/probability-statistics/2021/06/19/markov-chain.html"},"url":"/random-stuffs/probability-statistics/2021/06/19/markov-chain.html","author":{"@type":"Person","name":"trunghng"},"headline":"Markov Chain","dateModified":"2021-06-19T22:27:00+07:00","datePublished":"2021-06-19T22:27:00+07:00","@type":"BlogPosting","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="/feed.xml" title="Trung&apos;s blog" />
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Trung&#39;s blog</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Markov Chain</h1>
    <p class="post-meta"><time class="dt-published" datetime="2021-06-19T22:27:00+07:00" itemprop="datePublished">
        Jun 19, 2021
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>Since I have no idea how to begin with this post, why not just dive straight into details :P</p>

<p>Markov chain is a stochastic process in which the random variables follow a special property called Markov.</p>

<h3 id="markov-property">Markov property</h3>
<p>A sequence of random variables $X_0, X_1, X_2, \dots$ taking values in the <em>state space</em> $S=${$1, 2,\dots, M$}. For all $n\geq0$,
\begin{equation}
P(X_{n+1}=j|X_n=i)=P(X_{n+1}=j|X_n=i,X_{n-1}=i_{n-1},X_{n-2}=i_{n-2},\dots,X_0=i_0)
\end{equation}
In other words, knowledge of the preceding state is all we need to determine the probability distribution of the current state.</p>

<h3 id="transition-matrix">Transition matrix</h3>
<p>The quantity $P(X_{n+1}=j|X_n=i)$ is <em>transition probability</em> from state $i$ to $j$.<br />
If we denote that $q_{ij}=P(X_{n+1}=j|X_n=i)$ and let $Q=(q_{ij})$, which is a $M\times M$ matrix, there we have the <em>transition matrix</em> $Q$ of the chain.<br />
Therefore, each row of $Q$ is a conditional probability mass function (PMF) of $X_{n+1}$ given $X_n$. And hence, sum of its entries is 1.</p>

<h4 id="n-step-transition-probability">n-step transition probability</h4>
<p>The n-step <em>transition probability</em> from $i$ to $j$ is the probability of being at $i$ and $n$ steps later being at $j$, and be denoted as $q_{ij}^{(n)}$,
\begin{equation}
q_{ij}^{(n)}=P(X_n=j|X_0=i)
\end{equation}
We have that
\begin{equation}
q_{ij}^{(2)}=\sum_{k}^{}q_{ik}q_{kj}
\end{equation}
since it has to go through an intermediary step $k$ to reach $j$ in 2 steps from $i$. It’s easily seen that the right hand side is $Q_{ij}^2$. And by induction, we have that:
\begin{equation}
q_{ij}^{(n)}=Q_{ij}^{n}
\end{equation}
$Q^n$ is also called the <em>n-step transition matrix</em>.</p>

<h4 id="marginal-distribution-of-x_n">Marginal distribution of $X_n$</h4>
<p>Let $t=(t_1,\dots,t_M)^T$, where $t_i=P(X_0=i)$. By the law of total probability (LOTP), we have that:
\begin{align}
P(X_n=j)&amp;=\sum_{i=1}^{M}P(X_0=i)P(X_n=j|X_0=i) \\&amp;=\sum_{i=1}^{M}t_iq_{ij}^{(n)}
\end{align}
or the marginal distribution of $X_n$ is given by $tQ^n$.</p>

<h3 id="properties">Properties</h3>
<ul>
  <li>State $i$ of a Markov chain is defined as <em>recurrent</em> or <em>transient</em> depending upon whether or not the Markov chain will eventually return to it. Starting with <em>recurrent</em> state i, the chain will return to it with the probability of 1. Otherwise, it is <em>transient</em>.
    <ul>
      <li><strong>Proposition</strong>: Number of returns to <em>transient</em> state is distributed by <em>Geom($p$)</em>, with $p&gt;0$ is the probability of never returning to $i$.</li>
    </ul>
  </li>
  <li>A Markov chain is defined as <em>irreducible</em> if there exists a chain of steps between any $i,j$ that has positive probability. That is for any $i,j$, there is some $n&gt;0,\in\mathbb{N}$ such that $Q^n_{ij}&gt;0$. If not <em>irreducible</em>, it’s called <em>reducible</em>
    <ul>
      <li><strong>Proposition</strong>: <em>Irreducible</em> implies all states <em>recurrent</em></li>
    </ul>
  </li>
  <li>A state $i$ has <em>period</em> $k&gt;0$ if $k$ is the greatest common divisor (gcd) of the possible numbers of steps it can take to return to $i$ when starting at $i$.
And thus, $k=gcd(n)$ such that $Q^n_{ii}&gt;0$. $i$ is called <em>aperiodic</em> if $k_i=1$, and <em>periodic</em> otherwise. The chain itself is called <em>aperiodic</em> if all its states are <em>aperiodic</em>, and <em>periodic</em> otherwise.</li>
</ul>

<h3 id="stationary-distribution">Stationary distribution</h3>
<p>A vector $s=(s_1,\dots,s_M)^T$ such that $s_i\geq0$ and $\sum_{i}s_i=1$ is a <em>stationary distribution</em> for a Markov chain if
\begin{equation}
\sum_{i}s_iq_{ij}=s_j
\end{equation}
for all $j$, or equivalently $sQ=s$.</p>

<p><strong>Theorem</strong> (<em>Existence and uniqueness of stationary distribution</em>)<br />
    Any <em>irreducible</em> Markov chain has a unique <em>stationary distribution</em>. In this distribution, every state has positive probability.</p>

<p>The theorem is a consequence of a result from <a href="https://en.wikipedia.org/wiki/Perron–Frobenius_theorem"><em>Perron-Frobenius theorem</em></a>.</p>

<p><strong>Theorem</strong> (<em>Convergence to stationary distribution</em>)<br />
    Let $X_0,X_1,\dots$ be a Markov chain with <em>stationary distribution</em> $s$ and <em>transition matrix</em> $Q$, such that some power $Q^m$ has all entries positive (or in the other words, the chain is <em>irreducible</em> and <em>aperiodic</em>). Then $P(X_n=i)$ converges to $s_i$ as $n\rightarrow\infty$ (or $Q^n$ converges to a matrix in which each row is $s$).</p>

<p><strong>Theorem</strong> (<em>Expected time to run</em>)<br />
    Let $X_0,X_1,\dots$ be an <em>irreducible</em> Markov chain with <em>stationary distribution</em> $s$. Let $r_i$ be the expected time it takes the chain to return to $i$, given that it starts at $i$. Then $s_i=1/r_i$</p>

<h3 id="reversibility">Reversibility</h3>
<p>Let $Q=(q_{ij})$ be the <em>transition matrix</em> of a Markov chain. Suppose there is an $s=(s_1,\dots,s_M)^T$ with $s_i\geq0,\sum_{i}s_i=1$, such that
\begin{equation}
s_iq_{ij}=s_jq_{ji}
\end{equation}
for all states $i,j$. This equation is called <em>reversibility</em> or <em>detailed balance</em> condition. And if the condition holds, we say that the chain is <em>reversible</em> w.r.t $s$.</p>

<p><strong>Proposition</strong> (<em>Reversible implies stationary</em>)<br />
    Suppose that $Q=(q_{ij})$ be the <em>transition matrix</em> of a Markov chain that is <em>reversible</em> w.r.t to an $s=(s_1,\dots,s_M)^T$ with with $s_i\geq0,\sum_{i}s_i=1$. Then $s$ is a <em>stationary distribution</em> of the chain. (<em>proof</em>:$\sum_{j}s_jq_{ji}=\sum_{j}s_iq_{ij}=s_i\sum_{j}q_{ij}=s_i$)</p>

<p><strong>Proposition</strong><br />
    If each column of $Q$ sum to 1, then the <em>uniform distribution</em> over all states $(1/M,\dots,1/M)$, is a <em>stationary distribution</em>.(this kind of matrix is called <em>doubly stochastic matrix</em>).</p>

<h3 id="examples-and-application">Examples and application</h3>
<ul>
  <li><a href="https://en.wikipedia.org/wiki/Finite-state_machine"><em>Finite-state machines</em></a>, <a href="https://en.wikipedia.org/wiki/Random_walk"><em>random walks</em></a></li>
  <li>Diced board games such as Ludo, Monopoly,…</li>
  <li><a href="https://en.wikipedia.org/wiki/PageRank"><em>Google PageRank</em></a> - the heart of Google search</li>
  <li>Markov Decision Process (MDP), which is gonna be the content of next post.</li>
  <li>And various other applications.</li>
</ul>

<h4 id="footnote">Footnote:</h4>
<ul>
  <li>The Markov chain here is <em>time-homogeneous</em> Markov chain, in which the probability of any state transition is independent of time.</li>
  <li>This is more like intuitive and less formal definition of Markov chain, we will have more concrete definition with the help of <em>Measure theory</em> after the post about it.</li>
  <li>Well, it only matters where you are, not where you’ve been.</li>
</ul>

<h4 id="references">References:</h4>
<ol>
  <li>Introduction to Probability - Joseph K. Blitzstein &amp; Jessica Hwang</li>
  <li><a href="https://brilliant.org/wiki/markov-chains/">Brillant’s Markov chain</a></li>
</ol>

  </div>
<div id="disqus_thread"></div>
<script>
    /**
    *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
    *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables    */
    
    var disqus_config = function () {
    this.page.url = '';  // Replace PAGE_URL with your page's canonical URL variable
    this.page.identifier = ''; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    
    (function() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
    s.src = 'https://https-trunghng-github-io.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>


<script id="dsq-count-scr" src="//https-trunghng-github-io.disqus.com/count.js" async></script>

  <a class="u-url" href="/random-stuffs/probability-statistics/2021/06/19/markov-chain.html" hidden></a>
</article>
 <!-- mathjax javascript -->
       <script type="text/x-mathjax-config">
         MathJax.Hub.Config({
          tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
          });
        </script>
        <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
      </script>

      </div>

    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
        <ul class="contact-list">
          <li class="p-name">trunghng</li>
          <li><a class="u-email" href="mailto:trung.skipper@gmail.com">trung.skipper@gmail.com</a></li>
        </ul>
      </div>
      <div class="footer-col">
        <p>To document something I&#39;ve learned
</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/trunghng" title="trunghng"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
