<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Convex sets, convex functions | Littleroot</title>
<script type=text/x-mathjax-config>
  MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": {availableFonts: []}
  });
</script><script type=text/x-mathjax-config>
    MathJax.Hub.Config({
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
      "HTML-CSS": {availableFonts: []},
      TeX: {
        equationNumbers: { autoNumber: "AMS" },
      },
    });
  </script><script type=text/javascript src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><meta name=keywords content="mathematics,convex-optimization"><meta name=description content="
Notes on convex sets, convex functions.
"><meta name=author content="Trung H. Nguyen"><link rel=canonical href=http://localhost:1313/posts/optimization/cvx-sets-funcs/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.e9f4bcad0f9fc853201ee998afd06c07a01cb19320ff7cb62155b43ffdb33cea.css integrity="sha256-6fS8rQ+fyFMgHumYr9BsB6AcsZMg/3y2IVW0P/2zPOo=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=http://localhost:1313/images/favicon/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/images/favicon/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/images/favicon/favicon-32x32.png><link rel=apple-touch-icon href=http://localhost:1313/images/favicon/apple-touch-icon.png><link rel=mask-icon href=http://localhost:1313/images/favicon/android-chrome-512x512.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/posts/optimization/cvx-sets-funcs/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-GF0KK4E3F0"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-GF0KK4E3F0")</script><script type=text/x-mathjax-config>
  MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": {availableFonts: []}
  });
</script><script type=text/x-mathjax-config>
    MathJax.Hub.Config({
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
      "HTML-CSS": {availableFonts: []},
      TeX: {
        equationNumbers: { autoNumber: "AMS" },
      },
    });
  </script><script type=text/javascript src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><style>.post-content{text-align:justify;font-size:15px;font-family:"goudy bookletter 1911",sans-serif}.post-content h1,h2,h3,h4,h5,h6{text-align:left}.post-content a,.post-content a:link,.post-content a:active{box-shadow:none;color:#4682b4}.post-content a:hover{color:skyblue}.post-content a:visited{color:#00008b}.post-content ol,.post-content ul{margin-left:10px}.post-content li>ol,.post-content li>ul{margin-left:30px}.roman-list,.number-list,.alpha-list{counter-reset:section;margin-bottom:10px}.roman-list>li{list-style:none;position:relative}.number-list>li{list-style:none;position:relative}.alpha-list>li{list-style:none;position:relative}.roman-list>li:before{counter-increment:section;content:"(" counter(section,lower-roman)") ";position:absolute;left:-2em}.number-list>li:before{counter-increment:section;content:"(" counter(section,decimal)") ";position:absolute;left:-2em}.alpha-list>li:before{counter-increment:section;content:"(" counter(section,lower-alpha)") ";position:absolute;left:-2em}#non-style-list{margin-bottom:10px;margin-left:0}#non-style-list>li{position:relative}.toc{font-size:15px}.post-footer{font-size:15px}.post-content figure>img{display:block;margin-left:auto;margin-right:auto}.post-content figure>figcaption{all:revert;text-align:justify;font-size:12px;font-style:italic;width:70%;margin-left:15%}.post-content figure>figcaption>p{all:revert}.post-content h3{font-size:28px}.post-content h4{font-size:24px}.post-content h5{font-size:20px}.post-content h6{font-size:16px}</style><script async src="https://www.googletagmanager.com/gtag/js?id=G-GF0KK4E3F0"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-GF0KK4E3F0")}</script><meta property="og:title" content="Convex sets, convex functions"><meta property="og:description" content="
Notes on convex sets, convex functions.
"><meta property="og:type" content="article"><meta property="og:url" content="http://localhost:1313/posts/optimization/cvx-sets-funcs/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2021-12-02T13:03:00+07:00"><meta property="article:modified_time" content="2021-12-02T13:03:00+07:00"><meta property="og:site_name" content="Littleroot"><meta name=twitter:card content="summary"><meta name=twitter:title content="Convex sets, convex functions"><meta name=twitter:description content="
Notes on convex sets, convex functions.
"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"posts","item":"http://localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"Convex sets, convex functions","item":"http://localhost:1313/posts/optimization/cvx-sets-funcs/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Convex sets, convex functions","name":"Convex sets, convex functions","description":" Notes on convex sets, convex functions.\n","keywords":["mathematics","convex-optimization"],"articleBody":" Notes on convex sets, convex functions.\nConvex sets Affine \u0026 convex sets Affine sets A set $C\\subset\\mathbb{R}^n$ is affine if the line through any two distinct points in $C$ lies in $C$, i.e. for any $x_1,x_2\\in C$ and for any $\\theta\\in\\mathbb{R}$ we have \\begin{equation} \\theta x_1+(1-\\theta)x_2\\in C \\end{equation} A point of the form $\\theta_1 x_1+\\ldots+\\theta_k x_k$, where $\\theta_1+\\ldots+\\theta_k=1$ is known as an affine combination of the points $x_1,\\ldots,x_k$.\nHence, if $C$ is an affine set, and $x_1,\\ldots,x_k\\in C$, and $\\theta_1+\\ldots+\\theta_k=1$, then the point \\begin{equation} \\theta_1 x_1+\\ldots+\\theta_k x_k\\in C, \\end{equation} or in other words, an affine set contains every affine combination of its points.\nIf $C$ is an affine set and $x_0\\in C$, then the set \\begin{equation} V=C-x_0\\{x-x_0:x\\in C\\} \\end{equation} is a subspace.\nThe set of all affine combinations of points in some set $C\\subset\\mathbb{R}^n$ is referred as affine hull of $C$, denoted $\\text{aff}\\hspace{0.1cm}C$: \\begin{equation} \\text{aff}\\hspace{0.1cm}C=\\{\\theta_1 x_1+\\ldots+\\theta_k x_k:x_1,\\ldots,x_k\\in C;\\theta_1+\\ldots+\\theta_k=1\\} \\end{equation} The affine hull is the smallest affine set containing $C$.\nAffine dimension, relative interior The affine dimension of a set $C$ is defined as the dimension of $\\text{aff}\\hspace{0.1cm}C$.\nIf the affine dimension of $C\\subset\\mathbb{R}^n$ is less than $n$, then the set lies in $\\text{aff}\\hspace{0.1cm}C\\neq\\mathbb{R}^n$. The relative interior of the set $C$, denoted as $\\text{relint}\\hspace{0.1cm}C$, is defined as its interior relative to $\\text{aff}\\hspace{0.1cm}C$: \\begin{equation} \\text{relint}\\hspace{0.1cm}C=\\{x\\in C:B(x,r)\\cap\\text{aff}\\hspace{0.1cm}C\\in C\\text{ for some }r\u003e0\\}, \\end{equation} where $B(x,r)$ is the ball centered at $x$ with radius $r$ in the norm $\\Vert\\cdot\\Vert$ (here $\\Vert\\cdot\\Vert$ could be any norm; all norms define the same relative interior).\nThe relative boundary of $C$ is defined as $\\overline{C}\\backslash\\text{relint}\\hspace{0.1cm}C$, where $\\overline{C}$ is the closure of $C$.\nConvex sets A set $C$ is convex if the line segment between any points in $C$ also lies in $C$, i.e. for any $x_1,x_2\\in C$ and for any $0\\leq\\theta\\leq 1$, we have \\begin{equation} \\theta x_1+(1-\\theta)x_2\\in C \\end{equation} It is then easily seen that every affine sets is also convex.\nAnalogy to affine sets, we also refer a point of the form $\\theta_1 x_1+\\ldots+\\theta_k x_k$, where $\\theta_1+\\ldots+\\theta_k=1$ and $\\theta_i\\geq 0,\\forall i=1,\\ldots,k$, a convex combination of the points $x_1,\\ldots,x_k$. And a set is convex iff it contains every convex combination of its points.\nThe convex hull of $C$, denoted $\\text{conv}\\hspace{0.1cm}C$, is defined as the set of all convex combinations of points in $C$: \\begin{equation} \\text{conv}\\hspace{0.1cm}C=\\{\\theta_1 x_1+\\ldots+\\theta_k x_k:x_1,\\ldots,x_k\\in C;\\theta_1+\\ldots+\\theta_k=1;\\theta_1,\\ldots,\\theta_k\\geq 0\\} \\end{equation} Thus, $\\text{conv}\\hspace{0.1cm}C$ is convex and is the smallest convex set containing $C$.\nWe can generalize the definition of convex combination into: let $x_1,x_2\\ldots\\in C$ where $C\\subset\\mathbb{R}^n$ and let $\\{\\theta_n\\}_{n=1,2,\\ldots}$ be a countable sequence such that \\begin{equation} \\sum_{i=1}^{\\infty}\\theta_i=1;\\hspace{2cm}\\theta_i\\geq 0,\\hspace{0.5cm}\\forall i=1,2,\\ldots \\end{equation} Then the series \\begin{equation} \\sum_{i=1}^{\\infty}\\theta_i x_i\\in C, \\end{equation} if it converges.\nMore generally, suppose $p:\\mathbb{R}^n\\to\\mathbb{R}$ satisfies $p(x)\\geq 0$ forall $x\\in C$ and $\\int_C p(x)\\hspace{0.1cm}dx=1$, where $C\\subset\\mathbb{R}^n$ is a convex set. Then the integral \\begin{equation} \\int_C p(x)x\\hspace{0.1cm}dx\\in C \\end{equation} if it exists.\nIn the most general form, suppose $C\\subset\\mathbb{R}^n$ is convex and $x$ is a random vector with $x\\in C$ with probability one. Then we also have that \\begin{equation} \\mathbb{E}x\\in C \\end{equation}\nCones A set $C$ is called a cone, or nonnegative homogeneous, if for every $x\\in C$ and for any $\\theta\\geq 0$, we also have $\\theta x\\in C$.\nA convex cone $C$ is both convex and a cone, i.e. for any $x_1,x_2\\in C$ and for any $\\theta_1,\\theta_2\\geq 0$, we have \\begin{equation} \\theta_1 x_1+\\theta_2 x_2\\in C \\end{equation} since by definition of a cone, we can add a normalization factor $\\alpha$ into the point above \\begin{equation} \\alpha\\theta_1 x_1+\\alpha\\theta_2 x_2 \\end{equation} such that $\\alpha\\theta_1+\\alpha\\theta_2=1$ (in this particular case, $\\alpha=1/(\\theta_1+\\theta_2)$).\nA point of the form $\\theta_1 x_1+\\ldots+\\theta_k x_k$ with $\\theta_1,\\ldots,\\theta_k\\geq 0$ is called a conic combination. It is easily seen that a set $C$ is a convex cone iff it contains all conic combinations of its points. Like convex and affine combinations, we can generalize the definition of conic combination into infinite series and integrals.\nWe define the conic hull of a set $C$ as the set of all conic combinations of elements in $C$ \\begin{equation} \\{\\theta_1 x_1+\\ldots+\\theta_k x_k:x_i\\in C;\\theta_i\\geq 0,\\forall i=1,\\ldots,k\\} \\end{equation} Also, the conic hull of $C$ is the smallest convex cone containing $C$.\nExamples Hyperplanes, halfspaces A hyperplane $P$ is a set of form \\begin{equation} P=\\{x\\in\\mathbb{R}^n:a^\\text{T}x=b\\}, \\end{equation} where $a\\in\\mathbb{R}^n$, $a\\neq 0$ and $b\\in\\mathbb{R}$. We have that $P$ is convex.\nTo prove this, for $x_1,x_2\\in P$, and for any $0\\leq\\theta\\leq 1$, we have \\begin{equation} a^\\text{T}\\big(\\theta x_1+(1-\\theta)x_2\\big)=\\theta a^\\text{T}x_1+(1-\\theta)a^\\text{T}x_2=\\theta b+(1-\\theta)b=b \\end{equation}\nA hyperplane separates $\\mathbb{R}^n$ into two halfspaces. A (closed) halfspace is a set of of the form \\begin{equation} \\{x\\in\\mathbb{R}^n:a^\\text{T}x\\leq b\\}, \\end{equation} where $a\\in\\mathbb{R}^n$, $a\\neq 0$ and $b\\in\\mathbb{R}$. It is also easily seen that halfspaces are also convex.\nBalls, ellipsoids, norm cones Balls A (closed) ball in $\\mathbb{R}^n$ centered at $x_c$ and with radius $r$ and with $\\Vert\\cdot\\Vert$ is any norm in $\\mathbb{R}^n$ \\begin{equation} B(x_c,r)=\\{x\\in\\mathbb{R}^n:\\Vert x-x_c\\Vert\\leq r\\} \\end{equation} is a convex set.\nTo see this, for any $x_1,x_2\\in B(x_c,r)$ and for any $0\\leq\\theta\\leq 1$, by triangle inequality of norm, we have \\begin{align} \\Vert\\theta x_1+(1-\\theta)x_2-x_c\\Vert\u0026=\\Vert\\theta(x_1-x_c)+(1-\\theta)(x_2-x_c)\\Vert \\\\ \u0026\\leq\\theta\\Vert x_1-x_c\\Vert+(1-\\theta)\\Vert x_2-x_c\\Vert \\\\ \u0026\\leq\\theta r+(1-\\theta)r \\\\ \u0026=r \\end{align}\nEllipsoids An ellipsoid $\\mathcal{E}$ in $\\mathbb{R}^n$ centered at $x_c\\in\\mathbb{R}^n$ is defined as \\begin{equation} \\mathcal{E}=\\{x:(x-x_c)^\\text{T}P^{-1}(x-x_c)\\leq 1\\}, \\end{equation} where $P\\in\\mathbb{R}^{n\\times n}$ is symmetric and positive definite. The matrix $P$ determines how far $\\mathcal{E}$ extends in every direction from $x_c$; the lengths of the semi-axes of $\\mathcal{E}$ are $\\sqrt{\\lambda_i}$, where $\\lambda_i$ for $i=1,\\ldots,n$ are the eigenvalues of $P$. A ball of radius $r$ is an ellipsoid with \\begin{equation} P=r^2 I \\end{equation} We then have $\\mathcal{E}$ is convex.\nTo prove this claim, as usual, for $x_1,x_2\\in\\mathcal{E}$ and for $0\\leq\\theta\\leq 1$, we have \\begin{align} \u0026\\hspace{0.7cm}\\big(\\theta x_1+(1-\\theta)x_2-x_c\\big)^\\text{T}P^{-1}\\big(\\theta x_1+(1-\\theta)x_2-x_c\\big) \\\\ \u0026=\\big(\\theta x_1-\\theta x_c+(1-\\theta)x_2-(1-\\theta)x_c\\big)^\\text{T}P^{-1}\\big(\\theta x_1-\\theta x_c+(1-\\theta)x_2-(1-\\theta)x_c\\big) \\\\ \u0026=(a+b)^\\text{T}P^{-1}(a+b) \\\\ \u0026=a^\\text{T}P^{-1}a+b^\\text{T}P^{-1}b+2a^\\text{T}P^{-1}b \\\\ \u0026\\leq\\theta^2+(1-\\theta)^2+2\\theta(1-\\theta) \\\\ \u0026=1 \\end{align} where in the second step, we have let \\begin{equation} a=\\theta x_1-\\theta x_c,\\hspace{2cm}b=(1-\\theta)x_2-(1-\\theta)x_c, \\end{equation} which implies that \\begin{equation} a^\\text{T}P^{-1}a\\leq 1,\\hspace{2cm}b^\\text{T}P^{-1}b\\leq 1 \\end{equation} and thus \\begin{equation} a^\\text{T}P^{-1/2}\\leq 1,\\hspace{2cm}b^\\text{T}P^{-1/2}\\leq 1 \\end{equation}\nNorm cones A norm cone $C$ associated with the norm $\\Vert\\cdot\\Vert$ is defined as \\begin{equation} C=\\{(x,t):\\Vert x\\Vert\\leq t\\}\\subset\\mathbb{R}^{n+1} \\end{equation} is also convex\nPolyhedra A polyhedron $\\mathcal{P}$ is defined as \\begin{equation} \\mathcal{P}=\\{x:a_i^\\text{T}\\leq b_i,i=1,\\ldots,m;c_j^\\text{T}=d_j,j=1,\\ldots,p\\} \\end{equation} Then $\\mathcal{P}$ can be seen as the intersection of a finite number of halfspaces and hyperplanes. Another representation of $\\mathcal{P}$ is \\begin{equation} \\mathcal{P}=\\{x:Ax\\preceq b,Cx=d\\}, \\end{equation} where \\begin{equation} A=\\left[\\begin{matrix}a_1^\\text{T} \\\\ \\vdots \\\\ a_m^\\text{T}\\end{matrix}\\right],\\hspace{2cm}C=\\left[\\begin{matrix}c_1^\\text{T} \\\\ \\vdots \\\\ c_p^\\text{T}\\end{matrix}\\right] \\end{equation} And thus, we also have that $\\mathcal{P}$ is convex, which can be proved easily since $Ax$ and $Cx$ are both linear functions.\nNonnegative orthant The nonnegative orthant in $\\mathbb{R}^n$, denoted $\\mathbb{R}_+^{n}$, is the set of points with nonnegative components, i.e. \\begin{equation} \\mathbb{R}_+^n=\\{x\\in\\mathbb{R}^n:x\\succeq 0\\} \\end{equation} We have that $\\mathbb{R}_+^n$ is both a polyhedron and a cone, or a polyhedral cone, and hence is also convex.\nSimplex Suppose the $v_0,\\ldots,v_k\\in\\mathbb{R}^n$ are affinely independent, i.e. $v_1-v_0,\\ldots,v_k-v_0$ are linearly independent. The simplex determined by them is given as \\begin{equation} C=\\text{conv}\\{v_0,\\ldots,v_k\\}=\\{\\theta_0 v_0+\\ldots+\\theta_k v_k:\\theta\\succeq 0,\\mathbf{1}^\\text{T}\\theta=1\\} \\end{equation} As an instance of polyhedra, $C$ is thus convex.\nPositive semi-definite cone Let $\\mathbb{S}^n$ denote the set of symmetric $n\\times n$ matrices \\begin{equation} \\mathbb{S}^n=\\{X\\in\\mathbb{R}^{n\\times n}:X=X^\\text{T}\\}, \\end{equation} and let $\\mathbb{S}_+^n$ represent the set of symmetric positive semi-definite matrices \\begin{equation} \\mathbb{S}_+^n=\\{X\\in\\mathbb{S}^n:X\\succeq 0\\}, \\end{equation} and finally, let us assign the set of symmetric positive definite matrices to $\\mathbb{S}_{++}^n$ \\begin{equation} \\mathbb{S}_{++}^n=\\{X\\in\\mathbb{S}^n:X\\succ 0\\} \\end{equation} We have that $\\mathbb{S}_+^n$ is a convex cone, since for any matrices $A_1,A_2\\in\\mathbb{S}_+^n$, for any $\\theta_1,\\theta_2\\geq 0$ and for any $x\\in\\mathbb{R}^n$, we have \\begin{equation} x^\\text{T}(\\theta_1 A_1+\\theta_2 A_2)x=\\theta_1 x^\\text{T}A_1 x+\\theta_2 x^\\text{T}A_2 x\\geq 0 \\end{equation} The same argument can be applied to prove that $\\mathbb{S}_{++}^n$ or even the set of symmetric negative definite matrices and the set of symmetric negative semi-definite matrices are convex.\nOperations that preserve convexity Intersection Let $S_1,S_2$ be convex sets and let $x_1,x_2$ are two points containing in both sets, thus $x_1,x_2\\in S_1\\cap S_2$.\nSince $x_1,x_2\\in S_1$ which is convex, for $0\\leq\\theta\\leq 1$, we have the point \\begin{equation} \\theta x_1+(1-\\theta)x_2\\in S_1 \\end{equation} Analogously, we also have \\begin{equation} \\theta x_1+(1-\\theta)x_2\\in S_2, \\end{equation} which implies that \\begin{equation} \\theta x_1+(1-\\theta)x_2\\in S_1\\cap S_2 \\end{equation} Or in other words, $S_1\\cap S_2$ is also convex.\nBy induction, we can extend this property to: if $S_\\alpha$ is convex for every $\\alpha\\in\\mathcal{A}$, then their intersection \\begin{equation} \\bigcap_{\\alpha\\in\\mathcal{A}}S_\\alpha \\end{equation} is also convex.\nAffine functions A function $f:\\mathbb{R}^n\\to\\mathbb{R}^m$ is affine if it is a sum of linear function and a constant, i.e. it can be written as \\begin{equation} f(x)=Ax+b, \\end{equation} where $A\\in\\mathbb{R}^{m\\times n}$ and $b\\in\\mathbb{R}^m$.\nLet $S\\subset\\mathbb{R}^n$ be a convex set and let $f:\\mathbb{R}^n\\to\\mathbb{R}^m$ be an affine function. Then the image of $S$ under $f$ \\begin{equation} f(S)=\\{f(x):x\\in S\\} \\end{equation} is convex.\nAnalogously, the inverse image of $S$ under an affine function $g:\\mathbb{R}^k\\to\\mathbb{R}^n$ \\begin{equation} g^{-1}(S)=\\{x:g(x)\\in S\\} \\end{equation} is convex.\nThe projection of a convex set $S\\subset\\mathbb{R}^m\\times\\mathbb{R}^n$ onto some of its coordinates \\begin{equation} T=\\{x_1\\in\\mathbb{R}^m:(x_1,x_2)\\in S,\\text{ for some }x_2\\in\\mathbb{R}^n\\} \\end{equation} is convex.\nIf $S_1,S_2$ are convex then so is their sum \\begin{equation} S_1+S_2=\\{x_1+x_2:x_1\\in S_1,x_2\\in S_2\\} \\end{equation} This is due to its reverse image under the linear function $f(x_1,x_2)=x_1+x_2$, which is the Cartesian product \\begin{equation} S_1\\times S_2=\\{(x_1,x_2):x_1\\in S_1,x_2\\in S_2\\} \\end{equation} is convex.\nLinear-fractional, perspective functions Perspective functions The perspective function $P:\\mathbb{R}^{n+1}\\to\\mathbb{R}^n$, with domain $\\text{dom}\\hspace{0.1cm}P=\\mathbb{R}^n\\times\\mathbb{R}_{++}$ is defined as \\begin{equation} P(z,t)=\\frac{z}{t} \\end{equation} Suppose that $x=(\\tilde{x},x_{n+1}),y=(\\tilde{y},y_{n+1})\\in\\mathbb{R}^{n+1}$ with $x_{n+1},y_{n+1}\\gt 0$. Then for $0\\leq\\theta\\leq 1$, we have \\begin{equation} P(\\theta x+(1-\\theta)y)=\\frac{\\theta\\tilde{x}+(1-\\theta)\\tilde{y}}{\\theta x_{1+1}+(1-\\theta)y_{n+1}}=\\mu P(x)+(1-\\mu)P(y), \\end{equation} where \\begin{equation} \\mu=\\frac{\\theta x_{n+1}}{\\theta x_{n+1}+(1-\\theta)y_{n+1}}\\in[0,1], \\end{equation} which implies that \\begin{equation} P([x,y])=[P(x),P(y)]\\label{eq:pf.1} \\end{equation} Let $C$ be convex with $C\\subset\\text{dom}\\hspace{0.1cm}P$, and let $x,y\\in C$. By \\eqref{eq:pf.1}, we have that the line segment $[P(x),P(y)]$ is the image of the line segment $[x,y]$ under $P$, $P([x,y])$, and so lies in $P(C)$, which also claims the convexity of $P(C)$.\nThe inverse image of a convex set under the perspective function is also convex: if $C\\subset\\mathbb{R}^n$ is convex, then \\begin{equation} P^{-1}(C)=\\{(x,t)\\in\\mathbb{R}^{n+1}:x/t\\in C,t\u003e0\\} \\end{equation} is convex.\nTo prove this, for any $(x_1,t_1),(x_2,t_2)\\in P^{-1}(C)$ and for any $0\\leq t\\leq 1$, by the result \\eqref{eq:pf.1}, we have \\begin{equation} P^{-1}\\big(\\theta(x_1,t_1)+(1-\\theta)(x_2,t_2)\\big)=\\frac{\\theta x_1+(1-\\theta x_2)}{\\theta t_1+(1-\\theta)t_2}=\\mu\\frac{x_1}{t_1}+(1-\\mu)\\frac{x_2}{t_2}, \\end{equation} where \\begin{equation} \\mu=\\frac{\\theta t_1}{\\theta t_1+(1-\\theta)t_2}\\in[0,1] \\end{equation}\nLinear-fractional functions We define the linear-fractional function to be the composite function of a perspective function with an affine function. Specifically, let $g:\\mathbb{R}^n\\to\\mathbb{R}^{m+1}$ be affine \\begin{equation} g(x)=\\left[\\begin{matrix}A \\\\ c^\\text{T}\\end{matrix}\\right]x+\\left[\\begin{matrix}b \\\\ d\\end{matrix}\\right], \\end{equation} where $A\\in\\mathbb{R}^{m\\times n},b\\in\\mathbb{R}^m,c\\in\\mathbb{R}^n$ and $d\\in\\mathbb{R}$. The function $f:\\mathbb{R}^n\\to\\mathbb{R}^m$ given by \\begin{equation} f(x)=(P\\circ g)(x)=\\frac{Ax+b}{c^\\text{T}x+d}, \\end{equation} for $\\text{dom}\\hspace{0.1cm}f\\{x:c^\\text{T}x+d\u003e0\\}$, is called a linear-fractional function.\nIt is convenient to represent a linear-fractional function as a matrix \\begin{equation} Q=\\left[\\begin{matrix}A\u0026b \\\\ c^\\text{T}\u0026d\\end{matrix}\\right]\\in\\mathbb{R}^{(m+1)\\times(n+1)}, \\end{equation} which lets \\begin{equation} Q\\left[\\begin{matrix}x \\\\ 1\\end{matrix}\\right]=\\left[\\begin{matrix}A\u0026b \\\\ c^\\text{T}\u0026d\\end{matrix}\\right]\\left[\\begin{matrix}x \\\\ 1\\end{matrix}\\right]=\\left[\\begin{matrix}Ax+b \\\\ c^\\text{T}x+d\\end{matrix}\\right] \\end{equation}\nConvex functions A function $f:\\mathbb{R}^n\\to\\mathbb{R}$ is called convex if $\\text{dom}\\hspace{0.1cm}f$ is a convex set and if for all $x,y\\in\\text{dom}\\hspace{0.1cm}f$ and for any $0\\leq\\theta\\leq 1$, we have \\begin{equation} f\\big(\\theta x+(1-\\theta)y\\big)\\leq\\theta f(x)+(1-\\theta)f(y)\\label{eq:cf.1} \\end{equation} Intuitively, we can think of the above inequality as the line segment between $(x,f(x))$ and $(y,f(y))$ lies above the graph of $f$.\nWe call $f$ a strictly convex function if strict inequality hold in \\eqref{eq:cf.1} for every $x\\neq y$ and $0\\lt\\theta\\lt 1$. And $f$ is referred as concave if $-f$ is convex, or is known as strictly concave if $-f$ is strictly convex.\nA function is convex iff it is convex when restricted to any line that intersects its domain. In other words, $f$ is convex iff for all $x\\in\\text{dom}\\hspace{0.1cm}f$ and for all $v$, the function \\begin{equation} g(t)=f(x+tv) \\end{equation} is convex on its domain, $\\text{dom}\\hspace{0.1cm}g=\\{t:x+tv\\in\\text{dom}\\hspace{0.1cm}f\\}$.\nAll linear and affine functions are either convex or concave.\nProperties First-order conditions Let $f$ be differentible, i.e. $\\nabla f$ exists at each point in $\\text{dom}\\hspace{0.1cm}f$, which is open. Then $f$ is convex iff $\\text{dom}\\hspace{0.1cm}f$ is convex and \\begin{equation} f(y)\\geq f(x)+\\nabla f(x)^\\text{T}(y-x) \\end{equation} holds for all $x,y\\in\\text{dom}\\hspace{0.1cm}f$.\nSimilarly, we can also have that $f$ is strictly convex iff $\\text{dom}\\hspace{0.1cm}f$ is convex and for $x,y\\in\\text{dom}\\hspace{0.1cm}f$ such that $x\\neq y$, we have \\begin{equation} f(y)\u003ef(x)+\\nabla f(x)^\\text{T}(y-x) \\end{equation} And hence, $f$ is concave iff $\\text{dom}\\hspace{0.1cm}f$ is convex and for all $x,y\\in\\text{dom}\\hspace{0.1cm}f$, we have \\begin{equation} f(y)\\leq f(x)+\\nabla f(x)^\\text{T}(y-x) \\end{equation}\nProof\nWe first consider the case that $n=1$, i.e. $f:\\mathbb{R}\\to\\mathbb{R}$ is convex iff for all $x,y\\in$, we have \\begin{equation} f(y)\\geq f(x)+f’(x)(y-x)\\label{eq:soc.1} \\end{equation} Suppose that $f$ is convex, thus $\\text{dom}\\hspace{0.1cm}f$ is convex.\nLet $x,y$ be two points in $\\text{dom}\\hspace{0.1cm}f$. We therefore have that for any $0\\lt\\theta\\leq 1$, $(1-\\theta)x+\\theta y\\in\\text{dom}\\hspace{0.1cm}f$ and \\begin{equation} f\\big((1-\\theta)x+\\theta y\\big)\\leq(1-\\theta)f(x)+\\theta f(y), \\end{equation} which give us \\begin{equation} f(y)\\geq f(x)+\\frac{f\\big(x+\\theta(y-x)\\big)-f(x)}{\\theta} \\end{equation} Let $t\\to 0$, we obtain \\begin{equation} f(y)\\geq f(x)+f’(x)(y-x) \\end{equation} Given $f$ such that \\eqref{eq:soc.1} satisfies for all $x,y$ in $\\text{dom}\\hspace{0.1cm}f$ and $\\text{dom}\\hspace{0.1cm}f$ is convex.\nChoose any $x\\neq y$ and let $z=\\theta x+(1-\\theta)y$, for some $0\\leq\\theta\\leq 1$, we then have $z\\in\\text{dom}\\hspace{0.1cm}f$, which implies that \\begin{equation} f(x)\\geq f(z)+f’(z)(x-z) \\end{equation} and \\begin{equation} f(y)\\geq f(z)+f’(z)(y-z) \\end{equation} Since $0\\leq\\theta\\leq 1$, these two results above give us \\begin{equation} \\theta f(x)+(1-\\theta)f(y)\\geq f(z)=\\theta x+(1-\\theta)y, \\end{equation} which proves our claim.\nFor the general case of $f:\\mathbb{R}^n\\to\\mathbb{R}$. Let $x,y\\in\\mathbb{R}^n$ and consider $f$ restricted to the line passing through $x,y$, i.e. the function \\begin{equation} g(t)=f(ty+(1-t)x), \\end{equation} whose derivative is given as \\begin{equation} g’(t)=\\nabla f(ty+(1-t)x)^\\text{T}(y-x) \\end{equation} First suppose that $f$ is convex, and thus so is $g$. Using the above argument for the case of $n=1$, we have that \\begin{equation} g(1)\\geq g(0)+g’(0) \\end{equation} or \\begin{equation} f(y)\\geq f(x)+\\nabla f(x)^\\text{T}(y-x)\\label{eq:soc.2} \\end{equation} We continue with assuming that \\eqref{eq:soc.2} holds for any $x,y\\in\\text{dom}\\hspace{0.1cm}f$ and $\\text{dom}\\hspace{0.1cm}f$ is convex.\nThe convexity of $\\text{dom}\\hspace{0.1cm}f$ implies that for any $x,y\\in\\text{dom}\\hspace{0.1cm}f$ and for any $0\\leq t_1,t_2\\leq 1$, we have \\begin{equation} t_1 y+(1-t_1)x,t_2 y+(1-t_2)x\\in\\text{dom}\\hspace{0.1cm}f \\end{equation} By \\eqref{eq:soc.2} we have \\begin{equation} f(t_1 y+(1-t_1)x)\\geq f(t_2 y+(1-t_2)x)+\\nabla f(t_2 y+(1-t_2)x)^\\text{T}(y-x)(t_1-t_2) \\end{equation} or \\begin{equation} g(t_1)\\geq g(t_2)+g’(t_2)(t_1-t_2), \\end{equation} which implies that $g$ is convex, and hence so is $f$.\nSecond-order conditions Consider a function $f$ such that $f$ is twice differentiable. Then $f$ is convex iff $\\text{dom}\\hspace{0.1cm}f$ is convex and its Hessian is positive semidefinite, i.e. for all $x\\in\\text{dom}\\hspace{0.1cm}f$ we have \\begin{equation} \\nabla^2 f(x)\\succeq 0 \\end{equation} Analogously, we have that $f$ is concave iff $\\text{dom}\\hspace{0.1cm}f$ is convex and for all $x\\in\\text{dom}\\hspace{0.1cm}f$, $\\nabla^2 f(x)\\preceq 0$.\nOn the other hands, $f$ is stricly convex (or concave) if $\\text{dom}\\hspace{0.1cm}f$ is convex and $\\nabla^2 f(x)\\succ 0$ (or $\\nabla^2 f(x)\\prec 0$) for all $x\\in\\text{dom}\\hspace{0.1cm}f$. The reverse order is not true.\nExamples Functions on $\\mathbb{R}$ Exponential. $\\hspace{0.1cm}e^{ax}$ is convex on $\\mathbb{R}$, for any $a\\in\\mathbb{R}$. Since \\begin{equation} (e^{ax})''=(a e^{ax})'=a^2 e^{ax}\\geq 0, \\end{equation} for $a\\in\\mathbb{R}$. Powers. $\\hspace{0.1cm}x^a$ is convex on $\\mathbb{R}_{++}$ when $a\\geq 1$ or $a\\leq 0$, and concave for $0\\leq a\\leq 1$.\nFor $x\\in\\mathbb{R}_{++}$ and for $a\\geq 1$ or $a\\leq 0$, we have \\begin{equation} (x^a)''=(a x^{a-1})'=a(a-1)x^{a-2}\\geq 0 \\end{equation} On the other hands, for $x\\in\\mathbb{R}_{++}$ and for $0\\leq a\\leq 1$, we have \\begin{equation} (x^a)''=a(a-1)x^{a-2}\\leq 0 \\end{equation} Powers of absolute value. $\\hspace{0.1cm}\\vert x\\vert^p$ is convex on $\\mathbb{R}$ for $p\\geq 1$.\nFor any $0\\leq\\theta\\leq 1$, by triangle inequality we have \\begin{align} f(\\theta x+(1-\\theta)y)\u0026=\\vert\\theta x+(1-\\theta)y\\vert^p \\\\ \u0026\\leq\\left(\\theta\\vert x\\vert+(1-\\theta)\\vert y\\vert\\right)^p \\end{align} Logarithm. $\\hspace{0.1cm}\\log x$ is concave on $\\mathbb{R}_{++}$.\nFor $x\\in\\mathbb{R}_{++}$ we have \\begin{equation} (\\log x)''=\\left(\\frac{1}{x}\\right)'=\\frac{-1}{x^2}\\lt 0 \\end{equation} Negative entropy. $\\hspace{0.1cm}x\\log x$ (either on $\\mathbb{R}_{++}$ or on $\\mathbb{R}_+$ and defined as $0$ for $x=0$) is convex.\nWe have for all $x\\in\\mathbb{R}_{++}$ \\begin{equation} (x\\log x)''=(1+\\log x)'=\\frac{1}{x}\u003e0 \\end{equation} Functions on $\\mathbb{R}^n$ Norms. Every norm on $\\mathbb{R}^n$ is convex.\nFor $f:\\mathbb{R}^n\\to\\mathbb{R}$ is a norm and for any $0\\leq\\theta\\leq 1$, by triangle inequality, we have: \\begin{equation} f\\big(\\theta x+(1-\\theta)y\\big)\\leq f(\\theta x)+f\\big((1-\\theta)y\\big)=\\theta f(\\theta)+(1-\\theta)f(y) \\end{equation} Max function. $\\hspace{0.1cm}f(x)=\\max{x_1,\\ldots,x_n}=\\max_{i=1,\\ldots,n}x_i$ is convex on $\\mathbb{R}^n$.\nFor any $0\\leq\\theta\\leq 1$, we have \\begin{align} f(\\theta x+(1-\\theta)y)\u0026=\\max_i(\\theta x+(1-\\theta)y) \\\\ \u0026\\leq\\theta\\max_i x_i+(1-\\theta)\\max_i y_i \\\\ \u0026=\\theta f(x)+(1-\\theta)f(y) \\end{align} Quadratic-over-linear function. The function $f(x,y)=x^2/y$ with \\begin{equation} \\text{dom}\\hspace{0.1cm}f=\\{(x,y)\\in\\mathbb{R}^2:y\u003e0\\} \\end{equation} is convex, since we have its Hessian: \\begin{equation} \\nabla^2 f(x,y)=\\nabla^2\\frac{x^2}{y}=\\left[\\begin{matrix}2/y\u0026-2x/y^2 \\\\ -2x/y^2\u00262x^2/y^3\\end{matrix}\\right]=\\frac{2}{y^3}\\left[\\begin{matrix}y \\\\ -x\\end{matrix}\\right]\\left[\\begin{matrix}y \\\\ -x\\end{matrix}\\right]^\\text{T}\\succeq 0 \\end{equation} Log-sum-exp. $\\hspace{0.1cm}f(x)=\\log(e^{x_1}+\\ldots+e^{x_n})$ is convex on $\\mathbb{R}^n$.\nWe have the Hessian of $f(x)$ is \\begin{equation} \\nabla^2 f(x)=\\nabla^2\\log(e^{x_1}+\\ldots+e^{x_n}) \\end{equation} Sub-level sets Inequalities Jensen’s inequality Operations that preserve convexity The conjugate function Quasiconvex functions References [1] Stephen Boyd \u0026 Lieven Vandenberghe. Convex Optimization. Cambridge UP, 2004.\nFootnotes","wordCount":"2547","inLanguage":"en","datePublished":"2021-12-02T13:03:00+07:00","dateModified":"2021-12-02T13:03:00+07:00","author":{"@type":"Person","name":"Trung H. Nguyen"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/posts/optimization/cvx-sets-funcs/"},"publisher":{"@type":"Organization","name":"Littleroot","logo":{"@type":"ImageObject","url":"http://localhost:1313/images/favicon/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Littleroot (Alt + H)"><img src=http://localhost:1313/images/others/littleroottown.png alt aria-label=logo height=27>Littleroot</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/posts/ title=Posts><span>Posts</span></a></li><li><a href=http://localhost:1313/archives/ title=Archive><span>Archive</span></a></li><li><a href=http://localhost:1313/tags/ title=Tags><span>Tags</span></a></li><li><a href=http://localhost:1313/about/ title=About><span>About</span></a></li><li><a href=http://localhost:1313/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Convex sets, convex functions<sup><span class=entry-isdraft>&nbsp;&nbsp;[draft]</span></sup></h1><div class=post-meta><span title='2021-12-02 13:03:00 +0700 +07'>December 2, 2021</span>&nbsp;·&nbsp;12 min&nbsp;·&nbsp;Trung H. Nguyen</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#cvx-sets>Convex sets</a><ul><li><a href=#aff-cvx-sets>Affine & convex sets</a><ul><li><a href=#aff-sets>Affine sets</a></li><li><a href=#aff-dim-rel-int>Affine dimension, relative interior</a></li><li><a href=#cvx-sets-def>Convex sets</a></li><li><a href=#cones>Cones</a></li></ul></li><li><a href=#cvx-sets-eg>Examples</a><ul><li><a href=#hyperplane-halfspaces>Hyperplanes, halfspaces</a></li><li><a href=#balls-ellips-cones>Balls, ellipsoids, norm cones</a><ul><li><a href=#balls>Balls</a></li><li><a href=#ellips>Ellipsoids</a></li><li><a href=#norm-cones>Norm cones</a></li></ul></li><li><a href=#polyhedra>Polyhedra</a><ul><li><a href=#non-neg-orthant>Nonnegative orthant</a></li><li><a href=#simplex>Simplex</a></li></ul></li><li><a href=#psd-cone>Positive semi-definite cone</a></li></ul></li><li><a href=#operations-sets>Operations that preserve convexity</a><ul><li><a href=#intersect>Intersection</a></li><li><a href=#aff-funcs>Affine functions</a></li><li><a href=#lin-frac-persp-funcs>Linear-fractional, perspective functions</a><ul><li><a href=#persp-funcs>Perspective functions</a></li><li><a href=#lin-frac-funcs>Linear-fractional functions</a></li></ul></li></ul></li></ul></li><li><a href=#cvx-funcs>Convex functions</a><ul><li><a href=#props>Properties</a><ul><li><a href=#st-order-conds>First-order conditions</a></li><li><a href=#nd-order-conds>Second-order conditions</a></li></ul></li><li><a href=#cvx-funcs-eg>Examples</a><ul><li><a href=#func-on-r>Functions on $\mathbb{R}$</a></li><li><a href=#func-on-rn>Functions on $\mathbb{R}^n$</a></li></ul></li><li><a href=#sub-lvl-sets>Sub-level sets</a></li><li><a href=#inequalities>Inequalities</a><ul><li><a href=#jensens-inequality>Jensen&rsquo;s inequality</a></li></ul></li><li><a href=#operations-funcs>Operations that preserve convexity</a></li><li><a href=#conjugate-func>The conjugate function</a></li><li><a href=#quasi-cvx-funcs>Quasiconvex functions</a></li></ul></li><li><a href=#references>References</a></li><li><a href=#footnotes>Footnotes</a></li></ul></nav></div></details></div><div class=post-content><blockquote><p>Notes on convex sets, convex functions.</p></blockquote><h2 id=cvx-sets>Convex sets<a hidden class=anchor aria-hidden=true href=#cvx-sets>#</a></h2><h3 id=aff-cvx-sets>Affine & convex sets<a hidden class=anchor aria-hidden=true href=#aff-cvx-sets>#</a></h3><h4 id=aff-sets>Affine sets<a hidden class=anchor aria-hidden=true href=#aff-sets>#</a></h4><p>A set $C\subset\mathbb{R}^n$ is <strong>affine</strong> if the line through any two distinct points in $C$ lies in $C$, i.e. for any $x_1,x_2\in C$ and for any $\theta\in\mathbb{R}$ we have
\begin{equation}
\theta x_1+(1-\theta)x_2\in C
\end{equation}
A point of the form $\theta_1 x_1+\ldots+\theta_k x_k$, where $\theta_1+\ldots+\theta_k=1$ is known as an <strong>affine combination</strong> of the points $x_1,\ldots,x_k$.</p><p>Hence, if $C$ is an affine set, and $x_1,\ldots,x_k\in C$, and $\theta_1+\ldots+\theta_k=1$, then the point
\begin{equation}
\theta_1 x_1+\ldots+\theta_k x_k\in C,
\end{equation}
or in other words, an affine set contains every affine combination of its points.</p><p>If $C$ is an affine set and $x_0\in C$, then the set
\begin{equation}
V=C-x_0\{x-x_0:x\in C\}
\end{equation}
is a subspace.</p><p>The set of all affine combinations of points in some set $C\subset\mathbb{R}^n$ is referred as <strong>affine hull</strong> of $C$, denoted $\text{aff}\hspace{0.1cm}C$:
\begin{equation}
\text{aff}\hspace{0.1cm}C=\{\theta_1 x_1+\ldots+\theta_k x_k:x_1,\ldots,x_k\in C;\theta_1+\ldots+\theta_k=1\}
\end{equation}
The affine hull is the <em>smallest</em> affine set containing $C$.</p><h4 id=aff-dim-rel-int>Affine dimension, relative interior<a hidden class=anchor aria-hidden=true href=#aff-dim-rel-int>#</a></h4><p>The <strong>affine dimension</strong> of a set $C$ is defined as the dimension of $\text{aff}\hspace{0.1cm}C$.</p><p>If the affine dimension of $C\subset\mathbb{R}^n$ is less than $n$, then the set lies in $\text{aff}\hspace{0.1cm}C\neq\mathbb{R}^n$. The <strong>relative interior</strong> of the set $C$, denoted as $\text{relint}\hspace{0.1cm}C$, is defined as its interior relative to $\text{aff}\hspace{0.1cm}C$:
\begin{equation}
\text{relint}\hspace{0.1cm}C=\{x\in C:B(x,r)\cap\text{aff}\hspace{0.1cm}C\in C\text{ for some }r>0\},
\end{equation}
where $B(x,r)$ is the ball centered at $x$ with radius $r$ in the norm $\Vert\cdot\Vert$ (here $\Vert\cdot\Vert$ could be any norm; all norms define the same relative interior).</p><p>The <strong>relative boundary</strong> of $C$ is defined as $\overline{C}\backslash\text{relint}\hspace{0.1cm}C$, where $\overline{C}$ is the closure of $C$.</p><h4 id=cvx-sets-def>Convex sets<a hidden class=anchor aria-hidden=true href=#cvx-sets-def>#</a></h4><p>A set $C$ is <strong>convex</strong> if the line segment between any points in $C$ also lies in $C$, i.e. for any $x_1,x_2\in C$ and for any $0\leq\theta\leq 1$, we have
\begin{equation}
\theta x_1+(1-\theta)x_2\in C
\end{equation}
It is then easily seen that every affine sets is also convex.</p><p>Analogy to affine sets, we also refer a point of the form $\theta_1 x_1+\ldots+\theta_k x_k$, where $\theta_1+\ldots+\theta_k=1$ and $\theta_i\geq 0,\forall i=1,\ldots,k$, a <strong>convex combination</strong> of the points $x_1,\ldots,x_k$. And a set is convex iff it contains every convex combination of its points.</p><p>The <strong>convex hull</strong> of $C$, denoted $\text{conv}\hspace{0.1cm}C$, is defined as the set of all convex combinations of points in $C$:
\begin{equation}
\text{conv}\hspace{0.1cm}C=\{\theta_1 x_1+\ldots+\theta_k x_k:x_1,\ldots,x_k\in C;\theta_1+\ldots+\theta_k=1;\theta_1,\ldots,\theta_k\geq 0\}
\end{equation}
Thus, $\text{conv}\hspace{0.1cm}C$ is convex and is the smallest convex set containing $C$.</p><p>We can generalize the definition of convex combination into: let $x_1,x_2\ldots\in C$ where $C\subset\mathbb{R}^n$ and let $\{\theta_n\}_{n=1,2,\ldots}$ be a countable sequence such that
\begin{equation}
\sum_{i=1}^{\infty}\theta_i=1;\hspace{2cm}\theta_i\geq 0,\hspace{0.5cm}\forall i=1,2,\ldots
\end{equation}
Then the series
\begin{equation}
\sum_{i=1}^{\infty}\theta_i x_i\in C,
\end{equation}
if it converges.</p><p>More generally, suppose $p:\mathbb{R}^n\to\mathbb{R}$ satisfies $p(x)\geq 0$ forall $x\in C$ and $\int_C p(x)\hspace{0.1cm}dx=1$, where $C\subset\mathbb{R}^n$ is a convex set. Then the integral
\begin{equation}
\int_C p(x)x\hspace{0.1cm}dx\in C
\end{equation}
if it exists.</p><p>In the most general form, suppose $C\subset\mathbb{R}^n$ is convex and $x$ is a random vector with $x\in C$ with probability one. Then we also have that
\begin{equation}
\mathbb{E}x\in C
\end{equation}</p><h4 id=cones>Cones<a hidden class=anchor aria-hidden=true href=#cones>#</a></h4><p>A set $C$ is called a <strong>cone</strong>, or <strong>nonnegative homogeneous</strong>, if for every $x\in C$ and for any $\theta\geq 0$, we also have $\theta x\in C$.</p><p>A <strong>convex cone</strong> $C$ is both convex and a cone, i.e. for any $x_1,x_2\in C$ and for any $\theta_1,\theta_2\geq 0$, we have
\begin{equation}
\theta_1 x_1+\theta_2 x_2\in C
\end{equation}
since by definition of a cone, we can add a normalization factor $\alpha$ into the point above
\begin{equation}
\alpha\theta_1 x_1+\alpha\theta_2 x_2
\end{equation}
such that $\alpha\theta_1+\alpha\theta_2=1$ (in this particular case, $\alpha=1/(\theta_1+\theta_2)$).</p><p>A point of the form $\theta_1 x_1+\ldots+\theta_k x_k$ with $\theta_1,\ldots,\theta_k\geq 0$ is called a <strong>conic combination</strong>. It is easily seen that a set $C$ is a convex cone iff it contains all conic combinations of its points.
Like convex and affine combinations, we can generalize the definition of conic combination into infinite series and integrals.</p><p>We define the <strong>conic hull</strong> of a set $C$ as the set of all conic combinations of elements in $C$
\begin{equation}
\{\theta_1 x_1+\ldots+\theta_k x_k:x_i\in C;\theta_i\geq 0,\forall i=1,\ldots,k\}
\end{equation}
Also, the conic hull of $C$ is the smallest convex cone containing $C$.</p><h3 id=cvx-sets-eg>Examples<a hidden class=anchor aria-hidden=true href=#cvx-sets-eg>#</a></h3><h4 id=hyperplane-halfspaces>Hyperplanes, halfspaces<a hidden class=anchor aria-hidden=true href=#hyperplane-halfspaces>#</a></h4><p>A <strong>hyperplane</strong> $P$ is a set of form
\begin{equation}
P=\{x\in\mathbb{R}^n:a^\text{T}x=b\},
\end{equation}
where $a\in\mathbb{R}^n$, $a\neq 0$ and $b\in\mathbb{R}$. We have that $P$ is convex.</p><p>To prove this, for $x_1,x_2\in P$, and for any $0\leq\theta\leq 1$, we have
\begin{equation}
a^\text{T}\big(\theta x_1+(1-\theta)x_2\big)=\theta a^\text{T}x_1+(1-\theta)a^\text{T}x_2=\theta b+(1-\theta)b=b
\end{equation}</p><p>A hyperplane separates $\mathbb{R}^n$ into two <strong>halfspaces</strong>. A (closed) halfspace is a set of of the form
\begin{equation}
\{x\in\mathbb{R}^n:a^\text{T}x\leq b\},
\end{equation}
where $a\in\mathbb{R}^n$, $a\neq 0$ and $b\in\mathbb{R}$. It is also easily seen that halfspaces are also convex.</p><h4 id=balls-ellips-cones>Balls, ellipsoids, norm cones<a hidden class=anchor aria-hidden=true href=#balls-ellips-cones>#</a></h4><h5 id=balls>Balls<a hidden class=anchor aria-hidden=true href=#balls>#</a></h5><p>A (closed) <strong>ball</strong> in $\mathbb{R}^n$ centered at $x_c$ and with radius $r$ and with $\Vert\cdot\Vert$ is any norm in $\mathbb{R}^n$
\begin{equation}
B(x_c,r)=\{x\in\mathbb{R}^n:\Vert x-x_c\Vert\leq r\}
\end{equation}
is a convex set.</p><p>To see this, for any $x_1,x_2\in B(x_c,r)$ and for any $0\leq\theta\leq 1$, by triangle inequality of norm, we have
\begin{align}
\Vert\theta x_1+(1-\theta)x_2-x_c\Vert&=\Vert\theta(x_1-x_c)+(1-\theta)(x_2-x_c)\Vert \\ &\leq\theta\Vert x_1-x_c\Vert+(1-\theta)\Vert x_2-x_c\Vert \\ &\leq\theta r+(1-\theta)r \\ &=r
\end{align}</p><h5 id=ellips>Ellipsoids<a hidden class=anchor aria-hidden=true href=#ellips>#</a></h5><p>An <strong>ellipsoid</strong> $\mathcal{E}$ in $\mathbb{R}^n$ centered at $x_c\in\mathbb{R}^n$ is defined as
\begin{equation}
\mathcal{E}=\{x:(x-x_c)^\text{T}P^{-1}(x-x_c)\leq 1\},
\end{equation}
where $P\in\mathbb{R}^{n\times n}$ is symmetric and positive definite. The matrix $P$ determines how far $\mathcal{E}$ extends in every direction from $x_c$; the lengths of the semi-axes of $\mathcal{E}$ are $\sqrt{\lambda_i}$, where $\lambda_i$ for $i=1,\ldots,n$ are the eigenvalues of $P$. A ball of radius $r$ is an ellipsoid with
\begin{equation}
P=r^2 I
\end{equation}
We then have $\mathcal{E}$ is convex.</p><p>To prove this claim, as usual, for $x_1,x_2\in\mathcal{E}$ and for $0\leq\theta\leq 1$, we have
\begin{align}
&\hspace{0.7cm}\big(\theta x_1+(1-\theta)x_2-x_c\big)^\text{T}P^{-1}\big(\theta x_1+(1-\theta)x_2-x_c\big) \\ &=\big(\theta x_1-\theta x_c+(1-\theta)x_2-(1-\theta)x_c\big)^\text{T}P^{-1}\big(\theta x_1-\theta x_c+(1-\theta)x_2-(1-\theta)x_c\big) \\ &=(a+b)^\text{T}P^{-1}(a+b) \\ &=a^\text{T}P^{-1}a+b^\text{T}P^{-1}b+2a^\text{T}P^{-1}b \\ &\leq\theta^2+(1-\theta)^2+2\theta(1-\theta) \\ &=1
\end{align}
where in the second step, we have let
\begin{equation}
a=\theta x_1-\theta x_c,\hspace{2cm}b=(1-\theta)x_2-(1-\theta)x_c,
\end{equation}
which implies that
\begin{equation}
a^\text{T}P^{-1}a\leq 1,\hspace{2cm}b^\text{T}P^{-1}b\leq 1
\end{equation}
and thus
\begin{equation}
a^\text{T}P^{-1/2}\leq 1,\hspace{2cm}b^\text{T}P^{-1/2}\leq 1
\end{equation}</p><h5 id=norm-cones>Norm cones<a hidden class=anchor aria-hidden=true href=#norm-cones>#</a></h5><p>A <strong>norm cone</strong> $C$ associated with the norm $\Vert\cdot\Vert$ is defined as
\begin{equation}
C=\{(x,t):\Vert x\Vert\leq t\}\subset\mathbb{R}^{n+1}
\end{equation}
is also convex</p><h4 id=polyhedra>Polyhedra<a hidden class=anchor aria-hidden=true href=#polyhedra>#</a></h4><p>A <strong>polyhedron</strong> $\mathcal{P}$ is defined as
\begin{equation}
\mathcal{P}=\{x:a_i^\text{T}\leq b_i,i=1,\ldots,m;c_j^\text{T}=d_j,j=1,\ldots,p\}
\end{equation}
Then $\mathcal{P}$ can be seen as the intersection of a finite number of halfspaces and hyperplanes. Another representation of $\mathcal{P}$ is
\begin{equation}
\mathcal{P}=\{x:Ax\preceq b,Cx=d\},
\end{equation}
where
\begin{equation}
A=\left[\begin{matrix}a_1^\text{T} \\ \vdots \\ a_m^\text{T}\end{matrix}\right],\hspace{2cm}C=\left[\begin{matrix}c_1^\text{T} \\ \vdots \\ c_p^\text{T}\end{matrix}\right]
\end{equation}
And thus, we also have that $\mathcal{P}$ is convex, which can be proved easily since $Ax$ and $Cx$ are both linear functions.</p><h5 id=non-neg-orthant>Nonnegative orthant<a hidden class=anchor aria-hidden=true href=#non-neg-orthant>#</a></h5><p>The <strong>nonnegative orthant</strong> in $\mathbb{R}^n$, denoted $\mathbb{R}_+^{n}$, is the set of points with nonnegative components, i.e.
\begin{equation}
\mathbb{R}_+^n=\{x\in\mathbb{R}^n:x\succeq 0\}
\end{equation}
We have that $\mathbb{R}_+^n$ is both a polyhedron and a cone, or a <strong>polyhedral cone</strong>, and hence is also convex.</p><h5 id=simplex>Simplex<a hidden class=anchor aria-hidden=true href=#simplex>#</a></h5><p>Suppose the $v_0,\ldots,v_k\in\mathbb{R}^n$ are <strong>affinely independent</strong>, i.e. $v_1-v_0,\ldots,v_k-v_0$ are linearly independent. The <strong>simplex</strong> determined by them is given as
\begin{equation}
C=\text{conv}\{v_0,\ldots,v_k\}=\{\theta_0 v_0+\ldots+\theta_k v_k:\theta\succeq 0,\mathbf{1}^\text{T}\theta=1\}
\end{equation}
As an instance of polyhedra, $C$ is thus convex.</p><h4 id=psd-cone>Positive semi-definite cone<a hidden class=anchor aria-hidden=true href=#psd-cone>#</a></h4><p>Let $\mathbb{S}^n$ denote the set of symmetric $n\times n$ matrices
\begin{equation}
\mathbb{S}^n=\{X\in\mathbb{R}^{n\times n}:X=X^\text{T}\},
\end{equation}
and let $\mathbb{S}_+^n$ represent the set of symmetric positive semi-definite matrices
\begin{equation}
\mathbb{S}_+^n=\{X\in\mathbb{S}^n:X\succeq 0\},
\end{equation}
and finally, let us assign the set of symmetric positive definite matrices to $\mathbb{S}_{++}^n$
\begin{equation}
\mathbb{S}_{++}^n=\{X\in\mathbb{S}^n:X\succ 0\}
\end{equation}
We have that $\mathbb{S}_+^n$ is a convex cone, since for any matrices $A_1,A_2\in\mathbb{S}_+^n$, for any $\theta_1,\theta_2\geq 0$ and for any $x\in\mathbb{R}^n$, we have
\begin{equation}
x^\text{T}(\theta_1 A_1+\theta_2 A_2)x=\theta_1 x^\text{T}A_1 x+\theta_2 x^\text{T}A_2 x\geq 0
\end{equation}
The same argument can be applied to prove that $\mathbb{S}_{++}^n$ or even the set of symmetric negative definite matrices and the set of symmetric negative semi-definite matrices are convex.</p><h3 id=operations-sets>Operations that preserve convexity<a hidden class=anchor aria-hidden=true href=#operations-sets>#</a></h3><h4 id=intersect>Intersection<a hidden class=anchor aria-hidden=true href=#intersect>#</a></h4><p>Let $S_1,S_2$ be convex sets and let $x_1,x_2$ are two points containing in both sets, thus $x_1,x_2\in S_1\cap S_2$.</p><p>Since $x_1,x_2\in S_1$ which is convex, for $0\leq\theta\leq 1$, we have the point
\begin{equation}
\theta x_1+(1-\theta)x_2\in S_1
\end{equation}
Analogously, we also have
\begin{equation}
\theta x_1+(1-\theta)x_2\in S_2,
\end{equation}
which implies that
\begin{equation}
\theta x_1+(1-\theta)x_2\in S_1\cap S_2
\end{equation}
Or in other words, $S_1\cap S_2$ is also convex.</p><p>By induction, we can extend this property to: if $S_\alpha$ is convex for every $\alpha\in\mathcal{A}$, then their intersection
\begin{equation}
\bigcap_{\alpha\in\mathcal{A}}S_\alpha
\end{equation}
is also convex.</p><h4 id=aff-funcs>Affine functions<a hidden class=anchor aria-hidden=true href=#aff-funcs>#</a></h4><p>A function $f:\mathbb{R}^n\to\mathbb{R}^m$ is <strong>affine</strong> if it is a sum of linear function and a constant, i.e. it can be written as
\begin{equation}
f(x)=Ax+b,
\end{equation}
where $A\in\mathbb{R}^{m\times n}$ and $b\in\mathbb{R}^m$.</p><p>Let $S\subset\mathbb{R}^n$ be a convex set and let $f:\mathbb{R}^n\to\mathbb{R}^m$ be an affine function. Then the image of $S$ under $f$
\begin{equation}
f(S)=\{f(x):x\in S\}
\end{equation}
is convex.</p><p>Analogously, the inverse image of $S$ under an affine function $g:\mathbb{R}^k\to\mathbb{R}^n$
\begin{equation}
g^{-1}(S)=\{x:g(x)\in S\}
\end{equation}
is convex.</p><p>The <strong>projection</strong> of a convex set $S\subset\mathbb{R}^m\times\mathbb{R}^n$ onto some of its coordinates
\begin{equation}
T=\{x_1\in\mathbb{R}^m:(x_1,x_2)\in S,\text{ for some }x_2\in\mathbb{R}^n\}
\end{equation}
is convex.</p><p>If $S_1,S_2$ are convex then so is their sum
\begin{equation}
S_1+S_2=\{x_1+x_2:x_1\in S_1,x_2\in S_2\}
\end{equation}
This is due to its reverse image under the linear function $f(x_1,x_2)=x_1+x_2$, which is the <strong>Cartesian product</strong>
\begin{equation}
S_1\times S_2=\{(x_1,x_2):x_1\in S_1,x_2\in S_2\}
\end{equation}
is convex.</p><h4 id=lin-frac-persp-funcs>Linear-fractional, perspective functions<a hidden class=anchor aria-hidden=true href=#lin-frac-persp-funcs>#</a></h4><h5 id=persp-funcs>Perspective functions<a hidden class=anchor aria-hidden=true href=#persp-funcs>#</a></h5><p>The <strong>perspective function</strong> $P:\mathbb{R}^{n+1}\to\mathbb{R}^n$, with domain $\text{dom}\hspace{0.1cm}P=\mathbb{R}^n\times\mathbb{R}_{++}$ is defined as
\begin{equation}
P(z,t)=\frac{z}{t}
\end{equation}
Suppose that $x=(\tilde{x},x_{n+1}),y=(\tilde{y},y_{n+1})\in\mathbb{R}^{n+1}$ with $x_{n+1},y_{n+1}\gt 0$. Then for $0\leq\theta\leq 1$, we have
\begin{equation}
P(\theta x+(1-\theta)y)=\frac{\theta\tilde{x}+(1-\theta)\tilde{y}}{\theta x_{1+1}+(1-\theta)y_{n+1}}=\mu P(x)+(1-\mu)P(y),
\end{equation}
where
\begin{equation}
\mu=\frac{\theta x_{n+1}}{\theta x_{n+1}+(1-\theta)y_{n+1}}\in[0,1],
\end{equation}
which implies that
\begin{equation}
P([x,y])=[P(x),P(y)]\label{eq:pf.1}
\end{equation}
Let $C$ be convex with $C\subset\text{dom}\hspace{0.1cm}P$, and let $x,y\in C$. By \eqref{eq:pf.1}, we have that the line segment $[P(x),P(y)]$ is the image of the line segment $[x,y]$ under $P$, $P([x,y])$, and so lies in $P(C)$, which also claims the convexity of $P(C)$.</p><p>The inverse image of a convex set under the perspective function is also convex: if $C\subset\mathbb{R}^n$ is convex, then
\begin{equation}
P^{-1}(C)=\{(x,t)\in\mathbb{R}^{n+1}:x/t\in C,t>0\}
\end{equation}
is convex.</p><p>To prove this, for any $(x_1,t_1),(x_2,t_2)\in P^{-1}(C)$ and for any $0\leq t\leq 1$, by the result \eqref{eq:pf.1}, we have
\begin{equation}
P^{-1}\big(\theta(x_1,t_1)+(1-\theta)(x_2,t_2)\big)=\frac{\theta x_1+(1-\theta x_2)}{\theta t_1+(1-\theta)t_2}=\mu\frac{x_1}{t_1}+(1-\mu)\frac{x_2}{t_2},
\end{equation}
where
\begin{equation}
\mu=\frac{\theta t_1}{\theta t_1+(1-\theta)t_2}\in[0,1]
\end{equation}</p><h5 id=lin-frac-funcs>Linear-fractional functions<a hidden class=anchor aria-hidden=true href=#lin-frac-funcs>#</a></h5><p>We define the <strong>linear-fractional function</strong> to be the composite function of a perspective function with an affine function. Specifically, let $g:\mathbb{R}^n\to\mathbb{R}^{m+1}$ be affine
\begin{equation}
g(x)=\left[\begin{matrix}A \\ c^\text{T}\end{matrix}\right]x+\left[\begin{matrix}b \\ d\end{matrix}\right],
\end{equation}
where $A\in\mathbb{R}^{m\times n},b\in\mathbb{R}^m,c\in\mathbb{R}^n$ and $d\in\mathbb{R}$. The function $f:\mathbb{R}^n\to\mathbb{R}^m$ given by
\begin{equation}
f(x)=(P\circ g)(x)=\frac{Ax+b}{c^\text{T}x+d},
\end{equation}
for $\text{dom}\hspace{0.1cm}f\{x:c^\text{T}x+d>0\}$, is called a <strong>linear-fractional function</strong>.</p><p>It is convenient to represent a linear-fractional function as a matrix
\begin{equation}
Q=\left[\begin{matrix}A&amp;b \\ c^\text{T}&amp;d\end{matrix}\right]\in\mathbb{R}^{(m+1)\times(n+1)},
\end{equation}
which lets
\begin{equation}
Q\left[\begin{matrix}x \\ 1\end{matrix}\right]=\left[\begin{matrix}A&amp;b \\ c^\text{T}&amp;d\end{matrix}\right]\left[\begin{matrix}x \\ 1\end{matrix}\right]=\left[\begin{matrix}Ax+b \\ c^\text{T}x+d\end{matrix}\right]
\end{equation}</p><h2 id=cvx-funcs>Convex functions<a hidden class=anchor aria-hidden=true href=#cvx-funcs>#</a></h2><p>A function $f:\mathbb{R}^n\to\mathbb{R}$ is called <strong>convex</strong> if $\text{dom}\hspace{0.1cm}f$ is a convex set and if for all $x,y\in\text{dom}\hspace{0.1cm}f$ and for any $0\leq\theta\leq 1$, we have
\begin{equation}
f\big(\theta x+(1-\theta)y\big)\leq\theta f(x)+(1-\theta)f(y)\label{eq:cf.1}
\end{equation}
Intuitively, we can think of the above inequality as the line segment between $(x,f(x))$ and $(y,f(y))$ lies above the graph of $f$.</p><p>We call $f$ a <strong>strictly convex</strong> function if strict inequality hold in \eqref{eq:cf.1} for every $x\neq y$ and $0\lt\theta\lt 1$. And $f$ is referred as <strong>concave</strong> if $-f$ is convex, or is known as <strong>strictly concave</strong> if $-f$ is strictly convex.</p><p>A function is convex iff it is convex when restricted to any line that intersects its domain. In other words, $f$ is convex iff for all $x\in\text{dom}\hspace{0.1cm}f$ and for all $v$, the function
\begin{equation}
g(t)=f(x+tv)
\end{equation}
is convex on its domain, $\text{dom}\hspace{0.1cm}g=\{t:x+tv\in\text{dom}\hspace{0.1cm}f\}$.</p><p>All linear and affine functions are either convex or concave.</p><h3 id=props>Properties<a hidden class=anchor aria-hidden=true href=#props>#</a></h3><h4 id=st-order-conds>First-order conditions<a hidden class=anchor aria-hidden=true href=#st-order-conds>#</a></h4><p>Let $f$ be differentible, i.e. $\nabla f$ exists at each point in $\text{dom}\hspace{0.1cm}f$, which is open. Then $f$ is convex iff $\text{dom}\hspace{0.1cm}f$ is convex and
\begin{equation}
f(y)\geq f(x)+\nabla f(x)^\text{T}(y-x)
\end{equation}
holds for all $x,y\in\text{dom}\hspace{0.1cm}f$.</p><p>Similarly, we can also have that $f$ is strictly convex iff $\text{dom}\hspace{0.1cm}f$ is convex and for $x,y\in\text{dom}\hspace{0.1cm}f$ such that $x\neq y$, we have
\begin{equation}
f(y)>f(x)+\nabla f(x)^\text{T}(y-x)
\end{equation}
And hence, $f$ is concave iff $\text{dom}\hspace{0.1cm}f$ is convex and for all $x,y\in\text{dom}\hspace{0.1cm}f$, we have
\begin{equation}
f(y)\leq f(x)+\nabla f(x)^\text{T}(y-x)
\end{equation}</p><p><strong>Proof</strong><br>We first consider the case that $n=1$, i.e. $f:\mathbb{R}\to\mathbb{R}$ is convex iff for all $x,y\in$, we have
\begin{equation}
f(y)\geq f(x)+f&rsquo;(x)(y-x)\label{eq:soc.1}
\end{equation}
Suppose that $f$ is convex, thus $\text{dom}\hspace{0.1cm}f$ is convex.</p><p>Let $x,y$ be two points in $\text{dom}\hspace{0.1cm}f$. We therefore have that for any $0\lt\theta\leq 1$, $(1-\theta)x+\theta y\in\text{dom}\hspace{0.1cm}f$ and
\begin{equation}
f\big((1-\theta)x+\theta y\big)\leq(1-\theta)f(x)+\theta f(y),
\end{equation}
which give us
\begin{equation}
f(y)\geq f(x)+\frac{f\big(x+\theta(y-x)\big)-f(x)}{\theta}
\end{equation}
Let $t\to 0$, we obtain
\begin{equation}
f(y)\geq f(x)+f&rsquo;(x)(y-x)
\end{equation}
Given $f$ such that \eqref{eq:soc.1} satisfies for all $x,y$ in $\text{dom}\hspace{0.1cm}f$ and $\text{dom}\hspace{0.1cm}f$ is convex.</p><p>Choose any $x\neq y$ and let $z=\theta x+(1-\theta)y$, for some $0\leq\theta\leq 1$, we then have $z\in\text{dom}\hspace{0.1cm}f$, which implies that
\begin{equation}
f(x)\geq f(z)+f&rsquo;(z)(x-z)
\end{equation}
and
\begin{equation}
f(y)\geq f(z)+f&rsquo;(z)(y-z)
\end{equation}
Since $0\leq\theta\leq 1$, these two results above give us
\begin{equation}
\theta f(x)+(1-\theta)f(y)\geq f(z)=\theta x+(1-\theta)y,
\end{equation}
which proves our claim.</p><p>For the general case of $f:\mathbb{R}^n\to\mathbb{R}$. Let $x,y\in\mathbb{R}^n$ and consider $f$ restricted to the line passing through $x,y$, i.e. the function
\begin{equation}
g(t)=f(ty+(1-t)x),
\end{equation}
whose derivative is given as
\begin{equation}
g&rsquo;(t)=\nabla f(ty+(1-t)x)^\text{T}(y-x)
\end{equation}
First suppose that $f$ is convex, and thus so is $g$. Using the above argument for the case of $n=1$, we have that
\begin{equation}
g(1)\geq g(0)+g&rsquo;(0)
\end{equation}
or
\begin{equation}
f(y)\geq f(x)+\nabla f(x)^\text{T}(y-x)\label{eq:soc.2}
\end{equation}
We continue with assuming that \eqref{eq:soc.2} holds for any $x,y\in\text{dom}\hspace{0.1cm}f$ and $\text{dom}\hspace{0.1cm}f$ is convex.</p><p>The convexity of $\text{dom}\hspace{0.1cm}f$ implies that for any $x,y\in\text{dom}\hspace{0.1cm}f$ and for any $0\leq t_1,t_2\leq 1$, we have
\begin{equation}
t_1 y+(1-t_1)x,t_2 y+(1-t_2)x\in\text{dom}\hspace{0.1cm}f
\end{equation}
By \eqref{eq:soc.2} we have
\begin{equation}
f(t_1 y+(1-t_1)x)\geq f(t_2 y+(1-t_2)x)+\nabla f(t_2 y+(1-t_2)x)^\text{T}(y-x)(t_1-t_2)
\end{equation}
or
\begin{equation}
g(t_1)\geq g(t_2)+g&rsquo;(t_2)(t_1-t_2),
\end{equation}
which implies that $g$ is convex, and hence so is $f$.</p><h4 id=nd-order-conds>Second-order conditions<a hidden class=anchor aria-hidden=true href=#nd-order-conds>#</a></h4><p>Consider a function $f$ such that $f$ is twice differentiable. Then $f$ is convex iff $\text{dom}\hspace{0.1cm}f$ is convex and its Hessian is positive semidefinite, i.e. for all $x\in\text{dom}\hspace{0.1cm}f$ we have
\begin{equation}
\nabla^2 f(x)\succeq 0
\end{equation}
Analogously, we have that $f$ is concave iff $\text{dom}\hspace{0.1cm}f$ is convex and for all $x\in\text{dom}\hspace{0.1cm}f$, $\nabla^2 f(x)\preceq 0$.</p><p>On the other hands, $f$ is stricly convex (or concave) if $\text{dom}\hspace{0.1cm}f$ is convex and $\nabla^2 f(x)\succ 0$ (or $\nabla^2 f(x)\prec 0$) for all $x\in\text{dom}\hspace{0.1cm}f$. The reverse order is not true.</p><h3 id=cvx-funcs-eg>Examples<a hidden class=anchor aria-hidden=true href=#cvx-funcs-eg>#</a></h3><h4 id=func-on-r>Functions on $\mathbb{R}$<a hidden class=anchor aria-hidden=true href=#func-on-r>#</a></h4><ul class=number-list><li><b>Exponential</b>. $\hspace{0.1cm}e^{ax}$ is convex on $\mathbb{R}$, for any $a\in\mathbb{R}$. Since
\begin{equation}
(e^{ax})''=(a e^{ax})'=a^2 e^{ax}\geq 0,
\end{equation}
for $a\in\mathbb{R}$.</li><li><b>Powers</b>. $\hspace{0.1cm}x^a$ is convex on $\mathbb{R}_{++}$ when $a\geq 1$ or $a\leq 0$, and concave for $0\leq a\leq 1$.<br>For $x\in\mathbb{R}_{++}$ and for $a\geq 1$ or $a\leq 0$, we have
\begin{equation}
(x^a)''=(a x^{a-1})'=a(a-1)x^{a-2}\geq 0
\end{equation}
On the other hands, for $x\in\mathbb{R}_{++}$ and for $0\leq a\leq 1$, we have
\begin{equation}
(x^a)''=a(a-1)x^{a-2}\leq 0
\end{equation}</li><li><b>Powers of absolute value</b>. $\hspace{0.1cm}\vert x\vert^p$ is convex on $\mathbb{R}$ for $p\geq 1$.<br>For any $0\leq\theta\leq 1$, by triangle inequality we have
\begin{align}
f(\theta x+(1-\theta)y)&=\vert\theta x+(1-\theta)y\vert^p \\ &\leq\left(\theta\vert x\vert+(1-\theta)\vert y\vert\right)^p
\end{align}</li><li><b>Logarithm</b>. $\hspace{0.1cm}\log x$ is concave on $\mathbb{R}_{++}$.<br>For $x\in\mathbb{R}_{++}$ we have
\begin{equation}
(\log x)''=\left(\frac{1}{x}\right)'=\frac{-1}{x^2}\lt 0
\end{equation}</li><li><b>Negative entropy</b>. $\hspace{0.1cm}x\log x$ (either on $\mathbb{R}_{++}$ or on $\mathbb{R}_+$ and defined as $0$ for $x=0$) is convex.<br>We have for all $x\in\mathbb{R}_{++}$
\begin{equation}
(x\log x)''=(1+\log x)'=\frac{1}{x}>0
\end{equation}</li></ul><h4 id=func-on-rn>Functions on $\mathbb{R}^n$<a hidden class=anchor aria-hidden=true href=#func-on-rn>#</a></h4><ul class=number-list><li><b>Norms</b>. Every norm on $\mathbb{R}^n$ is convex.<br>For $f:\mathbb{R}^n\to\mathbb{R}$ is a norm and for any $0\leq\theta\leq 1$, by triangle inequality, we have:
\begin{equation}
f\big(\theta x+(1-\theta)y\big)\leq f(\theta x)+f\big((1-\theta)y\big)=\theta f(\theta)+(1-\theta)f(y)
\end{equation}</li><li><b>Max function</b>. $\hspace{0.1cm}f(x)=\max{x_1,\ldots,x_n}=\max_{i=1,\ldots,n}x_i$ is convex on $\mathbb{R}^n$.<br>For any $0\leq\theta\leq 1$, we have
\begin{align}
f(\theta x+(1-\theta)y)&=\max_i(\theta x+(1-\theta)y) \\ &\leq\theta\max_i x_i+(1-\theta)\max_i y_i \\ &=\theta f(x)+(1-\theta)f(y)
		\end{align}</li><li><b>Quadratic-over-linear function</b>. The function $f(x,y)=x^2/y$ with
\begin{equation}
\text{dom}\hspace{0.1cm}f=\{(x,y)\in\mathbb{R}^2:y>0\}
\end{equation}
is convex, since we have its Hessian:
\begin{equation}
\nabla^2 f(x,y)=\nabla^2\frac{x^2}{y}=\left[\begin{matrix}2/y&-2x/y^2 \\ -2x/y^2&2x^2/y^3\end{matrix}\right]=\frac{2}{y^3}\left[\begin{matrix}y \\ -x\end{matrix}\right]\left[\begin{matrix}y \\ -x\end{matrix}\right]^\text{T}\succeq 0
\end{equation}</li><li><b>Log-sum-exp</b>. $\hspace{0.1cm}f(x)=\log(e^{x_1}+\ldots+e^{x_n})$ is convex on $\mathbb{R}^n$.<br>We have the Hessian of $f(x)$ is
\begin{equation}
\nabla^2 f(x)=\nabla^2\log(e^{x_1}+\ldots+e^{x_n})
\end{equation}</li></ul><h3 id=sub-lvl-sets>Sub-level sets<a hidden class=anchor aria-hidden=true href=#sub-lvl-sets>#</a></h3><h3 id=inequalities>Inequalities<a hidden class=anchor aria-hidden=true href=#inequalities>#</a></h3><h4 id=jensens-inequality>Jensen&rsquo;s inequality<a hidden class=anchor aria-hidden=true href=#jensens-inequality>#</a></h4><h3 id=operations-funcs>Operations that preserve convexity<a hidden class=anchor aria-hidden=true href=#operations-funcs>#</a></h3><h3 id=conjugate-func>The conjugate function<a hidden class=anchor aria-hidden=true href=#conjugate-func>#</a></h3><h3 id=quasi-cvx-funcs>Quasiconvex functions<a hidden class=anchor aria-hidden=true href=#quasi-cvx-funcs>#</a></h3><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2><p>[1] Stephen Boyd & Lieven Vandenberghe. <a href=http://www.stanford.edu/%E2%88%BCboyd/cvxbook/>Convex Optimization</a>. Cambridge UP, 2004.</p><h2 id=footnotes>Footnotes<a hidden class=anchor aria-hidden=true href=#footnotes>#</a></h2></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/tags/mathematics/>mathematics</a></li><li><a href=http://localhost:1313/tags/convex-optimization/>convex-optimization</a></li></ul><nav class=paginav><a class=prev href=http://localhost:1313/posts/reinforcement-learning/td-learning/><span class=title>« Prev</span><br><span>Temporal-Difference Learning</span>
</a><a class=next href=http://localhost:1313/posts/probability-statistics/gaussian-dist-gaussian-bn/><span class=title>Next »</span><br><span>Gaussian Distribution & Gaussian Network Models</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Convex sets, convex functions on x" href="https://x.com/intent/tweet/?text=Convex%20sets%2c%20convex%20functions&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2foptimization%2fcvx-sets-funcs%2f&amp;hashtags=mathematics%2cconvex-optimization"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg>
</a><a target=_blank rel="noopener noreferrer" aria-label="share Convex sets, convex functions on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2foptimization%2fcvx-sets-funcs%2f&amp;title=Convex%20sets%2c%20convex%20functions&amp;summary=Convex%20sets%2c%20convex%20functions&amp;source=http%3a%2f%2flocalhost%3a1313%2fposts%2foptimization%2fcvx-sets-funcs%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg>
</a><a target=_blank rel="noopener noreferrer" aria-label="share Convex sets, convex functions on reddit" href="https://reddit.com/submit?url=http%3a%2f%2flocalhost%3a1313%2fposts%2foptimization%2fcvx-sets-funcs%2f&title=Convex%20sets%2c%20convex%20functions"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg>
</a><a target=_blank rel="noopener noreferrer" aria-label="share Convex sets, convex functions on facebook" href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fposts%2foptimization%2fcvx-sets-funcs%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg>
</a><a target=_blank rel="noopener noreferrer" aria-label="share Convex sets, convex functions on whatsapp" href="https://api.whatsapp.com/send?text=Convex%20sets%2c%20convex%20functions%20-%20http%3a%2f%2flocalhost%3a1313%2fposts%2foptimization%2fcvx-sets-funcs%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg>
</a><a target=_blank rel="noopener noreferrer" aria-label="share Convex sets, convex functions on telegram" href="https://telegram.me/share/url?text=Convex%20sets%2c%20convex%20functions&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2foptimization%2fcvx-sets-funcs%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg>
</a><a target=_blank rel="noopener noreferrer" aria-label="share Convex sets, convex functions on ycombinator" href="https://news.ycombinator.com/submitlink?t=Convex%20sets%2c%20convex%20functions&u=http%3a%2f%2flocalhost%3a1313%2fposts%2foptimization%2fcvx-sets-funcs%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></div></footer><script src=https://utteranc.es/client.js repo=trunghng/trunghng.github.io issue-term=pathname theme=github-light crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2024 <a href=http://localhost:1313/>Littleroot</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>