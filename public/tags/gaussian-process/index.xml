<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>gaussian-process on Littleroot</title>
    <link>http://localhost:1313/tags/gaussian-process/</link>
    <description>Recent content in gaussian-process on Littleroot</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Fri, 28 Jun 2024 16:14:16 +0700</lastBuildDate><atom:link href="http://localhost:1313/tags/gaussian-process/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Gaussian Processes</title>
      <link>http://localhost:1313/posts/machine-learning/gaussian-processes/</link>
      <pubDate>Fri, 28 Jun 2024 16:14:16 +0700</pubDate>
      
      <guid>http://localhost:1313/posts/machine-learning/gaussian-processes/</guid>
      <description>&lt;h2 id=&#34;gaussian-processes&#34;&gt;Gaussian Processes&lt;/h2&gt;
&lt;p&gt;A &lt;strong&gt;Gaussian process (GP)&lt;/strong&gt; is a collection of r.v.s, any finite number of which have a joint Gaussian distribution. Each GP $f(\mathbf{x})$ is fully defined by a mean function $m(\mathbf{x})$ and a positive definite covariance function $k(\mathbf{x},\mathbf{x}&amp;rsquo;)$.
\begin{align}
m(\mathbf{x})&amp;amp;=\mathbb{E}\big[f(\mathbf{x})\big] \\ k(\mathbf{x},\mathbf{x}&amp;rsquo;)&amp;amp;=\mathbb{E}\big[(f(\mathbf{x})-m(\mathbf{x}))(f(\mathbf{x}&amp;rsquo;)-m(\mathbf{x}&amp;rsquo;))\big]
\end{align}
And we denote
\begin{equation}
f(\mathbf{x})\sim\mathcal{GP}(m(\mathbf{x}),k(\mathbf{x},\mathbf{x}&amp;rsquo;))
\end{equation}&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;[1] Carl Edward Rasmussen &amp;amp; Christopher K. I. Williams. &lt;a href=&#34;https://gaussianprocess.org/gpml&#34;&gt;Gaussian Processes for Machine Learning&lt;/a&gt;. The MIT Press, 2006.&lt;/p&gt;
&lt;h2 id=&#34;footnotes&#34;&gt;Footnotes&lt;/h2&gt;</description>
    </item>
    
    <item>
      <title>PILCO</title>
      <link>http://localhost:1313/posts/reinforcement-learning/pilco/</link>
      <pubDate>Fri, 08 Mar 2024 10:03:08 +0700</pubDate>
      
      <guid>http://localhost:1313/posts/reinforcement-learning/pilco/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;A model-based RL method that learns a Bayesian nonparametric model (Gaussian process) and reduces model bias to improve sample efficiency.&lt;/p&gt;
&lt;/blockquote&gt;</description>
    </item>
    
  </channel>
</rss>
