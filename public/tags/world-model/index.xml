<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>world-model on Littleroot</title>
    <link>https://trunghng.github.io/tags/world-model/</link>
    <description>Recent content in world-model on Littleroot</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 22 Sep 2024 17:54:43 +0700</lastBuildDate><atom:link href="https://trunghng.github.io/tags/world-model/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Model-based RL with latent variable models</title>
      <link>https://trunghng.github.io/posts/reinforcement-learning/mbrl-lvm/</link>
      <pubDate>Sun, 22 Sep 2024 17:54:43 +0700</pubDate>
      
      <guid>https://trunghng.github.io/posts/reinforcement-learning/mbrl-lvm/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;Model-based RL methods that learn latent-variable models instead of trying to predict dynamics models in the observed space. The learned world model then can be used in planning effectively rather than being less efficiently, for instance in visual-based tasks, generating images for future time steps and feed them back into the model to predict the next ones, which requires more computation.&lt;/p&gt;
&lt;/blockquote&gt;</description>
    </item>
    
  </channel>
</rss>
